{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cristianmejia00/clustering/blob/main/Topic_Models_using_BERTopic_TOPIC_MODEL_20241101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zj3lYckpO2Yn"
   },
   "source": [
    "# Topic Modeling with BERTopic\n",
    "\n",
    "🔴 copied from the [Kubota Colab](https://colab.research.google.com/drive/1YsDp5_qGXGJKsEXsS8DO8CA_lqZc6EpA).  \n",
    "\n",
    "`Topic Models` are methods to automatically organize a corpus of text into topics.\n",
    "\n",
    "Topic Model process:\n",
    "1. Data preparation\n",
    "2. Tranform text to numeric vectors\n",
    "3. Multidimensionality reduction\n",
    "4. Clustering\n",
    "5. Topic analysis\n",
    "6. Cluster assignation\n",
    "\n",
    "\n",
    "This notebook uses the library `BERTopic` which is a one-stop solution for topic modeling including handy functions for plotting and analysis. However, BERTopic does not have a function to extract the X and Y coords from UMAP. If we need the coordinates then use the notebooks `Topic_Models_using_Transformers` instead. In any other situation, when a quick analysis is needed this notebook may be better.\n",
    "\n",
    "This notebook is also the one needed for the heatmap codes included in this folder.\n",
    "\n",
    "`BERTopic` is Python library that handles steps 2 to 6.\n",
    "BERT topic models use the transformer architechture to generate the embeds (i.e. the vector or numeric representation of words) and are currently the state-of-the-art method for vectorization.\n",
    "\n",
    "This notebook shows how to use it.\n",
    "\n",
    "---\n",
    "Reading:\n",
    "[Topic Modeling with Deep Learning Using Python BERTopic](https://medium.com/grabngoinfo/topic-modeling-with-deep-learning-using-python-bertopic-cf91f5676504)\n",
    "[Advanced Topic Modeling with BERTopic](https://www.pinecone.io/learn/bertopic/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlufmOowbHSF"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFQU-BC5ReYd"
   },
   "source": [
    "## Packages installation and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ckx8hOIyRZvv",
    "outputId": "20e7642f-824b-4ba1-86cc-5a97c89670c5"
   },
   "outputs": [],
   "source": [
    "#!pip install bertopic[visualization]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gMlZ_7DkOxGG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristian/Desktop/GitHub/clustering/env-tm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import uuid\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from datetime import date\n",
    "from itertools import compress\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZ1BccaqRtS0"
   },
   "source": [
    "## Connect your Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6os5BGPFRxfX",
    "outputId": "41e02c25-1dc9-426e-f441-874fc600fc70"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f2p9sY7sUYkU"
   },
   "outputs": [],
   "source": [
    "def find_e_keys(dictionary):\n",
    "    # List comprehension to find keys starting with 'e'\n",
    "    e_keys = [key for key in dictionary if str(key).lower().startswith('e')]\n",
    "    return e_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDm5-r5oR98q"
   },
   "source": [
    "# 🔴 Input files and options\n",
    "\n",
    "Go to your Google Drive and create a folder in the root directory. We are going to save all related data in that directory.\n",
    "Upload the dataset of news into the above folder.\n",
    "- The dataset should be a `.csv` file.\n",
    "- Every row in the dataset is a document\n",
    "- It can any kind of columns. Some columns must contain the text we want to analyze. For example, a dataset of academic articles may contain a \"Title\" and/or \"Abstract\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5ICq5zQbSJa8"
   },
   "outputs": [],
   "source": [
    "# The bibliometrics folder\n",
    "# Colab\n",
    "ROOT_FOLDER_PATH = \"drive/MyDrive/Bibliometrics_Drive\"\n",
    "\n",
    "# Mac\n",
    "ROOT_FOLDER_PATH = \"/Users/cristian/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive\"\n",
    "\n",
    "# Change to the name of the folder where the dataset is uploaded inside the above folder\n",
    "project_folder = 'Q339_igem'\n",
    "\n",
    "analysis_id = 'a01_tm__f01_e01__hdbs'\n",
    "\n",
    "# Filtered label\n",
    "settings_directive = \"settings_analysis_directive_2025-08-04-16-40.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QpoR8P3O0ACf"
   },
   "outputs": [],
   "source": [
    "# Read settings\n",
    "with open(f'{ROOT_FOLDER_PATH}/{project_folder}/{analysis_id}/{settings_directive}', 'r') as file:\n",
    "    settings = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "COh3zc3b2oAn"
   },
   "outputs": [],
   "source": [
    "# Input dataset\n",
    "dataset_file_path = f\"{ROOT_FOLDER_PATH}/{settings['metadata']['project_folder']}/{settings['metadata']['filtered_folder']}/dataset_raw_cleaned.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "biEFdxrm0WrO"
   },
   "outputs": [],
   "source": [
    "# Function to save files\n",
    "def save_as_csv(df, save_name_without_extension, with_index):\n",
    "    \"usage: `save_as_csv(dataframe, 'filename')`\"\n",
    "    df.to_csv(f\"{ROOT_FOLDER_PATH}/{save_name_without_extension}.csv\", index=with_index)\n",
    "    print(\"===\\nSaved: \", f\"{ROOT_FOLDER_PATH}/{save_name_without_extension}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ff7hQXE1dYDw"
   },
   "outputs": [],
   "source": [
    "# prompt: a function to save object to a pickle file\n",
    "def save_object_as_pickle(obj, filename):\n",
    "  \"\"\"\n",
    "  Saves an object as a pickle file.\n",
    "\n",
    "  Args:\n",
    "      obj: The object to be saved.\n",
    "      filename: The filename of the pickle file.\n",
    "  \"\"\"\n",
    "  with open(filename, \"wb\") as f:\n",
    "    pickle.dump(obj, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iljQe0_xb2FU"
   },
   "outputs": [],
   "source": [
    "# prompt: a function to load pickle object given a path\n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "Tob-4BIaUbZ9",
    "outputId": "d48eac6d-2af8-4991-af19-5bda2386e6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4199, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_N</th>\n",
       "      <th>uuid</th>\n",
       "      <th>UT</th>\n",
       "      <th>PY</th>\n",
       "      <th>AU</th>\n",
       "      <th>TI</th>\n",
       "      <th>AB</th>\n",
       "      <th>Countries</th>\n",
       "      <th>DI</th>\n",
       "      <th>ID</th>\n",
       "      <th>WC</th>\n",
       "      <th>Institutions</th>\n",
       "      <th>CR</th>\n",
       "      <th>C1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>f399a9de-8ec5-4ace-b6f3-b9137f3107eb</td>\n",
       "      <td>173</td>\n",
       "      <td>2009</td>\n",
       "      <td>UNIPV-Pavia</td>\n",
       "      <td>Ethanol? Whey not!</td>\n",
       "      <td>Cheese whey is classified as a special waste f...</td>\n",
       "      <td>ITA</td>\n",
       "      <td>https://2009.igem.org/Team:UNIPV-Pavia</td>\n",
       "      <td>Food/Energy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UniversitÃ  degli Studi di Pavia\\r\\r\\nDipartim...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9a1131bd-91da-4871-9bad-d809761bc77e</td>\n",
       "      <td>174</td>\n",
       "      <td>2009</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>Bac-man: sequestering cadmium into Bacillus sp...</td>\n",
       "      <td>Cadmium contamination can be a serious problem...</td>\n",
       "      <td>GBR</td>\n",
       "      <td>https://2009.igem.org/Team:Newcastle</td>\n",
       "      <td>Environment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newcastle University\\r\\r\\nNewcastle upon Tyne\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>f866ee62-25b0-4cde-b895-45009fa2b6fe</td>\n",
       "      <td>175</td>\n",
       "      <td>2009</td>\n",
       "      <td>TUDelft</td>\n",
       "      <td>Bacterial Relay Race</td>\n",
       "      <td>In our project, we aim at creating a cell-to-c...</td>\n",
       "      <td>NLD</td>\n",
       "      <td>https://2009.igem.org/Team:TUDelft</td>\n",
       "      <td>Information Processing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delft University of Technology\\r\\r\\nDelft, The...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>32a634be-6e1d-4d11-bace-8a31f9a3a88a</td>\n",
       "      <td>176</td>\n",
       "      <td>2009</td>\n",
       "      <td>USTC</td>\n",
       "      <td>E. coli Automatic Directed Evolution Machine: ...</td>\n",
       "      <td>Evolution is powerful enough to create everyth...</td>\n",
       "      <td>CHN</td>\n",
       "      <td>https://2009.igem.org/Team:USTC</td>\n",
       "      <td>Foundational Advance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of Science and Technology of China\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>63d73d3a-b239-4624-a2bb-2fb6d068294e</td>\n",
       "      <td>177</td>\n",
       "      <td>2009</td>\n",
       "      <td>Warsaw</td>\n",
       "      <td>BacInVader Ð a new system for cancer genetic t...</td>\n",
       "      <td>The main aim of our project is to design a mod...</td>\n",
       "      <td>POL</td>\n",
       "      <td>https://2009.igem.org/Team:Warsaw</td>\n",
       "      <td>Health/Medicine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of Warsaw\\r\\r\\nKrakowskie Przedmies...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_N                                  uuid   UT    PY           AU  \\\n",
       "0    1  f399a9de-8ec5-4ace-b6f3-b9137f3107eb  173  2009  UNIPV-Pavia   \n",
       "1    2  9a1131bd-91da-4871-9bad-d809761bc77e  174  2009    Newcastle   \n",
       "2    3  f866ee62-25b0-4cde-b895-45009fa2b6fe  175  2009      TUDelft   \n",
       "3    4  32a634be-6e1d-4d11-bace-8a31f9a3a88a  176  2009         USTC   \n",
       "4    5  63d73d3a-b239-4624-a2bb-2fb6d068294e  177  2009       Warsaw   \n",
       "\n",
       "                                                  TI  \\\n",
       "0                                 Ethanol? Whey not!   \n",
       "1  Bac-man: sequestering cadmium into Bacillus sp...   \n",
       "2                               Bacterial Relay Race   \n",
       "3  E. coli Automatic Directed Evolution Machine: ...   \n",
       "4  BacInVader Ð a new system for cancer genetic t...   \n",
       "\n",
       "                                                  AB Countries  \\\n",
       "0  Cheese whey is classified as a special waste f...       ITA   \n",
       "1  Cadmium contamination can be a serious problem...       GBR   \n",
       "2  In our project, we aim at creating a cell-to-c...       NLD   \n",
       "3  Evolution is powerful enough to create everyth...       CHN   \n",
       "4  The main aim of our project is to design a mod...       POL   \n",
       "\n",
       "                                       DI                      ID   WC  \\\n",
       "0  https://2009.igem.org/Team:UNIPV-Pavia             Food/Energy  NaN   \n",
       "1    https://2009.igem.org/Team:Newcastle             Environment  NaN   \n",
       "2      https://2009.igem.org/Team:TUDelft  Information Processing  NaN   \n",
       "3         https://2009.igem.org/Team:USTC    Foundational Advance  NaN   \n",
       "4       https://2009.igem.org/Team:Warsaw         Health/Medicine  NaN   \n",
       "\n",
       "                                        Institutions  CR  C1  \n",
       "0  UniversitÃ  degli Studi di Pavia\\r\\r\\nDipartim... NaN NaN  \n",
       "1  Newcastle University\\r\\r\\nNewcastle upon Tyne\\... NaN NaN  \n",
       "2  Delft University of Technology\\r\\r\\nDelft, The... NaN NaN  \n",
       "3  University of Science and Technology of China\\... NaN NaN  \n",
       "4  University of Warsaw\\r\\r\\nKrakowskie Przedmies... NaN NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the data file\n",
    "df = pd.read_csv(f\"{dataset_file_path}\", encoding='latin-1')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UrPiLepN1s9"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eK-U-Sl8fc-m"
   },
   "source": [
    "## PART 2: Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FhwGnBjFQT4x"
   },
   "outputs": [],
   "source": [
    "# bibliometrics_folder\n",
    "# project_folder\n",
    "# project_name_suffix\n",
    "# ROOT_FOLDER_PATH = f\"drive/MyDrive/{bibliometrics_folder}\"\n",
    "\n",
    "#############################################################\n",
    "# Embeddings folder\n",
    "embeddings_folder_name = settings['tmo']['embeds_folder']\n",
    "\n",
    "# Which column has the year of the documents?\n",
    "my_year = settings['tmo']['year_column']\n",
    "\n",
    "# Number of topics. Select the number of topics to extract.\n",
    "# Choose 0, for automatic detection.\n",
    "n_topics = 71#settings['tmo']['n_topics']\n",
    "\n",
    "# Minimum number of documents per topic\n",
    "min_topic_size = settings['tmo']['min_topic_size']\n",
    "\n",
    "# Threshold for others\n",
    "# This is the threshold for the topics that will be considered as \"others\"\n",
    "# Topics with a cumulative percentage of documents below this threshold will be grouped into an \"others\" topic.\n",
    "# For example, if set to 0.9, topics that together account for 90% of the documents will be kept, and the rest will be grouped into \"others\".\n",
    "others_threshold = 0.99#settings['tmo']['others_threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9RYSioo2cxxC"
   },
   "outputs": [],
   "source": [
    "# Get the embeddings back.\n",
    "embeddings = load_pickle(f\"{ROOT_FOLDER_PATH}/{project_folder}/{settings['metadata']['filtered_folder']}/{embeddings_folder_name}/embeddings.pck\")\n",
    "corpus =     pd.read_csv(f\"{ROOT_FOLDER_PATH}/{project_folder}/{settings['metadata']['filtered_folder']}/{embeddings_folder_name}/corpus.csv\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "injCV_IPN26L"
   },
   "outputs": [],
   "source": [
    "# Combine embeddings\n",
    "documents = corpus.text.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "ve_oloYNrBLz"
   },
   "outputs": [],
   "source": [
    "# corpus['uuid'] = [uuid.uuid4() for _ in range(len(corpus.index))]\n",
    "# corpus['X_N'] = [i for i in range(1, len(corpus.index)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onVFOjBZuMmJ",
    "outputId": "4898b936-f4ea-4a7d-8448-a65466de85f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4199"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S7LeuG_7S4Db",
    "outputId": "4e27c106-2e0c-4630-a741-2fbd5e5512b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(embeddings) == len(documents)\n",
    "len(embeddings['embeddings']) == len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings['embeddings'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "n6qUvhGGcPZo"
   },
   "outputs": [],
   "source": [
    "from hdbscan.hdbscan_ import HDBSCAN\n",
    "# Execute the topic model.\n",
    "# I suggest changing the values marked with #<---\n",
    "# The others are the default values and they'll work fine in most cases.\n",
    "# This will take several minutes to finish.\n",
    "\n",
    "# Initiate UMAP\n",
    "umap_model = UMAP(n_neighbors=15,\n",
    "                  n_components=5,\n",
    "                  min_dist=0.0,\n",
    "                  metric='cosine',\n",
    "                  random_state=100)\n",
    "\n",
    "if n_topics == 0:\n",
    "  # Initiate topic model with HDBScan (Automatic topic selection)\n",
    "  topic_model_params = HDBSCAN(min_cluster_size=min_topic_size,\n",
    "                               metric='euclidean',\n",
    "                               cluster_selection_method='eom',\n",
    "                               prediction_data=True)\n",
    "else:\n",
    "  # Initiate topic model with K-means (Manual topic selection)\n",
    "  topic_model_params = KMeans(n_clusters = n_topics)\n",
    "\n",
    "# Initiate BERTopic\n",
    "topic_model = BERTopic(umap_model = umap_model,\n",
    "                       hdbscan_model = topic_model_params,\n",
    "                       min_topic_size=min_topic_size,\n",
    "                       #nr_topics=15,          #<--- Footnote 1\n",
    "                       n_gram_range=(1,3),\n",
    "                       language='english',\n",
    "                       calculate_probabilities=True,\n",
    "                       verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# Footnote 1: This controls the number of topics we want AFTER clustering.\n",
    "# Add a hashtag at the beggining to use the number of topics returned by the topic model.\n",
    "# When using HDBScan nr_topics will be obtained after orphans removal, and there is no warranty that `nr_topics < HDBScan topics`.\n",
    "# thus, with HDBScan `nr_topics` means N topics OR LESS.\n",
    "# When using KMeans nr_topics can be used to further reduce the number of topics.\n",
    "# We use the topics as returned by the topic model. So we do not need to activate it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute topic model\n",
    "#topics, probabilities = topic_model.fit_transform(documents, embeddings)\n",
    "topics, probabilities = topic_model.fit_transform(documents, embeddings['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQQsmPGzUCuB",
    "outputId": "a2b43bac-051a-4599-ad04-a36b1a575a26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-04 16:45:38,492 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-08-04 16:45:46,733 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-08-04 16:45:46,743 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-08-04 16:45:46,819 - BERTopic - Cluster - Completed ✓\n",
      "2025-08-04 16:45:46,824 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2025-08-04 16:45:50,603 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# Compute topic model\n",
    "#topics, probabilities = topic_model.fit_transform(documents, embeddings)\n",
    "topics, probabilities = topic_model.fit_transform(documents, embeddings['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "67pgsMtwsFmH",
    "outputId": "82c86e95-6be7-4832-a076-94d8d9dcd8ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>0_heavy_metal_heavy metal_the</td>\n",
       "      <td>[heavy, metal, heavy metal, the, metals, and, ...</td>\n",
       "      <td>[Nanocrystal Ecoli Flocculation Union Heavy me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>1_the_of_to_in</td>\n",
       "      <td>[the, of, to, in, and, we, system, is, as, by]</td>\n",
       "      <td>[Conversensations Developing a TwoWay QuorumSe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>2_of_the_to_and</td>\n",
       "      <td>[of, the, to, and, we, circuits, in, synthetic...</td>\n",
       "      <td>[Back to the Basics Synthetic biology has stri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>117</td>\n",
       "      <td>3_insulin_to_the_diabetes</td>\n",
       "      <td>[insulin, to, the, diabetes, of, glucose, in, ...</td>\n",
       "      <td>[MINILOSS MIcrofluidic orgaN chIp for bLOod gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>4_the_of_and_in</td>\n",
       "      <td>[the, of, and, in, production, to, is, for, sy...</td>\n",
       "      <td>[Oppossum Plants and Pichia You Down With OPP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>19</td>\n",
       "      <td>66_olfactory_vocs_volatile_volatile organic</td>\n",
       "      <td>[olfactory, vocs, volatile, volatile organic, ...</td>\n",
       "      <td>[Vigilantly Optimizing Cancer Detection Using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>18</td>\n",
       "      <td>67_histamine_allergy_allergic_allergies</td>\n",
       "      <td>[histamine, allergy, allergic, allergies, is, ...</td>\n",
       "      <td>[Allergy test master the histamine receptor ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>15</td>\n",
       "      <td>68_retardant_fire_flame_flame retardant</td>\n",
       "      <td>[retardant, fire, flame, flame retardant, surf...</td>\n",
       "      <td>[Synbiofoam a synthetic alternative to fluoros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "      <td>69_pfas_pfoa_per and_of pfas</td>\n",
       "      <td>[pfas, pfoa, per and, of pfas, substances, and...</td>\n",
       "      <td>[Detection and Degradation of Perfluoroalkyl S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>70_nan_sententiae_sit_est</td>\n",
       "      <td>[nan, sententiae, sit, est, sententiae est, ip...</td>\n",
       "      <td>[CerviCare nan, Run Sperm Run nan, Lorem ipsum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                         Name  \\\n",
       "0       0    177                0_heavy_metal_heavy metal_the   \n",
       "1       1    127                               1_the_of_to_in   \n",
       "2       2    120                              2_of_the_to_and   \n",
       "3       3    117                    3_insulin_to_the_diabetes   \n",
       "4       4    101                              4_the_of_and_in   \n",
       "..    ...    ...                                          ...   \n",
       "66     66     19  66_olfactory_vocs_volatile_volatile organic   \n",
       "67     67     18      67_histamine_allergy_allergic_allergies   \n",
       "68     68     15      68_retardant_fire_flame_flame retardant   \n",
       "69     69     13                 69_pfas_pfoa_per and_of pfas   \n",
       "70     70     10                    70_nan_sententiae_sit_est   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [heavy, metal, heavy metal, the, metals, and, ...   \n",
       "1      [the, of, to, in, and, we, system, is, as, by]   \n",
       "2   [of, the, to, and, we, circuits, in, synthetic...   \n",
       "3   [insulin, to, the, diabetes, of, glucose, in, ...   \n",
       "4   [the, of, and, in, production, to, is, for, sy...   \n",
       "..                                                ...   \n",
       "66  [olfactory, vocs, volatile, volatile organic, ...   \n",
       "67  [histamine, allergy, allergic, allergies, is, ...   \n",
       "68  [retardant, fire, flame, flame retardant, surf...   \n",
       "69  [pfas, pfoa, per and, of pfas, substances, and...   \n",
       "70  [nan, sententiae, sit, est, sententiae est, ip...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [Nanocrystal Ecoli Flocculation Union Heavy me...  \n",
       "1   [Conversensations Developing a TwoWay QuorumSe...  \n",
       "2   [Back to the Basics Synthetic biology has stri...  \n",
       "3   [MINILOSS MIcrofluidic orgaN chIp for bLOod gl...  \n",
       "4   [Oppossum Plants and Pichia You Down With OPP ...  \n",
       "..                                                ...  \n",
       "66  [Vigilantly Optimizing Cancer Detection Using ...  \n",
       "67  [Allergy test master the histamine receptor ba...  \n",
       "68  [Synbiofoam a synthetic alternative to fluoros...  \n",
       "69  [Detection and Degradation of Perfluoroalkyl S...  \n",
       "70  [CerviCare nan, Run Sperm Run nan, Lorem ipsum...  \n",
       "\n",
       "[71 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of topics\n",
    "# Topic = the topic number. From the largest topic.\n",
    "#         \"-1\" is the generic topic. Genericr keywords are aggegrated here.\n",
    "# Count = Documents assigned to this topic\n",
    "# Name = Top 4 words of the topic based on probability\n",
    "# Representation = The list of words representing this topic\n",
    "# Representative_Docs = Documents assigned to this topic\n",
    "tm_summary = topic_model.get_topic_info()\n",
    "tm_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "k9mN1tgZQupy"
   },
   "outputs": [],
   "source": [
    "# Save the topic model assets\n",
    "tm_folder_path = f'{ROOT_FOLDER_PATH}/{project_folder}/{settings[\"metadata\"][\"analysis_id\"]}'\n",
    "\n",
    "if not os.path.exists(tm_folder_path):\n",
    "  !mkdir $tm_folder_path\n",
    "\n",
    "tm_summary.to_csv(f'{tm_folder_path}/topic_model_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WuE0vkbp3fVL",
    "outputId": "aa8ebf45-cdd3-4161-9ac4-1343c91f47da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of topics found\n",
    "found_topics = max(tm_summary.Topic) + 1\n",
    "found_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KjKUcNMdwFHQ",
    "outputId": "b3549b7c-4c8a-4b82-8d87-6a46774e4694"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm all documents are assigned\n",
    "sum(tm_summary.Count) == len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGyoQT47xY_R",
    "outputId": "9affafe5-0ff7-4edf-d9f6-3d7a7eda04eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('heavy', 0.015450560745119704),\n",
       " ('metal', 0.015082348247861244),\n",
       " ('heavy metal', 0.0106227120823726),\n",
       " ('the', 0.010473297896099042),\n",
       " ('metals', 0.010056216944294582),\n",
       " ('and', 0.01001487564575892),\n",
       " ('of', 0.00907147239699955),\n",
       " ('in', 0.00887287961654058),\n",
       " ('to', 0.008634367233939611),\n",
       " ('ions', 0.008075810917577921)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 10 terms for a topic\n",
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PU99D2xhxoOY",
    "outputId": "4e90e928-9bbf-40c3-c3b5-a1a50abe82f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nanocrystal Ecoli Flocculation Union Heavy metals especially zinc and cadmium inevitably have detrimental effects on the environment and our human race To be more specific water sources can be contaminated by heavy metals leaching from industrial waste acid rain can exacerbate this process by releasing heavy metals trapped in soils Considering the properties of heavy metals unable to decay and thus a different kind of challenge for medication we have constructed a heavy metal detection and recycle system Briefly our system is based on a special strain of Ecoli containing smtlocus CDS and an unfamiliar flocculation gene The system can detect the existence of metal zinc and cadmium through visualized pigment gene driven by the smtlocus recycle these heavy metal ions by forming nanocrystals resulted from CDS and flocculate the nanocrystals Eventually we can realize our doublewin goal safeguarding our environment by removing heavy metal ions and yielding a great amount of nanocrystals',\n",
       " 'Lead it go Heavy metal sequestration from regional contaminated waters using genetically engineered Ecoli Heavy metal pollution in water is one of the most significant public health risks around the world Pollutants including lead mercury and nickel can enter water supplies through improper disposal of waste industrial manufacturing and mining  Previous researchers have developed biological methods of heavy metal sequestration utilizing heavy metal transport proteins and metallothioneins a class of lowmolecular weight proteins with high binding affinities for heavy metals  In these genetically engineered systems the transport proteins will preferentially transport a specific heavy metal into the cell and the metallothionein will aggressively binddriving flux into the cell and sequestering the toxic metal  Our research aims to modularize previous sequestration systems for nickel and mercury utilizing a yeast metallothioneinglutathionestransferase fusion protein as well the transport proteins NixA nickel transporter and merTmerP mercury transporter  We also plan to extend this sequestration system using a putative lead transport protein',\n",
       " 'ColeaderzipHeavy metal treatment of copper lead and zinc Heavy metal pollution is a serious environmental problem in both developed and developing countries The existing chemical degradation methods have problems such as high cost complicated process low recovery efficiency and severe secondary pollution In Jilin China team is trying to build a new type of engineered bacteria for the treatment of copper lead and zinc ions which integrates heavy metal ion sensing and adsorption The specific promoter can effectively sense the presence of heavy metal ion and then activate the downstream fused expression of the metal binding protein and outer membrane protein on the cell surface And the expression is to achieve the purpose of adsorbing heavy metal ions Combined with our practical design our whole system is expected to solve the increasingly serious heavy metal ion pollution']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 10 documents for a topic\n",
    "topic_model.get_representative_docs(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "1CgYkbHN9I2T"
   },
   "outputs": [],
   "source": [
    "# Others\n",
    "\n",
    "# # Get the number of documents per topic (same as in the table above)\n",
    "# topic_model.get_topic_freq(0)\n",
    "\n",
    "# # Get the main keywords per topic\n",
    "# topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQKxUqHN9RT7",
    "outputId": "c572d73b-fc91-4c84-dc79-8f047b046aa2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'calculate_probabilities': True,\n",
       " 'ctfidf_model': ClassTfidfTransformer(),\n",
       " 'embedding_model': None,\n",
       " 'hdbscan_model': KMeans(n_clusters=71),\n",
       " 'language': 'english',\n",
       " 'low_memory': False,\n",
       " 'min_topic_size': 5,\n",
       " 'n_gram_range': (1, 3),\n",
       " 'nr_topics': None,\n",
       " 'representation_model': None,\n",
       " 'seed_topic_list': None,\n",
       " 'top_n_words': 10,\n",
       " 'umap_model': UMAP(angular_rp_forest=True, metric='cosine', min_dist=0.0, n_components=5, n_jobs=1, random_state=100, tqdm_kwds={'bar_format': '{desc}: {percentage:3.0f}%| {bar} {n_fmt}/{total_fmt} [{elapsed}]', 'desc': 'Epochs completed', 'disable': True}),\n",
       " 'vectorizer_model': CountVectorizer(ngram_range=(1, 3)),\n",
       " 'verbose': True,\n",
       " 'zeroshot_min_similarity': 0.7,\n",
       " 'zeroshot_topic_list': None}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the parameters used. (For reporting)\n",
    "topic_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8hwSK98RM9-",
    "outputId": "07a40193-c69a-4356-b1b0-ac721ef78c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "tm_params = dict(topic_model.get_params())\n",
    "for key, value in tm_params.items():\n",
    "    tm_params[key]=  str(value)\n",
    "with open(f'{tm_folder_path}/topic_model_params.json', 'w') as f:\n",
    "    json.dump(tm_params, f, ensure_ascii=False, indent=4)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5v4Wvn3ZAkZP",
    "outputId": "ea347717-a33e-40ad-ad2d-51798cbc5b5f"
   },
   "outputs": [],
   "source": [
    "# # Get the topic score for each paper and its assigned topic\n",
    "# topic_distr, _ = topic_model.approximate_distribution(documents, batch_size=1000)\n",
    "# distributions = [distr[topic] if topic != -1 else 0 for topic, distr in zip(topics, topic_distr)]\n",
    "# topic_distr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the topic score for each paper and its assigned topic\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "def calculate_centroid_scores(embeddings, topics, distance_metric='euclidean'):\n",
    "    \"\"\"\n",
    "    Calculate scores for documents based on distance from topic centroids.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: List/array of document embeddings (shape: [n_docs, embedding_dim])\n",
    "        topics: List of topic assignments for each document (length: n_docs)\n",
    "        distance_metric: 'euclidean' or 'cosine'\n",
    "    \n",
    "    Returns:\n",
    "        scores: List of scores (lower = closer to centroid)\n",
    "    \"\"\"\n",
    "    embeddings = np.array(embeddings)\n",
    "    topics = np.array(topics)\n",
    "    \n",
    "    # Group documents by topic\n",
    "    topic_groups = defaultdict(list)\n",
    "    for idx, topic in enumerate(topics):\n",
    "        topic_groups[topic].append(idx)\n",
    "    \n",
    "    # Calculate centroids for each topic\n",
    "    centroids = {}\n",
    "    for topic, doc_indices in topic_groups.items():\n",
    "        topic_embeddings = embeddings[doc_indices]\n",
    "        centroids[topic] = np.mean(topic_embeddings, axis=0)\n",
    "    \n",
    "    # Calculate scores (distances from centroids)\n",
    "    scores = np.zeros(len(embeddings))\n",
    "    \n",
    "    for topic, doc_indices in topic_groups.items():\n",
    "        centroid = centroids[topic]\n",
    "        topic_embeddings = embeddings[doc_indices]\n",
    "        \n",
    "        if distance_metric == 'euclidean':\n",
    "            distances = np.linalg.norm(topic_embeddings - centroid, axis=1)\n",
    "        elif distance_metric == 'cosine':\n",
    "            distances = cosine_distances([centroid], topic_embeddings)[0]\n",
    "        else:\n",
    "            raise ValueError(\"distance_metric must be 'euclidean' or 'cosine'\")\n",
    "        \n",
    "        scores[doc_indices] = distances\n",
    "    \n",
    "    return scores.tolist()\n",
    "\n",
    "\n",
    "# Normalize scores to 0-1 range per topic\n",
    "def normalize_scores_by_topic(scores, topics):\n",
    "    \"\"\"Normalize scores to 0-1 range within each topic.\"\"\"\n",
    "    scores = np.array(scores)\n",
    "    topics = np.array(topics)\n",
    "    normalized_scores = scores.copy()\n",
    "    \n",
    "    for topic in np.unique(topics):\n",
    "        topic_mask = topics == topic\n",
    "        topic_scores = scores[topic_mask]\n",
    "        \n",
    "        if len(topic_scores) > 1:  # Only normalize if more than 1 document\n",
    "            min_score = topic_scores.min()\n",
    "            max_score = topic_scores.max()\n",
    "            if max_score > min_score:\n",
    "                normalized_scores[topic_mask] = 1 - ((topic_scores - min_score) / (max_score - min_score))\n",
    "            else:\n",
    "                normalized_scores[topic_mask] = 0  # All documents identical\n",
    "    \n",
    "    return normalized_scores.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage with normalization:\n",
    "scores = calculate_centroid_scores(embeddings['embeddings'], topics)\n",
    "normalized_scores = normalize_scores_by_topic(scores, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "I7E0_6bv9hBp",
    "outputId": "06faea2f-1c00-4ca7-958b-4dd2dcb10c36"
   },
   "outputs": [],
   "source": [
    "# Document information. Including the topic assignation\n",
    "dataset_clustering_results = topic_model.get_document_info(documents, df = corpus, metadata={\"Score\": normalized_scores})\n",
    "\n",
    "# Check for orphans (Topic == -1), save and remove them\n",
    "if -1 in dataset_clustering_results['Topic'].values:\n",
    "    orphans = dataset_clustering_results[dataset_clustering_results['Topic'] == -1]\n",
    "    orphans.to_csv(f'{tm_folder_path}/orphans.csv', index=False)\n",
    "    dataset_clustering_results = dataset_clustering_results[dataset_clustering_results['Topic'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UT</th>\n",
       "      <th>uuid</th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Representative_document</th>\n",
       "      <th>Score</th>\n",
       "      <th>X_E</th>\n",
       "      <th>X_C</th>\n",
       "      <th>level0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173</td>\n",
       "      <td>791aefbd-0fde-417e-8e1b-2f7210647032</td>\n",
       "      <td>Ethanol Whey not Cheese whey is classified as ...</td>\n",
       "      <td>22</td>\n",
       "      <td>22_vitamin_the_of_and</td>\n",
       "      <td>[vitamin, the, of, and, to, in, production, la...</td>\n",
       "      <td>[Producing FL by Saccharomyces  cerevisiae Fuc...</td>\n",
       "      <td>vitamin - the - of - and - to - in - productio...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.825086</td>\n",
       "      <td>0.825086</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>84d56c08-f62f-4bfd-986c-71a44c1af2ed</td>\n",
       "      <td>Bacman sequestering cadmium into Bacillus spor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_heavy_metal_heavy metal_the</td>\n",
       "      <td>[heavy, metal, heavy metal, the, metals, and, ...</td>\n",
       "      <td>[Nanocrystal Ecoli Flocculation Union Heavy me...</td>\n",
       "      <td>heavy - metal - heavy metal - the - metals - a...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.484021</td>\n",
       "      <td>0.484021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175</td>\n",
       "      <td>8a69e820-ef66-4438-8ed2-08943ab2c6b1</td>\n",
       "      <td>Bacterial Relay Race In our project we aim at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_the_of_to_in</td>\n",
       "      <td>[the, of, to, in, and, we, system, is, as, by]</td>\n",
       "      <td>[Conversensations Developing a TwoWay QuorumSe...</td>\n",
       "      <td>the - of - to - in - and - we - system - is - ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.961273</td>\n",
       "      <td>0.961273</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176</td>\n",
       "      <td>572f8dd4-bb30-4d59-a319-2a5e650cce90</td>\n",
       "      <td>E coli Automatic Directed Evolution Machine a ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9_dna_the_of_to</td>\n",
       "      <td>[dna, the, of, to, and, in, evolution, for, we...</td>\n",
       "      <td>[SciPhi  Enabling orthogonal replication and p...</td>\n",
       "      <td>dna - the - of - to - and - in - evolution - f...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.680135</td>\n",
       "      <td>0.680135</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177</td>\n",
       "      <td>be21c9a1-0aac-4e87-86f5-f6023d374461</td>\n",
       "      <td>BacInVader  a new system for cancer genetic th...</td>\n",
       "      <td>12</td>\n",
       "      <td>12_cancer_tumor_cells_the</td>\n",
       "      <td>[cancer, tumor, cells, the, to, and, of, thera...</td>\n",
       "      <td>[BLAST  Bifidobacterium Longum induced Apoptos...</td>\n",
       "      <td>cancer - tumor - cells - the - to - and - of -...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.727408</td>\n",
       "      <td>0.727408</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UT                                  uuid  \\\n",
       "0  173  791aefbd-0fde-417e-8e1b-2f7210647032   \n",
       "1  174  84d56c08-f62f-4bfd-986c-71a44c1af2ed   \n",
       "2  175  8a69e820-ef66-4438-8ed2-08943ab2c6b1   \n",
       "3  176  572f8dd4-bb30-4d59-a319-2a5e650cce90   \n",
       "4  177  be21c9a1-0aac-4e87-86f5-f6023d374461   \n",
       "\n",
       "                                            Document  Topic  \\\n",
       "0  Ethanol Whey not Cheese whey is classified as ...     22   \n",
       "1  Bacman sequestering cadmium into Bacillus spor...      0   \n",
       "2  Bacterial Relay Race In our project we aim at ...      1   \n",
       "3  E coli Automatic Directed Evolution Machine a ...      9   \n",
       "4  BacInVader  a new system for cancer genetic th...     12   \n",
       "\n",
       "                            Name  \\\n",
       "0          22_vitamin_the_of_and   \n",
       "1  0_heavy_metal_heavy metal_the   \n",
       "2                 1_the_of_to_in   \n",
       "3                9_dna_the_of_to   \n",
       "4      12_cancer_tumor_cells_the   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [vitamin, the, of, and, to, in, production, la...   \n",
       "1  [heavy, metal, heavy metal, the, metals, and, ...   \n",
       "2     [the, of, to, in, and, we, system, is, as, by]   \n",
       "3  [dna, the, of, to, and, in, evolution, for, we...   \n",
       "4  [cancer, tumor, cells, the, to, and, of, thera...   \n",
       "\n",
       "                                 Representative_Docs  \\\n",
       "0  [Producing FL by Saccharomyces  cerevisiae Fuc...   \n",
       "1  [Nanocrystal Ecoli Flocculation Union Heavy me...   \n",
       "2  [Conversensations Developing a TwoWay QuorumSe...   \n",
       "3  [SciPhi  Enabling orthogonal replication and p...   \n",
       "4  [BLAST  Bifidobacterium Longum induced Apoptos...   \n",
       "\n",
       "                                         Top_n_words  Representative_document  \\\n",
       "0  vitamin - the - of - and - to - in - productio...                    False   \n",
       "1  heavy - metal - heavy metal - the - metals - a...                    False   \n",
       "2  the - of - to - in - and - we - system - is - ...                     True   \n",
       "3  dna - the - of - to - and - in - evolution - f...                    False   \n",
       "4  cancer - tumor - cells - the - to - and - of -...                    False   \n",
       "\n",
       "      Score       X_E  X_C  level0  \n",
       "0  0.825086  0.825086   23      23  \n",
       "1  0.484021  0.484021    1       1  \n",
       "2  0.961273  0.961273    2       2  \n",
       "3  0.680135  0.680135   10      10  \n",
       "4  0.727408  0.727408   13      13  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standar format for report analysis\n",
    "dataset_clustering_results = dataset_clustering_results.reset_index(drop=True)\n",
    "dataset_clustering_results = dataset_clustering_results.drop(columns=['text'])\n",
    "dataset_clustering_results['X_E'] = dataset_clustering_results['Score']\n",
    "dataset_clustering_results['X_C'] = dataset_clustering_results['Topic'] + 1\n",
    "\n",
    "\n",
    "\n",
    "# Assign 'level0' based on cluster coverage (90%)\n",
    "cluster_counts = dataset_clustering_results['X_C'].value_counts().sort_values(ascending=False)\n",
    "total_rows = len(dataset_clustering_results)\n",
    "cumulative = cluster_counts.cumsum() / total_rows\n",
    "main_clusters = cluster_counts.index[cumulative <= others_threshold].tolist()\n",
    "dataset_clustering_results['level0'] = dataset_clustering_results['X_C'].apply(lambda x: x if x in main_clusters else 99999)\n",
    "dataset_clustering_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UT</th>\n",
       "      <th>uuid</th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Representative_document</th>\n",
       "      <th>Score</th>\n",
       "      <th>X_E</th>\n",
       "      <th>X_C</th>\n",
       "      <th>level0</th>\n",
       "      <th>cl99</th>\n",
       "      <th>cl-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173</td>\n",
       "      <td>791aefbd-0fde-417e-8e1b-2f7210647032</td>\n",
       "      <td>Ethanol Whey not Cheese whey is classified as ...</td>\n",
       "      <td>22</td>\n",
       "      <td>22_vitamin_the_of_and</td>\n",
       "      <td>[vitamin, the, of, and, to, in, production, la...</td>\n",
       "      <td>[Producing FL by Saccharomyces  cerevisiae Fuc...</td>\n",
       "      <td>vitamin - the - of - and - to - in - productio...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.825086</td>\n",
       "      <td>0.825086</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>84d56c08-f62f-4bfd-986c-71a44c1af2ed</td>\n",
       "      <td>Bacman sequestering cadmium into Bacillus spor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_heavy_metal_heavy metal_the</td>\n",
       "      <td>[heavy, metal, heavy metal, the, metals, and, ...</td>\n",
       "      <td>[Nanocrystal Ecoli Flocculation Union Heavy me...</td>\n",
       "      <td>heavy - metal - heavy metal - the - metals - a...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.484021</td>\n",
       "      <td>0.484021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175</td>\n",
       "      <td>8a69e820-ef66-4438-8ed2-08943ab2c6b1</td>\n",
       "      <td>Bacterial Relay Race In our project we aim at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_the_of_to_in</td>\n",
       "      <td>[the, of, to, in, and, we, system, is, as, by]</td>\n",
       "      <td>[Conversensations Developing a TwoWay QuorumSe...</td>\n",
       "      <td>the - of - to - in - and - we - system - is - ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.961273</td>\n",
       "      <td>0.961273</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176</td>\n",
       "      <td>572f8dd4-bb30-4d59-a319-2a5e650cce90</td>\n",
       "      <td>E coli Automatic Directed Evolution Machine a ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9_dna_the_of_to</td>\n",
       "      <td>[dna, the, of, to, and, in, evolution, for, we...</td>\n",
       "      <td>[SciPhi  Enabling orthogonal replication and p...</td>\n",
       "      <td>dna - the - of - to - and - in - evolution - f...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.680135</td>\n",
       "      <td>0.680135</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177</td>\n",
       "      <td>be21c9a1-0aac-4e87-86f5-f6023d374461</td>\n",
       "      <td>BacInVader  a new system for cancer genetic th...</td>\n",
       "      <td>12</td>\n",
       "      <td>12_cancer_tumor_cells_the</td>\n",
       "      <td>[cancer, tumor, cells, the, to, and, of, thera...</td>\n",
       "      <td>[BLAST  Bifidobacterium Longum induced Apoptos...</td>\n",
       "      <td>cancer - tumor - cells - the - to - and - of -...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.727408</td>\n",
       "      <td>0.727408</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UT                                  uuid  \\\n",
       "0  173  791aefbd-0fde-417e-8e1b-2f7210647032   \n",
       "1  174  84d56c08-f62f-4bfd-986c-71a44c1af2ed   \n",
       "2  175  8a69e820-ef66-4438-8ed2-08943ab2c6b1   \n",
       "3  176  572f8dd4-bb30-4d59-a319-2a5e650cce90   \n",
       "4  177  be21c9a1-0aac-4e87-86f5-f6023d374461   \n",
       "\n",
       "                                            Document  Topic  \\\n",
       "0  Ethanol Whey not Cheese whey is classified as ...     22   \n",
       "1  Bacman sequestering cadmium into Bacillus spor...      0   \n",
       "2  Bacterial Relay Race In our project we aim at ...      1   \n",
       "3  E coli Automatic Directed Evolution Machine a ...      9   \n",
       "4  BacInVader  a new system for cancer genetic th...     12   \n",
       "\n",
       "                            Name  \\\n",
       "0          22_vitamin_the_of_and   \n",
       "1  0_heavy_metal_heavy metal_the   \n",
       "2                 1_the_of_to_in   \n",
       "3                9_dna_the_of_to   \n",
       "4      12_cancer_tumor_cells_the   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [vitamin, the, of, and, to, in, production, la...   \n",
       "1  [heavy, metal, heavy metal, the, metals, and, ...   \n",
       "2     [the, of, to, in, and, we, system, is, as, by]   \n",
       "3  [dna, the, of, to, and, in, evolution, for, we...   \n",
       "4  [cancer, tumor, cells, the, to, and, of, thera...   \n",
       "\n",
       "                                 Representative_Docs  \\\n",
       "0  [Producing FL by Saccharomyces  cerevisiae Fuc...   \n",
       "1  [Nanocrystal Ecoli Flocculation Union Heavy me...   \n",
       "2  [Conversensations Developing a TwoWay QuorumSe...   \n",
       "3  [SciPhi  Enabling orthogonal replication and p...   \n",
       "4  [BLAST  Bifidobacterium Longum induced Apoptos...   \n",
       "\n",
       "                                         Top_n_words  Representative_document  \\\n",
       "0  vitamin - the - of - and - to - in - productio...                    False   \n",
       "1  heavy - metal - heavy metal - the - metals - a...                    False   \n",
       "2  the - of - to - in - and - we - system - is - ...                     True   \n",
       "3  dna - the - of - to - and - in - evolution - f...                    False   \n",
       "4  cancer - tumor - cells - the - to - and - of -...                    False   \n",
       "\n",
       "      Score       X_E  X_C  level0   cl99  cl-99  \n",
       "0  0.825086  0.825086   23      23  False  False  \n",
       "1  0.484021  0.484021    1       1  False  False  \n",
       "2  0.961273  0.961273    2       2  False  False  \n",
       "3  0.680135  0.680135   10      10  False  False  \n",
       "4  0.727408  0.727408   13      13  False  False  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standar format for report analysis\n",
    "dataset_clustering_results['cl99'] = [True if x == 99999 else False for x in dataset_clustering_results['level0']]\n",
    "dataset_clustering_results['cl-99'] = [True if x == 99999 else False for x in dataset_clustering_results['level0']]\n",
    "dataset_clustering_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level0\n",
       "1     177\n",
       "2     127\n",
       "3     120\n",
       "4     117\n",
       "5     101\n",
       "     ... \n",
       "63     23\n",
       "64     22\n",
       "65     22\n",
       "66     20\n",
       "67     19\n",
       "Name: count, Length: 68, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_clustering_results.level0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "eyQDhrjyc6Oh"
   },
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "dataset_clustering_results.to_csv(f'{tm_folder_path}/dataset_minimal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RYcsXanZvrr",
    "outputId": "d625d86f-5897-4d75-8b32-54f2dd258ad3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-04 20:55:17,318 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    }
   ],
   "source": [
    "# Save the topic model\n",
    "topic_model.save(f'{tm_folder_path}/topic_model_object.pck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SX1EBSOY3Pz1"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM4oE6dpT6UwjIg42kzzsWo",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "env-tm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
