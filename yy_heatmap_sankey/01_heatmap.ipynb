{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cristianmejia00/clustering/blob/main/06_heatmap_sankey/01_heatmap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj3lYckpO2Yn"
      },
      "source": [
        "# Heatmap for Topic Modeling with BERTopic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlufmOowbHSF"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFQU-BC5ReYd"
      },
      "source": [
        "## Packages installation and initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ckx8hOIyRZvv",
        "outputId": "dd3c2113-0f65-414c-b1c8-63876ad67bd1"
      },
      "outputs": [],
      "source": [
        "#!pip install bertopic[visualization]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMlZ_7DkOxGG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "from datetime import date\n",
        "import uuid\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "from itertools import compress\n",
        "from bertopic import BERTopic\n",
        "from umap import UMAP\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yyjtq0uBkCx"
      },
      "outputs": [],
      "source": [
        "# Change to the name of the folder in your Google Drive\n",
        "root_folder_name = 'Bibliometrics_Drive'\n",
        "#ROOT_FOLDER_PATH = f\"drive/MyDrive/{root_folder_name}\" # <- Google Colab\n",
        "ROOT_FOLDER_PATH = f\"/Users/cristian/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/{root_folder_name}\" #Mac"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ1BccaqRtS0"
      },
      "source": [
        "## Connect your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6os5BGPFRxfX",
        "outputId": "97ba01a4-0e59-4578-bec9-7ac238f63ec0"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff7hQXE1dYDw"
      },
      "outputs": [],
      "source": [
        "# Function to save object to a pickle file\n",
        "def save_object_as_pickle(obj, filename):\n",
        "  \"\"\"\n",
        "  Saves an object as a pickle file.\n",
        "\n",
        "  Args:\n",
        "      obj: The object to be saved.\n",
        "      filename: The filename of the pickle file.\n",
        "  \"\"\"\n",
        "  with open(filename, \"wb\") as f:\n",
        "    pickle.dump(obj, f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iljQe0_xb2FU"
      },
      "outputs": [],
      "source": [
        "# Function to load pickle object given a path\n",
        "def load_pickle(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        return pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcU4y72SJEUb"
      },
      "outputs": [],
      "source": [
        "def save_heatmap_settings_as_json(heatmap_settings, filename=\"heatmap_settings.json\"):\n",
        "  \"\"\"Saves heatmap settings as a JSON file with pretty indentation.\n",
        "\n",
        "  Args:\n",
        "      heatmap_settings: The heatmap settings dictionary.\n",
        "      filename: The name of the JSON file.\n",
        "  \"\"\"\n",
        "  with open(filename, \"w\") as f:\n",
        "    json.dump(heatmap_settings, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX1EBSOY3Pz1"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FRHMbe93fxj"
      },
      "source": [
        "## PART 3: Merging Topic Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDm5-r5oR98q"
      },
      "source": [
        "# ðŸ”´ Input files and options\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZqze8YlocRW"
      },
      "outputs": [],
      "source": [
        "heatmap_settings = {\n",
        "    'metadata': {\n",
        "      'heatmap_analysis_id': 'H013',\n",
        "      'heatmap_name': 'Brain_Heath_Social_Issues',\n",
        "      'date': '2025-05-07',\n",
        "      'created_by': 'cristianmejia00@gmail.com',\n",
        "      'notes': '',\n",
        "      'input_directory': '',\n",
        "      'output_directory': ''\n",
        "    },\n",
        "    'global': {\n",
        "                'min_cluster_size': 10,\n",
        "                'seed': 100,\n",
        "                'transformer_model': 'all-MiniLM-L6-v2',\n",
        "                'sankey_threshold': 0.8\n",
        "              },\n",
        "    'inputs': [\n",
        "        {\n",
        "            'project_folder_name': 'Q10_brain_health_ts_20250501',\n",
        "            'analysis_folder_name': 'a01_cn__f01_dc__c01_lv',\n",
        "            'level_folder_name': 'level1',\n",
        "            'embeddings_folder_name': 'f01/e01',\n",
        "            'display_name': 'BH_lv1',\n",
        "            'cluster_column': 'Cluster Code',\n",
        "            'heatmap_display_order': 0,\n",
        "            'sankey_display_order': 0,\n",
        "            'color': \"#E9571F\"\n",
        "        },\n",
        "        {\n",
        "            'project_folder_name': 'Q6_wellbeing_ti_20250501',\n",
        "            'analysis_folder_name': 'a01_cn__f01_dc__c01_lv',\n",
        "            'embeddings_folder_name': 'f01/e01',\n",
        "            'level_folder_name': 'level1',\n",
        "            'display_name': 'WB_lv1',\n",
        "            'cluster_column': 'Cluster Code',\n",
        "            'heatmap_display_order': 1,\n",
        "            'sankey_display_order': 1,\n",
        "            'color': '#808080'\n",
        "        },\n",
        "        {\n",
        "            'project_folder_name': 'Q7_qol_ti_20250501',\n",
        "            'analysis_folder_name': 'a01_cn__f01_dc__c01_lv',\n",
        "            'embeddings_folder_name': 'f01/e01',\n",
        "            'level_folder_name': 'level1',\n",
        "            'display_name': 'QoL_lv1',\n",
        "            'cluster_column': 'Cluster Code',\n",
        "            'heatmap_display_order': 2,\n",
        "            'sankey_display_order': 1,\n",
        "            'color': '#89CFF0'\n",
        "        },\n",
        "        {\n",
        "            'project_folder_name': 'Q8_sustainability_ti_20250501',\n",
        "            'analysis_folder_name': 'a01_cn__f01_dc__c01_lv',\n",
        "            'embeddings_folder_name': 'f01/e01',\n",
        "            'level_folder_name': 'level1',\n",
        "            'display_name': 'Sust_lv1',\n",
        "            'cluster_column': 'Cluster Code',\n",
        "            'heatmap_display_order': 3,\n",
        "            'sankey_display_order': 1,\n",
        "            'color': '#F2BA05'\n",
        "        },\n",
        "        {\n",
        "            'project_folder_name': 'Q9_happiness_ti_5y_20250501',\n",
        "            'analysis_folder_name': 'a01_cn__f01_dc__c01_lv',\n",
        "            'embeddings_folder_name': 'f01/e01',\n",
        "            'level_folder_name': 'level1',\n",
        "            'display_name': 'H_lv1',\n",
        "            'cluster_column': 'Cluster Code',\n",
        "            'heatmap_display_order': 4,\n",
        "            'sankey_display_order': 1,\n",
        "            'color': '#66FF00'\n",
        "        }\n",
        "      ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFRS37jwxC7g"
      },
      "outputs": [],
      "source": [
        "# Save settings\n",
        "save_heatmap_settings_as_json(heatmap_settings, filename=f'{ROOT_FOLDER_PATH}/{heatmap_settings[\"metadata\"][\"heatmap_analysis_id\"]}/heatmap_settings_{heatmap_settings[\"metadata\"][\"heatmap_analysis_id\"]}_{heatmap_settings[\"metadata\"][\"heatmap_name\"]}.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f'{ROOT_FOLDER_PATH}/{heatmap_settings[\"metadata\"][\"heatmap_analysis_id\"]}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLZ9CUa8BJgy",
        "outputId": "10349bb8-5786-47ec-a776-c5f696d1f028"
      },
      "outputs": [],
      "source": [
        "heatmap_input_dfs = []\n",
        "for tm in heatmap_settings['inputs']:\n",
        "  document_path = f'{ROOT_FOLDER_PATH}/{tm[\"project_folder_name\"]}/{tm[\"analysis_folder_name\"]}/louvain/0.9/{tm[\"level_folder_name\"]}/article_report.csv'\n",
        "  print(document_path)\n",
        "  input_df = pd.read_csv(document_path,\n",
        "                         usecols=['ID', 'uuid', tm['cluster_column']])\n",
        "  # Each dataset can use different clustering result e.g. X_C, level0, level1, so we need to unify the header name for concatenation\n",
        "  input_df['display_name'] = tm['display_name']\n",
        "  input_df['cluster'] = input_df['display_name'] + \"-\" + input_df[tm['cluster_column']].astype(str)\n",
        "  input_df = input_df.rename(columns={'ID': 'UT'})\n",
        "  input_df = input_df.drop(columns=[tm['cluster_column']])\n",
        "  heatmap_input_dfs.append(input_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "8VSmnzWY420U",
        "outputId": "8149efa3-5dad-461c-a858-0c064bcf05b1"
      },
      "outputs": [],
      "source": [
        "document_info = pd.concat(heatmap_input_dfs).reset_index(drop=True)\n",
        "print(len(document_info))\n",
        "document_info.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJw5Z63p4oke"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz4lwPFzFCbP"
      },
      "source": [
        "## PART 5. Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz_aKvVfFFw7",
        "outputId": "bb1e4765-1b48-4c95-f086-3aa4c722075e"
      },
      "outputs": [],
      "source": [
        "# For firms we know, simply get the embeddings back.\n",
        "embeddings_list = []\n",
        "corpus_list = []\n",
        "for tm in heatmap_settings['inputs']:\n",
        "  print(f\"=================Loading: {tm['project_folder_name']}\")\n",
        "  embeddings = load_pickle(f\"{ROOT_FOLDER_PATH}/{tm['project_folder_name']}/{tm['embeddings_folder_name']}/embeddings.pck\")\n",
        "  if type(embeddings) == dict:\n",
        "    print('Dict type found')\n",
        "    embeddings = embeddings['embeddings']\n",
        "    print(len(embeddings))\n",
        "  corpus_tmp = pd.read_csv(f\"{ROOT_FOLDER_PATH}/{tm['project_folder_name']}/{tm['embeddings_folder_name']}/corpus.csv\")\n",
        "  print(len(corpus_tmp))\n",
        "  \n",
        "  embeddings_list.append(embeddings)\n",
        "  corpus_list.append(corpus_tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus_list[1].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-fp1H0JFFw8"
      },
      "outputs": [],
      "source": [
        "# Combine embeddings\n",
        "embeddings_uploaded = np.vstack(embeddings_list)\n",
        "corpus_uploaded = pd.concat(corpus_list).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQKrqM2JGL0H",
        "outputId": "ef0aad17-d3d1-4b06-b19a-ea6f05a1b487"
      },
      "outputs": [],
      "source": [
        "# Count df lengths\n",
        "print(len(embeddings_uploaded))\n",
        "print(len(corpus_uploaded))\n",
        "print(len(document_info))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxC5w5JId9FT"
      },
      "outputs": [],
      "source": [
        "# prompt: add `embeddings_uploaded` as a column to `corpus_uploaded`\n",
        "corpus_uploaded['embeddings'] = list(embeddings_uploaded)\n",
        "corpus_uploaded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS4grWkSejG6"
      },
      "outputs": [],
      "source": [
        "# Remove rows where 'UT' is duplicated, keeping the first occurrence\n",
        "corpus_uploaded = corpus_uploaded.drop_duplicates(subset=['uuid'], keep='first')\n",
        "corpus_uploaded.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQfGGD18a7sK"
      },
      "outputs": [],
      "source": [
        "# prompt: merge `corpus_uploaded` and `document_info` by column uuid. The merged data frame has as many rows and same sorting as corpus_uploaded. The merged data frame is named `full_corpus`.\n",
        "full_corpus = pd.merge(document_info[['UT', 'uuid', 'cluster']], corpus_uploaded[['uuid', 'text', 'embeddings']], on='uuid', how='left')\n",
        "print(len(full_corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi0cijLJawgh",
        "outputId": "6af2679f-91a4-4ce4-82d1-b1e913d84fde"
      },
      "outputs": [],
      "source": [
        "len(full_corpus) == len(document_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cai5LgWWfaxw"
      },
      "outputs": [],
      "source": [
        "# prompt: Remove all rows in full_corpus where the size of column `embeddings` do not match 384\n",
        "len(embeddings_uploaded[0])\n",
        "\n",
        "# Add a new column 'vector_length' to store the size of the embeddings\n",
        "full_corpus['vector_length'] = full_corpus['embeddings'].apply(lambda x: len(x) if isinstance(x, (list, np.ndarray)) else 0)\n",
        "\n",
        "# Display the first few rows to verify\n",
        "full_corpus.head()\n",
        "\n",
        "#full_corpus = full_corpus[full_corpus['embeddings'].apply(lambda x: len(x) == 384 if isinstance(x, list) or isinstance(x, np.ndarray) else False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_corpus.vector_length.value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMk7pf0Cf_i4",
        "outputId": "4a19ca4a-0b96-4248-8036-2b7415a37b8d"
      },
      "outputs": [],
      "source": [
        "len(full_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwPaSU19cASw"
      },
      "outputs": [],
      "source": [
        "# Remodel the topic model\n",
        "from bertopic.backend import BaseEmbedder\n",
        "from bertopic.cluster import BaseCluster\n",
        "from bertopic.vectorizers import ClassTfidfTransformer\n",
        "from bertopic.dimensionality import BaseDimensionalityReduction\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "4E6UHo-8giGK",
        "outputId": "d609736c-cde2-41a1-ea53-3c8ac39a4a67"
      },
      "outputs": [],
      "source": [
        "# This part is optional when we have datasets with small clusters\n",
        "# cluster_idx_mapping = full_corpus.cluster.value_counts()\n",
        "# #cluster_idx_mapping = cluster_idx_mapping[cluster_idx_mapping >= heatmap_settings['global']['min_cluster_size']]\n",
        "# full_corpus = full_corpus[full_corpus.cluster.isin(cluster_idx_mapping.index.to_list())]\n",
        "# cluster_idx_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTuU330fQUFU"
      },
      "outputs": [],
      "source": [
        "# Form the embbedings\n",
        "my_embeddings = np.vstack(full_corpus['embeddings'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C179UtDfC2zN"
      },
      "outputs": [],
      "source": [
        "# get text and topics\n",
        "docs = full_corpus.text\n",
        "cluster_list = full_corpus.cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCqQzTXIhh5u"
      },
      "outputs": [],
      "source": [
        "#idx_cluster = [cluster_idx_mapping.index.get_loc(i) for i in cluster_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHe0sfXHmQsk",
        "outputId": "c0cb6220-3d24-4d71-8e18-dc10ca52c3ac"
      },
      "outputs": [],
      "source": [
        "len(idx_cluster) == len(docs) == len(my_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr7Y_RmpDPh9"
      },
      "source": [
        "# ðŸŸ¢ðŸŸ¢"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pjB2Pa9bjZM"
      },
      "outputs": [],
      "source": [
        "# Init \"empty\" models\n",
        "embedding_model = SentenceTransformer(heatmap_settings[\"global\"][\"transformer_model\"])\n",
        "empty_dimensionality_model = BaseDimensionalityReduction()\n",
        "empty_cluster_model = BaseCluster()\n",
        "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
        "\n",
        "# Fit BERTopic without actually performing any clustering\n",
        "topic_model= BERTopic(\n",
        "        embedding_model=embedding_model,\n",
        "        umap_model=empty_dimensionality_model,\n",
        "        hdbscan_model=empty_cluster_model,\n",
        "        ctfidf_model=ctfidf_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8AlrWz3Cv2-"
      },
      "outputs": [],
      "source": [
        "topics, probs = topic_model.fit_transform(docs, my_embeddings, y=idx_cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "A5IPOTW_c7bJ",
        "outputId": "48c598d0-be1f-4df2-86ae-4edd8bba445b"
      },
      "outputs": [],
      "source": [
        "tm_summary = topic_model.get_topic_info()\n",
        "tm_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "PR-toKbrt9hx",
        "outputId": "ded63b6e-13f2-4f42-9751-56f4a6be3afb"
      },
      "outputs": [],
      "source": [
        "# Document information. Including the topic assignation\n",
        "test = topic_model.get_document_info(docs, df = full_corpus)\n",
        "test = test[['cluster', 'Name']].drop_duplicates(subset=['cluster'], keep='first')\n",
        "test['short_name'] = test['Name'].str[:7]\n",
        "test['dataset'] = test['cluster'].str.split('-').str[0]\n",
        "print(test.shape)\n",
        "test.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh4J9235wLEi"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "03sfdd-mZ7s0",
        "outputId": "4050b554-02ef-40f4-b74c-876abd12ef3a"
      },
      "outputs": [],
      "source": [
        "# Default\n",
        "# Visualize topic similarity using heatmap (self similarity)\n",
        "hm = topic_model.visualize_heatmap()\n",
        "#hm.write_html(f\"{ROOT_FOLDER_PATH}/heatmap_updated.html\")\n",
        "hm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf7K6pewQ1ru"
      },
      "outputs": [],
      "source": [
        "#pd.DataFrame(hm.data[0]['z'], columns=hm.data[0]['x']).to_csv(f'{ROOT_FOLDER_PATH}/{heatmap_settings[\"metadata\"][\"heatmap_analysis_id\"]}/heatmap_matrix.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s290w4fG1uJO"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVRkRFD31W9e"
      },
      "source": [
        "## coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The code adjusts the similarity matrix to ignore (set to 0) similarities between items that belong to the same dataset. This might be useful in scenarios where intra-dataset similarities are not meaningful or should be excluded from further analysis.\n",
        "label_dataset = []\n",
        "for i, label in enumerate(hm.data[0]['x']):\n",
        "    short_label = label[:7]\n",
        "    label_dataset.append(test[test['short_name'] == short_label]['dataset'].iloc[0])\n",
        "\n",
        "updated_matrix = []\n",
        "for this_line, current_sim_values in enumerate(hm.data[0]['z']):\n",
        "    updated_sim_values = [0 if label_dataset[i] == label_dataset[this_line] else x for i, x in enumerate(current_sim_values)]\n",
        "    updated_matrix.append(updated_sim_values)\n",
        "\n",
        "updated_matrix = np.array(updated_matrix)\n",
        "updated_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XmDKJ6se12Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import umap\n",
        "\n",
        "def reduce_dimensionality(data):\n",
        "    # Create a UMAP object with the desired settings\n",
        "    reducer = umap.UMAP(n_components=2, random_state=heatmap_settings['global']['seed'], metric='cosine', min_dist=0.65, n_neighbors=25, n_epochs=1500, verbose=True)\n",
        "\n",
        "    # Perform dimensionality reduction\n",
        "    reduced_data = reducer.fit_transform(data)\n",
        "\n",
        "    return reduced_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx4hapb0e3ox",
        "outputId": "944b1b99-3930-4d78-bcc5-5aa10c2394a4"
      },
      "outputs": [],
      "source": [
        "# Reduce dimensionality using UMAP\n",
        "reduced_data = reduce_dimensionality(hm.data[0]['z'])\n",
        "#reduced_data = reduce_dimensionality(updated_matrix) \n",
        "# Print the shape of the reduced data\n",
        "print(\"Reduced data shape:\", reduced_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZP1M-kM0fIhH",
        "outputId": "ae17361f-d9f8-4a20-ef92-c26ce2f15ecc"
      },
      "outputs": [],
      "source": [
        "# Here's a dangerous procedure. We are appending the names of the clusters without veryfying the order in the heatmap.\n",
        "dms = pd.DataFrame(reduced_data)\n",
        "dms.columns = ['x', 'y']\n",
        "dms['label'] = tm_summary['Name'] # Here. We need to ensure the order. If the heatmap change the order of the cluster like by applying the heatmap clustered, then this code will fail.\n",
        "dms['cluster'] = dms['label'].map(test.set_index('Name')['cluster'])\n",
        "dms.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CquU5o6pihm"
      },
      "outputs": [],
      "source": [
        "# Save dms\n",
        "dms.to_csv(f'{ROOT_FOLDER_PATH}/{heatmap_settings[\"metadata\"][\"heatmap_analysis_id\"]}/coordinates.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_rxUZVF2LCn"
      },
      "outputs": [],
      "source": [
        "# Save heatmap\n",
        "pd.DataFrame(hm.data[0]['z'], columns=dms[\"cluster\"]).to_csv(f'{ROOT_FOLDER_PATH}/{heatmap_settings[\"metadata\"][\"heatmap_analysis_id\"]}/heatmap_matrix.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dms['dataset'] = dms['cluster'].str.split('_').str[0]\n",
        "dms.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from turtle import color\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a scatter plot with different colors for each dataset\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=dms, x='x', y='y', s=100, hue='dataset', palette='Set1', alpha=0.7)\n",
        "plt.title('Scatter Plot by Dataset')\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "# Add legend\n",
        "plt.legend(title='Dataset', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "# Improve appearance\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.tight_layout()\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tLpfJBI1x63"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKu6IWyh2WW_"
      },
      "source": [
        "## Melted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jG_Dj8Qq0ShV",
        "outputId": "c6dbbcaf-d51c-467b-8dfe-4e4d820f716f"
      },
      "outputs": [],
      "source": [
        "# prompt: `hm_test` is a squared matrix similarity matrix. This is a symmetric matrix so we only consider the lower triangle, without the diagonal.  Let's get the melted form as a data frame with 3 columns `Source`, `Target`, and `Similarity`. Then, sort it from the largest similarity to the lowest. Remove the pairs with value of zero.\n",
        "hm_test = hm.data[0]['z']\n",
        "\n",
        "# Assuming hm_test is your similarity matrix\n",
        "df = pd.DataFrame(hm_test)\n",
        "\n",
        "# Get the lower triangle without the diagonal\n",
        "rows, cols = np.tril_indices(df.shape[0], -1)\n",
        "\n",
        "# Create a DataFrame with Source, Target, and Similarity\n",
        "similarity_df = pd.DataFrame({\n",
        "    'Source': df.columns[rows],\n",
        "    'Target': df.columns[cols],\n",
        "    'Similarity': df.values[rows, cols]\n",
        "})\n",
        "\n",
        "# Remove rows with similarity of zero\n",
        "similarity_df = similarity_df[similarity_df['Similarity'] > 0]\n",
        "\n",
        "# Sort by similarity in descending order\n",
        "similarity_df = similarity_df.sort_values('Similarity', ascending=False)\n",
        "\n",
        "similarity_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTVjyViIM1-U"
      },
      "outputs": [],
      "source": [
        "# prompt: Using dataframe similarity_df: Replace the values of columns Source and Target with the labels from `dms[\"cluster\"]`\n",
        "\n",
        "# Replace Source and Target with labels from dms[\"cluster\"]\n",
        "similarity_df['Source'] = similarity_df['Source'].map(lambda x: dms[\"cluster\"][int(x)]) # Convert x to integer\n",
        "similarity_df['Target'] = similarity_df['Target'].map(lambda x: dms[\"cluster\"][int(x)]) # Convert x to integer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HXuaklWK2Xyo",
        "outputId": "f3cb8435-15bf-4344-a462-f3bada256d06"
      },
      "outputs": [],
      "source": [
        "similarity_df.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqxZbpBZ2xx0"
      },
      "outputs": [],
      "source": [
        "# # prompt: Using dataframe similarity_df: Replace the values of columns Source and Target with the corresponding \"cluster\" in the `dms` data frame. Use the column \"label\" in `dms` to find the matches.\n",
        "\n",
        "# # Assuming you have a dataframe named 'dms' with 'label' and 'cluster' columns\n",
        "\n",
        "# # Create a dictionary mapping 'label' to 'cluster' from the 'dms' dataframe\n",
        "# label_to_cluster = dict(zip(dms['label'], dms['cluster']))\n",
        "\n",
        "# # Replace 'Source' column values with corresponding 'cluster' values\n",
        "# similarity_df['Source'] = similarity_df['Source'].map(label_to_cluster)\n",
        "\n",
        "# # Replace 'Target' column values with corresponding 'cluster' values\n",
        "# similarity_df['Target'] = similarity_df['Target'].map(label_to_cluster)\n",
        "\n",
        "# similarity_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfSDuZ-H3hLV"
      },
      "outputs": [],
      "source": [
        "similarity_df.to_csv(f'{ROOT_FOLDER_PATH}/{heatmap_settings[\"metadata\"][\"heatmap_analysis_id\"]}/heatmap_melted.csv', index = False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPZYLVK4w6Td6m/N/ZC9umh",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env-tm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
