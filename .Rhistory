print(glue('Total selected papers for this cluster: {nrow(cluster_data)}'))
my_texts <- list()
for (i in c(1:min(10,nrow(cluster_data)))) {
my_texts[i] <- glue('##### {cluster_data$text[[i]]}')
}
my_texts <- paste(my_texts, collapse = ' ')
my_texts <- substr(my_texts, 1, (3500 * 4))
# Get the topic of the cluster
print('Get cluster topic')
prompt_desc <- prompt_cluster_description(topic = MAIN_TOPIC,
topic_description = MAIN_TOPIC_DESCRIPTION,
cluster_text = my_texts)
cluster_completed <- FALSE
while(!cluster_completed) {
tmp <- tryCatch({
cluster_description <- ask_gpt(system_prompt = prompt_desc$system,
user_prompt = prompt_desc$user,
temperature = 0.2)
cluster_completed <- TRUE
print(cluster_description)
},
error = function(err){
message(glue('Error getting topic description of cluster {cluster}. Trying again'))
message(err)
})
}
rcs_merged$description[which(rcs_merged$cluster_code == cluster)] <- cluster_description
# Get the name of the cluster
print('Get cluster name')
cluster_completed <- FALSE
while(!cluster_completed) {
tmp <- tryCatch({
prompt <- prompt_cluster_name(topic = MAIN_TOPIC,
topic_description = MAIN_TOPIC_DESCRIPTION,
cluster_description = cluster_description)
cluster_name <- ask_gpt(system_prompt = prompt$system,
user_prompt = prompt$user,
max_tokens = 60,
temperature = 0.3)
cluster_completed <- TRUE
print(cluster_name)
},
error = function(err){
message(glue('Error getting topic name of cluster {cluster}. Trying again'))
message(err)
})
}
rcs_merged$name[which(rcs_merged$cluster_code == cluster)] <- cluster_name
}
save.image(file='env20240930imcompletellm.RData')
list_of_clusters <- dataset$X_C %>% unique() %>% sort()
# We do this to keep copy of the edits in case we mess it.
rcs_merged$name2 <- gsub('^.*?"','',rcs_merged$name) %>% gsub('".$','', .) %>% gsub('"','', .)
rcs_merged$cluster_name <- rcs_merged$name2
rcs_merged$detailed_description <- rcs_merged$description
for (cluster in list_of_clusters) {
print('=================================================================')
print(glue('cluster: {cluster}'))
# Get the topic of the cluster
print('Get enhanced description')
cluster_completed <- FALSE
while(!cluster_completed) {
tmp <- tryCatch({
prompt_enh <- prompt_cluster_description_enhanced(topic = MAIN_TOPIC,
cluster_description = rcs_merged$detailed_description[rcs_merged$cluster_code == cluster])
print(prompt_enh$user)
cluster_description <- ask_claude(system_prompt = prompt_enh$system,
user_prompt = prompt_enh$user,
model = 'claude-3-opus-20240229',
temperature = 0.1)
print(cluster_description)
cluster_completed <- TRUE
},
error = function(err){
message(glue('Error getting topic enhanced description of cluster {cluster}. Trying again'))
message(err)
})
}
rcs_merged$description[which(rcs_merged$cluster_code == cluster)] <- cluster_description
}
# Save
write.csv(rcs_merged,
file.path(output_folder_level, "rcs_merged_llm__.csv"),
row.names = FALSE)
# Save
write.csv(rcs_merged,
file.path(output_folder_level, file="rcs_merged_llm__.csv"),
row.names = FALSE)
# Save
write.csv(rcs_merged,
file.path(file="rcs_merged_llm__.csv"),
row.names = FALSE)
save.image(file = "env20240930_llm_completed")
load("~/03-bibliometrics/Q302 human augmentation (core)/001/level0/environ.rdata")
# 20230717
library(glue)
# The topic used to infer the query
MAIN_TOPIC <- 'Human Augmentation and human enhancement'
# It means that you know about ...
MAIN_TOPIC_DESCRIPTION <- "Human augmentation, or human enhancement, refers to the use of technology or scientific methods to improve human abilities beyond natural limits. This includes physical enhancements like exoskeletons or gene therapy, cognitive boosts through brain-computer interfaces or nootropics, and sensory improvements via devices like augmented reality glasses or cochlear implants. It also covers efforts to extend healthspan and longevity through medical interventions. While promising for improving life and performance, it raises ethical concerns around fairness, accessibility, and societal impacts."
###################################
###################################
# Article summary
###################################
prompt_summarize_a_paper <- function(topic, topic_description, article_text){
list('system' = glue('You are a researcher with a great record of publications and that understands what good academic writing is.
Your writing style is that of authors in reputable journals like Nature or Science.
Your answers are concise and avoid adverbs.
Your research of expertice is on <<{topic}>>, meaning that you know about {topic_description}'),
'user' = glue('Be sure that your summary is shorter than the text provided. Summarize in one sentence of less than 50 words, and focussing on "{topic}" the following text: {article_text}'))
}
###################################
###################################
# Cluster description
###################################
prompt_cluster_description <- function(topic, topic_description, cluster_text) {
list('system' = glue('You are a policy consultant with expertise on <<{topic}>>, meaning that you know about {topic_description}
You will be given multiple texts (a.k.a cluster) separated by #####. Your task is to read the texts and find their common topic. Ideally, the common topic should be framed in the context of <<{topic}>>.
To find the topic name you will follow the next steps:
Step 1: You understand the main topic of each text
Step 2: You find common keywords across the texts relevant to <<{topic}>>
Step 3: You summarize all the text in a single paragraph taking into consideration the common keywords and themes.
Step 4: You conclude by giving a name for the common topic shared by the articles.
Your answers are concise.'),
'user' = glue('What is the main topic of the following cluster: {cluster_text}'))
}
###################################
###################################
# Cluster description enhanced
###################################
prompt_cluster_description_enhanced <- function(topic, cluster_description) {
list('system' = glue('Please synthesize the following text in a single cohesive paragraph. Do not mention the texts one by one, but in an integrated and coherent manner. Do not use the word "delve" and do not define <<{topic}>> because the reader already know their meaning'),
'user' = glue('Please synthesize what this cluster is about: {cluster_description}'))
}
###################################
###################################
# Cluster name
###################################
prompt_cluster_name <- function(topic, topic_description, cluster_description) {
list('system' = glue('You are a policy consultant with expertise on <<{topic}>>, meaning that you know about {topic_description}
You will be given the decription of a cluster of documents.
Either extract the cluster name given in the description, or give a short name based on what you read.
Your answers are concise and include only the name of the cluster without any further explanation or introduction.'),
'user' = glue('What is the name of the following cluster?: {cluster_description}'))
}
###################################
###################################
# Cluster figure caption
###################################
prompt_figure_caption <- function(topic){
list('system' = 'You are a researcher with a great record of publications and that understands what good academic writing is.
Your writing style is that of authors in reputable journals like Nature or Science.
Your answers are concise.',
'user' = 'Please provide some bullet points with good practices for figure captions based on standard practices in scientific writing.',
'assistant' = "I can provide some general guidelines for writing figure captions based on standard practices in scientific writing:
1. **Caption Length:** Keep the caption concise but descriptive enough to understand the figure without reading the main text. Typically, a few sentences should be sufficient.
2. **Start with a Title:** The caption should start with a brief title that explains what the figure is about.
3. **Description:** After the title, you should provide a detailed explanation of what the figure is displaying. Include necessary details such as the experiment's conditions, what each part of the figure indicates (e.g., axes of graphs), and the significance of the results.
4. **Avoid Redundancy:** The caption should not just repeat information that's already in the text. Instead, it should complement the text and provide extra information to help readers understand the figure.
5. **Key Details:** Any symbols, abbreviations, and units of measurement used in the figure should be clearly defined in the caption.
6. **Statistical Information:** If your figure includes any statistical data, make sure to include information about the statistical tests used, the number of observations, and any relevant significance values.
7. **Avoid Interpretation:** Try not to include any conclusions or interpretations in the figure caption. The role of the caption is to describe, while interpretation of the data should be left for the main body of the text.
8. **Referencing the Figure:** When you refer to the figure in your text, make sure to use the same terminology as in the caption. For example, if your caption refers to panels A, B, and C, your text should use the same terms.
9. **Readability:** Make sure your caption is easily understandable and accessible to the readership of the journal. Avoid overly technical jargon where possible and consider the background knowledge of your audience.
10. **Proofread:** Finally, make sure to proofread your caption carefully. Errors in your caption can confuse readers and potentially undermine the credibility of your work.",
'user' = glue("Please write concisely a figure caption explaining the following:
-	The figure represents the citation network of {topic}
-	Each cluster is represented with different colors.
-	Clusters are labeled from the largest by the number of documents.
-	Clusters that are near each other tend to be topically related and those apart are topically divergent.")
)
}
###################################
###################################
# Cluster {SENTIMENT} description
# POSITIVE or NEGATIVE
###################################
prompt_cluster_sentiment_description <- function(topic, topic_description, sentiment, cluster_text) {
list(
list(
'role' = 'system',
'content' = 'You are a policy consultant with expertise on <<{topic}>>, meaning that you know about {topic_description}
You will be given multiple texts (a.k.a cluster) separated by #####.
These are {sentiment} news about <<{topic}>>
Your task is to read the texts and find their common topic. Ideally, the common topic should be framed in the context of <<{topic}>>.
To analyze the cluster you will follow these steps:
Step 1: You understand the main topic of each text highlighting their {sentiment} connotation or impact if any.
Step 2: You find common keywords across the texts relevant to <<{topic}>>
Step 3: You explain why all these news are considered to be {sentiment}
Step 4: You summarize all the text in a single paragraph taking into consideration the common keywords and themes.
Your response must not show the steps. Instead, you reply with a paragraph  synthesizing your analysis emphasizing why this cluster is {sentiment}.
'
),
list(
'role' = 'user',
'content' = glue('What is the main topic of the following cluster: {cluster_text}')
)
)
}
##########################################################
# Load libraries
source("04_utils/02_libraries.R")
##########################################################
##########################################################
##########################################################
library(httr)
library(jsonlite)
claude_api_key = readr::read_file(file.path('05_assets', 'credentials', 'claude.key'))
#' @description
#' Get answers from OpenAI's GPT. Here used for ARTICLE summarization.
#' @param prompt LIST. A prompt in the format of OpenAI. See the code `zz-prompts.R` for details.
#' @param model STRING {gpt-3.5-turbo-0613} the OpenAI Moodel to use. Options: gpt-3.5-turbo-0613, gpt-4, 'gpt-4-0613'
#' @param temperature NUMBER. Between 0 and 2. 0 means less randomness and 2 more creative.
#' @param max_tokens INTEGER. The approx MAX size possible for the reply from ChatGPT.
#' @param n INTEGER. Number of reply variations to get.
#' @returns The JSON reply from OpenAI in R's LIST form. The actual reply text is located at `x$choices[[1]]$message$content`
ask_claude <- function(system_prompt,
user_prompt,
api_key = claude_api_key,
model = 'claude-3-sonnet-20240229',#'claude-3-opus-20240229',
temperature = 0.1,
max_tokens = 500) {
# Set up API endpoint and headers
api_url <- "https://api.anthropic.com/v1/messages"
headers <- c(
"anthropic-version" = "2023-06-01",
"content-type" = "application/json",
"x-api-key" = api_key
)
# Set up the request payload
payload <- list(
system = system_prompt,
model = model,
temperature = temperature,
max_tokens = max_tokens,
messages = list(
list(
'role' = 'user',
'content' = user_prompt
)
)
)
# Send the API request
response <- httr::POST(
url = api_url,
add_headers(headers),
body = toJSON(payload, auto_unbox = TRUE)
)
# Check the response status
if (response$status_code == 200) {
# Parse the JSON response
result <- fromJSON(httr::content(response,
as = "text",
encoding = "UTF-8"))
# Extract and print the assistant's response
assistant_response <- result$content$text
return(assistant_response)
} else {
return(paste("Error:", response$status_code))
}
}
##########################################################
##########################################################
##########################################################
# Libraries
library(reticulate)
library(glue)
# Activate enviroment
reticulate::use_condaenv('openai_env')
# Attach key.
# In VSCode create a file `openai.key`
# Is only one line with the OpenAi key.
# `credentials/openai.key` was added to .gitignore so is not committed to the repo.
# import Openai Python library
openai <- reticulate::import('openai')
client = openai$OpenAI(api_key = readr::read_file('05_assets/credentials/openai.key'))
# utils
#' @description
#' Get answers from OpenAI's GPT. Here used for ARTICLE summarization.
#' @param prompt LIST. A prompt in the format of OpenAI. See the code `zz-prompts.R` for details.
#' @param model STRING {gpt-3.5-turbo-0613} the OpenAI Moodel to use. Options: gpt-3.5-turbo-0613, gpt-4, 'gpt-4-0613'
#' @param temperature NUMBER. Between 0 and 2. 0 means less randomness and 2 more creative.
#' @param max_tokens INTEGER. The approx MAX size possible for the reply from ChatGPT.
#' @param n INTEGER. Number of reply variations to get.
#' @returns The JSON reply from OpenAI in R's LIST form. The actual reply text is located at `x$choices[[1]]$message$content`
ask_gpt <- function(system_prompt,
user_prompt,
model = 'gpt-3.5-turbo',
temperature = 0.1,
max_tokens = 500,
n = 1) {
response <- client$chat$completions$create(model = model,
temperature = temperature,
max_tokens = as.integer(max_tokens),
n = as.integer(n),
messages = list(
list(
'role' = 'system',
'content' = system_prompt
),
list(
'role' = 'user',
'content' = user_prompt
)
)
)
return(response$choices[[1]]$message$content)
}
#' @description
#' Function to get a subset of the cluster containing the combination of
#' top 5 most linked (X_E), most cited (Z9), and Most linked of the most recent
#' @param dataset DATAFRAME. the dataset
#' @param cluster INTEGER. the cluster number to subset. Compatible with X_C, meaning sypport for cluster 99.
#' @returns DATAFRAME. The largest possible is of `top * 3` when all 3 conditions are different
get_cluster_data <- function(dataset_, cluster_, top = 5) {
cluster_data <- dataset_ %>% filter(X_C == cluster_) %>% select(all_of(c('X_C','TI','AB','AU','PY','UT','Z9','X_E', 'summary')))
print(cluster_data$X_C)
if (nrow(cluster_data) > top) {
selected_papers <- c(
# Most connected
cluster_data$UT[order(cluster_data$X_E, decreasing = TRUE)][1:top],
# Most cited
cluster_data$UT[order(cluster_data$Z9, decreasing = TRUE)][1:top],
# Newest most connected (X_E is preferred over Z9 because most of paper wont have citations)
cluster_data$UT[order(cluster_data$PY, cluster_data$X_E, decreasing = TRUE)][1:top]
) %>% unique()
# Only retain selected papers
cluster_data <- cluster_data[cluster_data$UT %in% selected_papers,]
}
cluster_data$text <- paste(cluster_data$TI, cluster_data$AB, sep = ' ')
return(cluster_data)
}
#' @description
#' AskGPT to summarize each article in the given dataset. Each summary is appended to column `summary`
#' @param dataset DATAFRAME. the dataset
#' @returns DATAFRAME. the same dataset with the column summary appended.
get_papers_summary <- function(cl_dataset) {
#cl_dataset$summary <- ''
starting <- 1
ending <- nrow(cl_dataset)
while(starting < ending) {
for(idx in c(starting:ending)) {
print(paste(cl_dataset$X_C[idx], as.character(idx), cl_dataset$TI[idx], sep = "; "))
article_summary <- tryCatch({
if (nchar(cl_dataset$summary[idx]) == 0) {
prompt_summary <- prompt_summarize_a_paper(topic = MAIN_TOPIC,
topic_description = MAIN_TOPIC_DESCRIPTION,
article_text = cl_dataset$text[idx])
article_summary <- ask_claude(system_prompt = prompt_summary$system,
user_prompt = prompt_summary$user,
temperature = 0.7)
cl_dataset$summary[idx] <- article_summary
}
},
error = function(err){
message(glue('error found in {idx}'))
message(err)
},
finally = {
starting <- idx
Sys.sleep(5)
})
}
#starting <- idx
}
return(cl_dataset)
}
# Using OpenAI and Claude in R.
source("zz-llm_v2_0_prompts.R")
source("zz-llm_v2_1_functions.R")
###################################
###################################
# Initialize
###################################
#rcs_merged <- rcs
rcs_merged$description <- ''
rcs_merged$name <- ''
dataset$summary <- ''
###################################
###################################
# Article summary
###################################
# The oldest article(s) in the dataset.
# When there are many "old papers" we analyze only the two most cited.
oldest_year <- min(dataset$PY, na.rm = TRUE)
oldest_data <- subset(dataset, PY <= oldest_year)#subset(dataset, PY == oldest_year)
if (nrow(oldest_data) > 2) {
oldest_data <- oldest_data[order(oldest_data$Z9, decreasing = FALSE)[c(1:2)],]
}
oldest_data$summary <- ''
for (i in nrow(oldest_data)) {
old_UT <- oldest_data$UT[i]
prompt_old <- prompt_summarize_a_paper(topic = MAIN_TOPIC,
topic_description = MAIN_TOPIC_DESCRIPTION,
article_text = paste(oldest_data$TI[i], oldest_data$AB[i], sep = ' '))
old_summary <- ask_claude(system_prompt = prompt_old$system,
user_prompt = prompt_old$user)
oldest_data$summary[i] <- old_summary
dataset$summary[which(dataset$UT == old_UT)] <- old_summary
}
# Start where the loop was interrupted
dataset$X_C_backup <- dataset$X_C
View(dataset)
View(dataset)
dataset$X_C <- dataset$level0
list_of_clusters <- dataset$X_C %>% unique() %>% sort()
list_of_clusters <- list_of_clusters[5:length(list_of_clusters)]
list_of_clusters <- dataset$X_C %>% unique() %>% sort()
# Compute summaries
COMPUTE_SUMMARIES = TRUE
for (cluster in list_of_clusters) {
if (COMPUTE_SUMMARIES) {
# Get this cluster tops
print('=================================================================')
print(glue('cluster: {cluster}'))
cluster_data <- get_cluster_data(dataset, cluster_ = cluster, top = 3)
print(cluster_data$X_C)
# Summarize each of the selected papers
cluster_data <- get_papers_summary(cluster_data)
# Assign the summaries to the main dataset
print('asign summaries to main dataset')
dataset$summary[match(cluster_data$UT, dataset$UT)] <- cluster_data$summary
} else {
cluster_data <- dataset %>% filter(X_C == cluster, summary != '')
cluster_data$text <- paste(cluster_data$TI, cluster_data$AB, sep = ' ')
}
# Generate the bulk text
print('get bulk text')
print(glue('Total selected papers for this cluster: {nrow(cluster_data)}'))
my_texts <- list()
for (i in c(1:min(10,nrow(cluster_data)))) {
my_texts[i] <- glue('##### {cluster_data$text[[i]]}')
}
my_texts <- paste(my_texts, collapse = ' ')
my_texts <- substr(my_texts, 1, (3500 * 4))
# Get the topic of the cluster
print('Get cluster topic')
prompt_desc <- prompt_cluster_description(topic = MAIN_TOPIC,
topic_description = MAIN_TOPIC_DESCRIPTION,
cluster_text = my_texts)
cluster_completed <- FALSE
while(!cluster_completed) {
tmp <- tryCatch({
cluster_description <- ask_gpt(system_prompt = prompt_desc$system,
user_prompt = prompt_desc$user,
temperature = 0.2)
cluster_completed <- TRUE
print(cluster_description)
},
error = function(err){
message(glue('Error getting topic description of cluster {cluster}. Trying again'))
message(err)
})
}
rcs_merged$description[which(rcs_merged$cluster_code == cluster)] <- cluster_description
# Get the name of the cluster
print('Get cluster name')
cluster_completed <- FALSE
while(!cluster_completed) {
tmp <- tryCatch({
prompt <- prompt_cluster_name(topic = MAIN_TOPIC,
topic_description = MAIN_TOPIC_DESCRIPTION,
cluster_description = cluster_description)
cluster_name <- ask_gpt(system_prompt = prompt$system,
user_prompt = prompt$user,
max_tokens = 60,
temperature = 0.3)
cluster_completed <- TRUE
print(cluster_name)
},
error = function(err){
message(glue('Error getting topic name of cluster {cluster}. Trying again'))
message(err)
})
}
rcs_merged$name[which(rcs_merged$cluster_code == cluster)] <- cluster_name
}
View(rcs_merged)
# We do this to keep copy of the edits in case we mess it.
rcs_merged$name2 <- gsub('^.*?"','',rcs_merged$name) %>% gsub('".$','', .) %>% gsub('"','', .)
rcs_merged$cluster_name <- rcs_merged$name2
rcs_merged$detailed_description <- rcs_merged$description
for (cluster in list_of_clusters) {
print('=================================================================')
print(glue('cluster: {cluster}'))
# Get the topic of the cluster
print('Get enhanced description')
cluster_completed <- FALSE
while(!cluster_completed) {
tmp <- tryCatch({
prompt_enh <- prompt_cluster_description_enhanced(topic = MAIN_TOPIC,
cluster_description = rcs_merged$detailed_description[rcs_merged$cluster_code == cluster])
print(prompt_enh$user)
cluster_description <- ask_claude(system_prompt = prompt_enh$system,
user_prompt = prompt_enh$user,
model = 'claude-3-opus-20240229',
temperature = 0.1)
print(cluster_description)
cluster_completed <- TRUE
},
error = function(err){
message(glue('Error getting topic enhanced description of cluster {cluster}. Trying again'))
message(err)
})
}
rcs_merged$description[which(rcs_merged$cluster_code == cluster)] <- cluster_description
}
# Save
write.csv(rcs_merged,
file.path(file="rcs_merged_core_llm__.csv"),
row.names = FALSE)
save.image(file = "env20240930_core_llm_completed")
