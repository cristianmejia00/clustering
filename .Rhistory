rm(list = ls())
##########################################################
# Select root directory
# It should be the directory where this code (00_general_parameters.R) is placed.
# setwd("/var/container/MAIN TOPIC-CLUSTERING") #Linux
# setwd(choose.dir()) #Windows
getwd()
##########################################################
# Load libraries
source("04_utils/02_libraries.R")
# Load settings from the project we are interested in
# source(file.choose())
source("settings.R")
##########################################################
# Output Folder
output_folder_reports <- file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder)
dir.create(output_folder_reports)
##########################################################
# Load data
load(file.path(
settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"dataset_clustering.rdata"
))
##########################################################
# Verify the data is correctly formatted for reports
source(file.path(getwd(), "04_utils", "00_verify_data.R"))
dataset$X_E <- dataset$Z9
dataset$X_E[is.na(dataset$X_E)] <- 0
zz_env <- list('x01' = ls())
# Reporting clusters
source(file.path(getwd(), "02_citation_network", "01_execute_and_reports.R"))
table(dataset$X_C)
table(myDataCorrect$X_C)
table(myDataCorrect$level0)
table(myDataCorrect_SAMPLE$X_C)
# Dataset merged RCS
source(file.path(getwd(), "03_reports", "15_rcs_merged.R"))
# Save code snapshot
files_to_save <- list.files(getwd(), full.names = TRUE, recursive = TRUE)
files_to_omit <- list.files(file.path(getwd(),'renv','library'), full.names = TRUE, recursive = TRUE)
files_to_save <- setdiff(files_to_save, files_to_omit)
# Not to zip Rdata environments as they are heavy and saved separately
files_to_save <- files_to_save[!grepl('rdata$', tolower(files_to_save))]
# Zip them. This needs Rtools to work
zip(zipfile = file.path(output_folder_level, 'source_code'),
files = files_to_save)
# Save readable settings
writeLines(RJSONIO::toJSON(settings, pretty=TRUE, auto_unbox=TRUE),
file.path(output_folder_level, "settings.json"))
# Save settings object
save(settings, file = file.path(output_folder_level, "settings.rdata"))
# Save package list
session_info <- sessionInfo()
save(session_info, file = file.path(output_folder_level, "sessionInfo.rdata"))
writeLines(capture.output(sessionInfo()), file.path(output_folder_level, "sessionInfo.txt"))
# Save Global environment
save.image(file.path(output_folder_level, "environ_zz_reports.rdata"))
# Save cluster IDS
if ('fukan_original_cluster_id' %in% colnames(dataset)) {
print('Saving cluster id comparison for subclusters')
cluster_comparison <- dataset[c('X_C', 'fukan_X_C', 'fukan_original_cluster_id', 'fukan_subcluster_label')]
cluster_comparison <- cluster_comparison[!duplicated(cluster_comparison$fukan_subcluster_label),]
cluster_comparison <- cluster_comparison[order(cluster_comparison$fukan_X_C),]
write.csv(cluster_comparison, file = file.path(output_folder_level, "cluster_id_comparison.csv"), row.names = FALSE)
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents != 0) {
article_report_20 <- article_report %>%
group_by(X_C) %>%
top_n(settings$rp$top_documents, settings$rp$column_labels['X_E'])
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(X_C) %>%
top_n(settings$rp$top_documents, settings$rp$column_labels['X_E'])
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(settings$rp$column_labels['X_C']) %>%
top_n(settings$rp$top_documents, settings$rp$column_labels['X_E'])
}
settings$rp$column_labels['X_C']
settings$rp$column_labels['X_E']
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(settings$rp$top_documents, Degree)
}
View(article_report)
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(20, Degree)
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(20, settings$rp$column_labels['X_E'])
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(20, settings$rp$column_labels['X_E'])
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(20, Degree)
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(30, Degree)
}
# Write the article report
write.csv(article_report_20,
file = gsub('_report', '_report_20', rn$PROJECTarticlereport),
row.names = FALSE)
###########################################################################################
# OPTIONS
###########################################################################################
## Select the input folders:
dataset_folder <- choose.dir()
## Query_id
## This has de form Qxxx whith the query number from the query control file
dataset_metadata <- list("query_id" = "Q282tm_all_years",
"fukan_url" = "https://academic-landscape.com/dataset/48254")
###########################################################################################
# RUN FROM HERE
###########################################################################################
## Libraries
source("04_utils/02_libraries.R")
source(file.path(getwd(), "04_utils", "read_from_fukan_function.R"))
## Path to `/inputs`
# Here 'input' refer to the inputs for clustering.
# From the pov of this very code, this is actually the output folder. Where the files generated by this code will be placed.
bibliometrics_folder <- "C:\\Users\\crist\\OneDrive\\Documentos\\03-bibliometrics"
## Read files
dataset <- read_from_fukan_2(dataset_folder)
orphans <- read_from_fukan_2(dataset_folder, what = "orphans")
# Verify clusters are ordered from the largest
table(dataset$X_C)
## Create directories
dir.create(file.path(bibliometrics_folder, dataset_metadata$query_id), showWarnings = FALSE)
save(dataset,orphans,dataset_metadata,
file = file.path(bibliometrics_folder, dataset_metadata$query_id, "dataset.rdata"))
## Clear environment
if (file.exists(file.path(bibliometrics_folder, dataset_metadata$query_id, "dataset.rdata"))) {
#rm(list = (setdiff(ls(), c("dataset", "orphans", "network", "dataset_metadata"))))
rm(list = (ls()))
}
##########################################################
# Select root directory
# It should be the directory where this code is placed.
# setwd("/var/container/MAIN TOPIC-CLUSTERING") #Linux
# setwd(choose.dir()) #Windows
getwd()
##########################################################
# Load libraries
source("04_utils/02_libraries.R")
# Load input settings file
source("settings.R")
# Load data
load(file.path(
settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
"dataset.rdata"
))
##########################################################
# Document classification (Get clusters or Get topics)
if (settings$params$type_of_analysis == "citation_network") {
source(file.path(getwd(), "02_citation_network", "00_citation_network_clustering.R"))
}
##########################################################
# Document classification (Get clusters or Get topics)
if (settings$params$type_of_analysis == "citation_network") {
source(file.path(getwd(), "02_citation_network", "00_citation_network_clustering.R"))
}
########################################################################################
# LEVEL 0 ##############################################################################
# Assign fukan clusters to nodes
cl_threshold <- cl_selector(dataset_minimal$X_C, threshold = settings$cno$threshold, size_lower_limit = settings$cno$size_lower_limit, max_cluster = settings$cno$max_clusters)
dataset_minimal$level0 <- unifyer(dataset_minimal$X_C, cl_threshold)
dataset_minimal$X_C
new_clusters <- sapply(dataset_minimal$X_C, function(x) {
if (x > 352) {
99
} else {
(x)
}
})
table(is.na(dataset_minimal$X_C))
table(is.na(dataset$X_C))
##########################################################
# Check all documents have a cluster assigned
if (any(is.na(dataset$X_C))) {
print('CRITICAL: At least one document is missing cluster assignation!')
print('Those papers are removed')
dataset <- dataset[!is.na(dataset$X_C),]
}
##########################################################
# Document classification (Get clusters or Get topics)
if (settings$params$type_of_analysis == "citation_network") {
source(file.path(getwd(), "02_citation_network", "00_citation_network_clustering.R"))
}
if (settings$params$type_of_analysis == "topic_model") {
source(file.path(getwd(), "02_topic_model", "00_topic_model_clustering.R"))
}
# Create stats folder
dir.create(file.path(
settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder
))
source(file.path(getwd(), "03_reports", "03_general_summary.R"))
# Orphans treatment
if (settings$addons$include_orphans == "99" | settings$addons$include_orphans == "999") {
source(file.path(getwd(), "04_utils", "zz-append_orphans.R"))
}
# Add-ons
if (settings$params$type_of_analysis == "citation_network" &
exists('g1') &
(settings$addons$page_rank | settings$addons$eigen_centrality | settings$addons$closeness_centrality | settings$addons$betweeness_centrality)) {
source(file.path(getwd(), "04_utils", "zz-centrality_meassures.R"))
}
##########################################################
# save objects
if (settings$params$type_of_analysis == "topic_model") {
dataset <- myDataCorrect
}
if (settings$params$type_of_analysis == "citation_network") {
dataset <- merge(dataset, dataset_minimal[, c("X_N", "level0")])
setnames(dataset, "X_C", "fukan_X_C")
setnames(dataset, "level0", "X_C")
}
save(dataset, file = file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"dataset_clustering.rdata"))
save.image(file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"environ_clustering.rdata"))
rm(list = ls())
##########################################################
# Select root directory
# It should be the directory where this code (00_general_parameters.R) is placed.
# setwd("/var/container/MAIN TOPIC-CLUSTERING") #Linux
# setwd(choose.dir()) #Windows
getwd()
##########################################################
# Load libraries
source("04_utils/02_libraries.R")
# Load settings from the project we are interested in
# source(file.choose())
source("settings.R")
##########################################################
# Output Folder
output_folder_reports <- file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder)
dir.create(output_folder_reports)
##########################################################
# Load data
load(file.path(
settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"dataset_clustering.rdata"
))
##########################################################
# Verify the data is correctly formatted for reports
source(file.path(getwd(), "04_utils", "00_verify_data.R"))
dataset$X_E <- dataset$Z9
dataset$X_E[is.na(dataset$X_E)] <- 0
zz_env <- list('x01' = ls())
# Reporting clusters
source(file.path(getwd(), "02_citation_network", "01_execute_and_reports.R"))
# Dataset merged RCS
source(file.path(getwd(), "03_reports", "15_rcs_merged.R"))
# Save code snapshot
files_to_save <- list.files(getwd(), full.names = TRUE, recursive = TRUE)
files_to_omit <- list.files(file.path(getwd(),'renv','library'), full.names = TRUE, recursive = TRUE)
files_to_save <- setdiff(files_to_save, files_to_omit)
# Not to zip Rdata environments as they are heavy and saved separately
files_to_save <- files_to_save[!grepl('rdata$', tolower(files_to_save))]
# Zip them. This needs Rtools to work
zip(zipfile = file.path(output_folder_level, 'source_code'),
files = files_to_save)
# Save readable settings
writeLines(RJSONIO::toJSON(settings, pretty=TRUE, auto_unbox=TRUE),
file.path(output_folder_level, "settings.json"))
# Save settings object
save(settings, file = file.path(output_folder_level, "settings.rdata"))
# Save package list
session_info <- sessionInfo()
save(session_info, file = file.path(output_folder_level, "sessionInfo.rdata"))
writeLines(capture.output(sessionInfo()), file.path(output_folder_level, "sessionInfo.txt"))
# Save Global environment
save.image(file.path(output_folder_level, "environ_zz_reports.rdata"))
# Save cluster IDS
if ('fukan_original_cluster_id' %in% colnames(dataset)) {
print('Saving cluster id comparison for subclusters')
cluster_comparison <- dataset[c('X_C', 'fukan_X_C', 'fukan_original_cluster_id', 'fukan_subcluster_label')]
cluster_comparison <- cluster_comparison[!duplicated(cluster_comparison$fukan_subcluster_label),]
cluster_comparison <- cluster_comparison[order(cluster_comparison$fukan_X_C),]
write.csv(cluster_comparison, file = file.path(output_folder_level, "cluster_id_comparison.csv"), row.names = FALSE)
}
load("~/03-bibliometrics/Q286/001/level1/environ.rdata")
table(dataset$fukan_X_C, dataset$X_C)
tmp_text <- paste(tolower(dataset$TI),
tolower(dataset$AB),
tolower(dataset$DE),
tolower(dataset$ID),
sep = ' ')
count_patent <- str_count(tmp_text, "patent")
##########################################################
# Load libraries
source("04_utils/02_libraries.R")
# Load settings from the project we are interested in
# source(file.choose())
source("settings.R")
count_patent <- str_count(tmp_text, "patent")
count_patent1 <- str_count(tmp_text, "patent-1")
count_patent2 <- str_count(tmp_text, "patent-2")
count_patent3 <- str_count(tmp_text, "patent plus")
count_patent4 <- str_count(tmp_text, "pulmonary arterial hypertension")
test <- grepl("patent-1", tmp_text)
test <- dataset[grepl("patent-1", tmp_text),]
View(test)
test <- dataset[grepl("patent-1", tmp_text),]
test <- dataset[grepl("patent-2", tmp_text),]
test <- dataset[grepl("patent plus", tmp_text),]
test <- dataset[grepl("pulmonary arterial hypertension", tmp_text),]
test <- dataset[grepl("patent-2", tmp_text),]
View(test)
test <- dataset[grepl("patent-1", tmp_text),"UT"]
banned <- unique(c(test1,test2,test3,test4))
test1 <- dataset[grepl("patent-1", tmp_text),"UT"]
test2 <- dataset[grepl("patent-2", tmp_text),"UT"]
test3 <- dataset[grepl("patent plus", tmp_text),"UT"]
test4 <- dataset[grepl("pulmonary arterial hypertension", tmp_text),"UT"]
banned <- unique(c(test1,test2,test3,test4))
View(dataset)
banned
test <- dataset[!dataset$UT %in% banned,]
table(test$X_C)
table(test$level0)
table(test$level1)
table(test$subcluster_label1)
save(banned, file = 'banned.rdata')
library(readr)
dataset <- read_delim("C:/Users/crist/Desktop/a48195-patents-Lou/mission.facet.all.tsv",
delim = "\t", escape_double = FALSE,
trim_ws = TRUE)
View(dataset)
load("~/GitHub/clustering/banned.rdata")
table(banned %in% dataset$UT)
cls <- c(1,3,5,8,10,12,13,15,16,18,20,24,26,29,34,36,37,38,39,40,41,44,48,49,52,53,54,56,57,58)
selected <- dataset[dataset$"_C" %in% cls,]
nrow(selected) / nrow(dataset)
selected$'_N' <- NULL
selected$'_C' <- NULL
selected$'_D' <- NULL
selected$'_E' <- NULL
selected$'_F' <- NULL
selected$'_Y' <- NULL
load('banned.rdata')
selected <- selected[!(selected$UT %in% banned),]
write.table(selected, file='selected.txt', sep = '\t', row.names = FALSE)
#################################################
# Format and Save:
selected$'_N' <- NULL
selected$'_C' <- NULL
selected$'_D' <- NULL
selected$'_E' <- NULL
selected$'_F' <- NULL
selected$'_Y' <- NULL
write.table(selected, file='selected.txt', sep = '\t', row.names = FALSE)
###########################################################################################
# OPTIONS
###########################################################################################
## Select the input folders:
dataset_folder <- choose.dir()
###########################################################################################
# RUN FROM HERE
###########################################################################################
## Libraries
source("04_utils/02_libraries.R")
source(file.path(getwd(), "04_utils", "read_from_fukan_function.R"))
## Path to `/inputs`
# Here 'input' refer to the inputs for clustering.
# From the pov of this very code, this is actually the output folder. Where the files generated by this code will be placed.
bibliometrics_folder <- "C:\\Users\\crist\\OneDrive\\Documentos\\03-bibliometrics"
dir.create(file.path(bibliometrics_folder, dataset_metadata$query_id), showWarnings = FALSE)
## Read files
dataset <- read_from_fukan_2(dataset_folder)
orphans <- read_from_fukan_2(dataset_folder, what = "orphans")
## Read files
network_folder <- choose.dir()
network <- fread(paste(network_folder, "\\mission.pairs.tsv", sep = ""), sep = '\t')
# Get the network object
gd <- graph_from_data_frame(network, directed = TRUE)
gi <- graph_from_data_frame(network, directed = FALSE)
# Get degrees
gi_degree <- degree(gi, mode = 'all')
gi_degree_in <- degree(gi, mode = 'in')
gi_degree_out <- degree(gi, mode = 'out')
V(gi)$name
dfi <- data.frame('X_N' = V(gi)$name,
'all' = gi_degree,
'in' = gi_degree_in,
'out' = gi_degree_out)
View(dfi)
View(dataset)
View(dataset)
dfi <- data.frame('X_N' = as.numeric(V(gi)$name),
'all' = gi_degree,
'in' = gi_degree_in,
'out' = gi_degree_out)
dfi_extra <- merge(dfi, dataset[,'X_N', 'X_C', 'X_E', 'X_D'], by = 'X_N')
dfi_extra <- merge(dfi, dataset[,c('X_N', 'X_C', 'X_E', 'X_D')], by = 'X_N')
View(dfi_extra)
View(dfi_extra)
dfi_extra$diff <- dfi_extra$all - dfi_extra$X_D
View(dfi_extra)
dfi_extra <- merge(dfi, dataset[,c('X_N', 'X_C', 'X_E', 'X_D', 'TC', 'Z9', 'UT')], by = 'X_N')
dfi_extra$diff <- dfi_extra$all - dfi_extra$X_D
dfi_extra <- merge(dfi, dataset[,c('X_N', 'X_C', 'X_E', 'X_D', 'TC', 'Z9', 'UT')], by = 'X_N')
colnames(dataset)
dfi_extra <- merge(dfi, dataset[,c('X_N', 'X_C', 'X_E', 'X_D', 'Z9', 'UT')], by = 'X_N')
dfi_extra$diff <- dfi_extra$all - dfi_extra$X_D
View(dfi_extra)
dataset$X_N[dataset$X_C == cluster]
cluster <- 1
dataset$X_N[dataset$X_C == cluster]
dataset$X_N[dataset$X_C == cluster] %>% length
cluster <- 2
dataset$X_N[dataset$X_C == cluster] %>% length
cluster <- 1
papers_in_cluster <- dataset$X_N[dataset$X_C == cluster]
node_ids <- which(as.numeric(V(gi)$name) %in% papers_in_cluster)
gc <- subgraph(gi, node_ids)
is_directed(gc)
gc_degree <- degree(gc, mode = 'all')
gci <- data.frame('X_N' = as.numeric(V(gc)$name),
'all' = gc_degree)
View(gci)
dfi_extra <- merge(dfi_extra, gci, by = 'X_N', all.x = TRUE, all.y = TRUE)
View(dfi_extra)
# Get degrees
gd_degree <- degree(gd, mode = 'all')
gd_degree_in <- degree(gd, mode = 'in')
gd_degree_out <- degree(gd, mode = 'out')
dfd <- data.frame('X_N' = as.numeric(V(gd)$name),
'all' = gd_degree,
'in' = gd_degree_in,
'out' = gd_degree_out)
dfd_extra <- merge(dfd, dataset[,c('X_N', 'X_C', 'X_E', 'X_D', 'Z9', 'UT')], by = 'X_N')
dfd_extra$diff <- dfd_extra$all - dfd_extra$X_D
cluster <- 1
papers_in_cluster <- dataset$X_N[dataset$X_C == cluster]
node_ids <- which(as.numeric(V(gd)$name) %in% papers_in_cluster)
gc <- subgraph(gd, node_ids)
is_directed(gc)
gc_degree <- degree(gc, mode = 'all')
gc_degree_in <- degree(gc, mode = 'in')
gc_degree_out <- degree(gc, mode = 'out')
gc_degree <- degree(gc, mode = 'all')
gc_degree_in <- degree(gc, mode = 'in')
gc_degree_out <- degree(gc, mode = 'out')
gcd <- data.frame('X_N' = as.numeric(V(gc)$name),
'gc_all' = gc_degree,
'gc_in' = gc_degree_in,
'gc_out' = gc_degree_out)
dfd_extra <- merge(dfd_extra, gcd, by = 'X_N', all.x = TRUE, all.y = TRUE)
View(dfd_extra)
View(dfi_extra)
library(readr)
lou <- read_delim("C:/Users/crist/Desktop/a48200-selected-LOU/mission.facet.all.tsv",
delim = "\t", escape_double = FALSE,
trim_ws = TRUE)
View(lou)
library(readr)
neu <- read_delim("C:/Users/crist/Desktop/a48203-selected-NEU/mission.facet.all.tsv",
delim = "\t", escape_double = FALSE,
trim_ws = TRUE)
View(neu)
lou$TI[lou$`_N` == 1]
neu$TI[neu$`_N` == 1]
lou$TI[lou$`_N` == 1] == neu$TI[neu$`_N` == 1]
test <- unique(lou$`_N`, neu$`_N`)
length(test) == nrow(lou) == nrow(neu)
length(test) == nrow(lou)
test <- lapply(lou$`_N`, function(x) {
lou$TI[lou$`_N` == x] == neu$TI[neu$`_N` == x]
})
all(test)
test
all(unlist(test))
