settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder
))
source(file.path(getwd(), "03_reports", "03_general_summary.R"))
# Orphans treatment
if (settings$addons$include_orphans == "99" | settings$addons$include_orphans == "999") {
source(file.path(getwd(), "04_utils", "zz-append_orphans.R"))
}
# Add-ons
if (settings$params$type_of_analysis == "citation_network" &
exists('g1') &
(settings$addons$page_rank | settings$addons$eigen_centrality | settings$addons$closeness_centrality | settings$addons$betweeness_centrality)) {
source(file.path(getwd(), "04_utils", "zz-centrality_meassures.R"))
}
##########################################################
# save objects
if (settings$params$type_of_analysis == "topic_model") {
dataset <- myDataCorrect
}
if (settings$params$type_of_analysis == "citation_network") {
dataset <- merge(dataset, dataset_minimal[, c("X_N", "level0")])
setnames(dataset, "X_C", "fukan_X_C")
setnames(dataset, "level0", "X_C")
}
save(dataset, file = file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"dataset_clustering.rdata"))
save.image(file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"environ_clustering.rdata"))
rm(list = ls())
##########################################################
# Select root directory
# It should be the directory where this code (00_general_parameters.R) is placed.
# setwd("/var/container/MAIN TOPIC-CLUSTERING") #Linux
# setwd(choose.dir()) #Windows
getwd()
##########################################################
# Load libraries
source("04_utils/02_libraries.R")
# Load settings from the project we are interested in
# source(file.choose())
source("settings.R")
##########################################################
# Output Folder
output_folder_reports <- file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder)
dir.create(output_folder_reports)
##########################################################
# Load data
load(file.path(
settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"dataset_clustering.rdata"
))
##########################################################
# Verify the data is correctly formatted for reports
source(file.path(getwd(), "04_utils", "00_verify_data.R"))
dataset$X_E <- dataset$Z9
dataset$X_E[is.na(dataset$X_E)] <- 0
zz_env <- list('x01' = ls())
# Reporting clusters
source(file.path(getwd(), "02_citation_network", "01_execute_and_reports.R"))
# Dataset merged RCS
source(file.path(getwd(), "03_reports", "15_rcs_merged.R"))
# figures
# Save PNG figures. Normal raster figures for easy navigation in PC.
extension <- 'png'
subfolder_dataset <- "charts_dataset"
subfolder_clusters <- "charts_clusters"
source(file.path(getwd(), "zz-charts_dataset.R"))
source(file.path(getwd(), "zz-charts_clusters_stats1.R"))
source(file.path(getwd(), "zz-charts_clusters_stats2.R"))
source(file.path(getwd(), "zz-charts_clusters_stats3.R"))
source(file.path(getwd(), "zz-charts_clusters_stats4.R"))
source(file.path(getwd(), "zz-charts_clusters_scatterplots.R"))
source(file.path(getwd(), "zz-charts_trends_and_clustered_bars.R"))
# Save PNG figures. Needed for notebook.
extension <- 'svg'
subfolder_dataset <- "index_files/charts"
subfolder_clusters <- "index_files/charts"
source(file.path(getwd(), "zz-charts_dataset.R"))
source(file.path(getwd(), "zz-charts_clusters_stats1.R"))
source(file.path(getwd(), "zz-charts_clusters_stats2.R"))
source(file.path(getwd(), "zz-charts_clusters_stats3.R"))
source(file.path(getwd(), "zz-charts_clusters_stats4.R"))
source(file.path(getwd(), "zz-charts_clusters_scatterplots.R"))
source(file.path(getwd(), "zz-charts_trends_and_clustered_bars.R"))
# Save code snapshot
files_to_save <- list.files(getwd(), full.names = TRUE, recursive = TRUE)
files_to_omit <- list.files(file.path(getwd(),'renv','library'), full.names = TRUE, recursive = TRUE)
files_to_save <- setdiff(files_to_save, files_to_omit)
# Not to zip Rdata environments as they are heavy and saved separately
files_to_save <- files_to_save[!grepl('rdata$', tolower(files_to_save))]
# Zip them. This needs Rtools to work
zip(zipfile = file.path(output_folder_level, 'source_code'),
files = files_to_save)
# Save readable settings
writeLines(RJSONIO::toJSON(settings, pretty=TRUE, auto_unbox=TRUE),
file.path(output_folder_level, "settings.json"))
# Save settings object
save(settings, file = file.path(output_folder_level, "settings.rdata"))
# Save package list
session_info <- sessionInfo()
save(session_info, file = file.path(output_folder_level, "sessionInfo.rdata"))
writeLines(capture.output(sessionInfo()), file.path(output_folder_level, "sessionInfo.txt"))
# Save Global environment
save.image(file.path(output_folder_level, "environ_zz_reports.rdata"))
# Save cluster IDS
if ('fukan_original_cluster_id' %in% colnames(dataset)) {
print('Saving cluster id comparison for subclusters')
cluster_comparison <- dataset[c('X_C', 'fukan_X_C', 'fukan_original_cluster_id', 'fukan_subcluster_label')]
cluster_comparison <- cluster_comparison[!duplicated(cluster_comparison$fukan_subcluster_label),]
cluster_comparison <- cluster_comparison[order(cluster_comparison$fukan_X_C),]
write.csv(cluster_comparison, file = file.path(output_folder_level, "cluster_id_comparison.csv"), row.names = FALSE)
}
###########################################################################################
# OPTIONS
###########################################################################################
## Select the input folders:
dataset_folder <- choose.dir()
## Query_id
## This has de form Qxxx whith the query number from the query control file
dataset_metadata <- list("query_id" = "Q282tm",
"fukan_url" = "https://academic-landscape.com/analysis/48186/0#c0")
###########################################################################################
# RUN FROM HERE
###########################################################################################
## Libraries
source("04_utils/02_libraries.R")
source(file.path(getwd(), "04_utils", "read_from_fukan_function.R"))
## Path to `/inputs`
# Here 'input' refer to the inputs for clustering.
# From the pov of this very code, this is actually the output folder. Where the files generated by this code will be placed.
bibliometrics_folder <- "C:\\Users\\crist\\OneDrive\\Documentos\\03-bibliometrics"
## Read files
dataset <- read_from_fukan_2(dataset_folder)
orphans <- read_from_fukan_2(dataset_folder, what = "orphans")
## Create directories
dir.create(file.path(bibliometrics_folder, dataset_metadata$query_id), showWarnings = FALSE)
save(dataset,orphans,dataset_metadata,
file = file.path(bibliometrics_folder, dataset_metadata$query_id, "dataset.rdata"))
## Clear environment
if (file.exists(file.path(bibliometrics_folder, dataset_metadata$query_id, "dataset.rdata"))) {
#rm(list = (setdiff(ls(), c("dataset", "orphans", "network", "dataset_metadata"))))
rm(list = (ls()))
}
##########################################################
# Select root directory
# It should be the directory where this code is placed.
# setwd("/var/container/MAIN TOPIC-CLUSTERING") #Linux
# setwd(choose.dir()) #Windows
getwd()
##########################################################
# Load libraries
source("04_utils/02_libraries.R")
# Load input settings file
source("settings.R")
# Load data
load(file.path(
settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
"dataset.rdata"
))
##########################################################
# Document classification (Get clusters or Get topics)
if (settings$params$type_of_analysis == "citation_network") {
source(file.path(getwd(), "02_citation_network", "00_citation_network_clustering.R"))
}
if (settings$params$type_of_analysis == "topic_model") {
source(file.path(getwd(), "02_topic_model", "00_topic_model_clustering.R"))
}
# Create stats folder
dir.create(file.path(
settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder
))
source(file.path(getwd(), "03_reports", "03_general_summary.R"))
# Orphans treatment
if (settings$addons$include_orphans == "99" | settings$addons$include_orphans == "999") {
source(file.path(getwd(), "04_utils", "zz-append_orphans.R"))
}
# Add-ons
if (settings$params$type_of_analysis == "citation_network" &
exists('g1') &
(settings$addons$page_rank | settings$addons$eigen_centrality | settings$addons$closeness_centrality | settings$addons$betweeness_centrality)) {
source(file.path(getwd(), "04_utils", "zz-centrality_meassures.R"))
}
##########################################################
# save objects
if (settings$params$type_of_analysis == "topic_model") {
dataset <- myDataCorrect
}
if (settings$params$type_of_analysis == "citation_network") {
dataset <- merge(dataset, dataset_minimal[, c("X_N", "level0")])
setnames(dataset, "X_C", "fukan_X_C")
setnames(dataset, "level0", "X_C")
}
save(dataset, file = file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"dataset_clustering.rdata"))
save.image(file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"environ_clustering.rdata"))
rm(list = ls())
##########################################################
# Load libraries
source("04_utils/02_libraries.R")
# Load settings from the project we are interested in
# source(file.choose())
source("settings.R")
##########################################################
# Output Folder
output_folder_reports <- file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder)
dir.create(output_folder_reports)
##########################################################
# Load data
load(file.path(
settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"dataset_clustering.rdata"
))
##########################################################
# Verify the data is correctly formatted for reports
source(file.path(getwd(), "04_utils", "00_verify_data.R"))
dataset$X_E <- dataset$Z9
dataset$X_E[is.na(dataset$X_E)] <- 0
zz_env <- list('x01' = ls())
# Reporting clusters
source(file.path(getwd(), "02_citation_network", "01_execute_and_reports.R"))
# Reporting clusters
source(file.path(getwd(), "02_citation_network", "01_execute_and_reports.R"))
# Dataset merged RCS
source(file.path(getwd(), "03_reports", "15_rcs_merged.R"))
table(myDataCorrect_SAMPLE$X_C)
myDataCorrect_SAMPLE_Backup <- myDataCorrect_SAMPLE
# The main (first) sampling must be based on the finest granularity clustering we selected
# This is to avoid sampling articles which vocabulary is not reflected in the top articles of the parent cluster
if (settings$params$type_of_analysis == "citation_network") {
if (settings$params$recursive_level == 0) {
myDataCorrect$sampling_column <- myDataCorrect$"level0"
}
if (settings$params$recursive_level == 1) {
myDataCorrect$sampling_column <- myDataCorrect$"subcluster_label1"
}
if (settings$params$recursive_level == 2) {
myDataCorrect$sampling_column <- myDataCorrect$"subcluster_label2"
}
if (settings$params$recursive_level == 3) {
myDataCorrect$sampling_column <- myDataCorrect$"subcluster_label3"
}
}
if (settings$params$type_of_analysis == "topic_model") {
myDataCorrect$sampling_column <- myDataCorrect$"level0"
}
sample_columns <- intersect(c('TI', 'AB', 'DE', 'ID','X_E','X_C','sampling_column',
'subcluster_label1','subcluster_label2','subcluster_label3'),
colnames(myDataCorrect))
# Sampling sizes vary depending on level
my_thres <- c(100, 50, 10, 10)
if (nrow(myDataCorrect) > 10000) {
myDataCorrect_SAMPLE <- myDataCorrect[,sample_columns] %>%
group_by(sampling_column) %>%
top_n(my_thres[level_report + 1], X_E) %>%
ungroup() # optionally use fractions %>% top_frac_ceiling(0.05, X_E)
} else {
myDataCorrect_SAMPLE <- myDataCorrect[,sample_columns]
}
table(myDataCorrect_SAMPLE$X_C)
#########################################
# When the dataset is too large., instead of computing this vector based on all text, we use a sample.
# The sample is the top x% most cited articles. (We are NOT using a random sample!)
rm(myDataCorrect_SAMPLE)
# The main (first) sampling must be based on the finest granularity clustering we selected
# This is to avoid sampling articles which vocabulary is not reflected in the top articles of the parent cluster
if (settings$params$type_of_analysis == "citation_network") {
if (settings$params$recursive_level == 0) {
myDataCorrect$sampling_column <- myDataCorrect$"level0"
}
if (settings$params$recursive_level == 1) {
myDataCorrect$sampling_column <- myDataCorrect$"subcluster_label1"
}
if (settings$params$recursive_level == 2) {
myDataCorrect$sampling_column <- myDataCorrect$"subcluster_label2"
}
if (settings$params$recursive_level == 3) {
myDataCorrect$sampling_column <- myDataCorrect$"subcluster_label3"
}
}
table(myDataCorrect_SAMPLE$X_C)
if (settings$params$type_of_analysis == "topic_model") {
myDataCorrect$sampling_column <- myDataCorrect$"level0"
}
sample_columns <- intersect(c('TI', 'AB', 'DE', 'ID','X_E','X_C','sampling_column',
'subcluster_label1','subcluster_label2','subcluster_label3'),
colnames(myDataCorrect))
# Sampling sizes vary depending on level
my_thres <- c(100, 50, 10, 10)
if (nrow(myDataCorrect) > 10000) {
myDataCorrect_SAMPLE <- myDataCorrect[,sample_columns] %>%
group_by(sampling_column) %>%
top_n(my_thres[level_report + 1], X_E) %>%
ungroup() # optionally use fractions %>% top_frac_ceiling(0.05, X_E)
} else {
myDataCorrect_SAMPLE <- myDataCorrect[,sample_columns]
}
table(myDataCorrect_SAMPLE$X_C)
View(myDataCorrect_SAMPLE)
table(myDataCorrect$X_C)
table(myDataCorrect$level0)
table(dataset$X_C)
##########################################################
# Select root directory
# It should be the directory where this code is placed.
# setwd("/var/container/MAIN TOPIC-CLUSTERING") #Linux
# setwd(choose.dir()) #Windows
getwd()
##########################################################
# Load libraries
source("04_utils/02_libraries.R")
# Load input settings file
source("settings.R")
# Load data
load(file.path(
settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
"dataset.rdata"
))
##########################################################
# Document classification (Get clusters or Get topics)
if (settings$params$type_of_analysis == "citation_network") {
source(file.path(getwd(), "02_citation_network", "00_citation_network_clustering.R"))
}
if (settings$params$type_of_analysis == "topic_model") {
source(file.path(getwd(), "02_topic_model", "00_topic_model_clustering.R"))
}
# Create stats folder
dir.create(file.path(
settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder
))
source(file.path(getwd(), "03_reports", "03_general_summary.R"))
# Orphans treatment
if (settings$addons$include_orphans == "99" | settings$addons$include_orphans == "999") {
source(file.path(getwd(), "04_utils", "zz-append_orphans.R"))
}
# Add-ons
if (settings$params$type_of_analysis == "citation_network" &
exists('g1') &
(settings$addons$page_rank | settings$addons$eigen_centrality | settings$addons$closeness_centrality | settings$addons$betweeness_centrality)) {
source(file.path(getwd(), "04_utils", "zz-centrality_meassures.R"))
}
##########################################################
# save objects
if (settings$params$type_of_analysis == "topic_model") {
dataset <- myDataCorrect
}
if (settings$params$type_of_analysis == "citation_network") {
dataset <- merge(dataset, dataset_minimal[, c("X_N", "level0")])
setnames(dataset, "X_C", "fukan_X_C")
setnames(dataset, "level0", "X_C")
}
save(dataset, file = file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"dataset_clustering.rdata"))
save.image(file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"environ_clustering.rdata"))
rm(list = ls())
##########################################################
# Select root directory
# It should be the directory where this code (00_general_parameters.R) is placed.
# setwd("/var/container/MAIN TOPIC-CLUSTERING") #Linux
# setwd(choose.dir()) #Windows
getwd()
##########################################################
# Load libraries
source("04_utils/02_libraries.R")
# Load settings from the project we are interested in
# source(file.choose())
source("settings.R")
##########################################################
# Output Folder
output_folder_reports <- file.path(settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder)
dir.create(output_folder_reports)
##########################################################
# Load data
load(file.path(
settings$analysis_metadata$bibliometrics_folder,
settings$analysis_metadata$project_folder,
settings$analysis_metadata$analysis_folder,
"dataset_clustering.rdata"
))
##########################################################
# Verify the data is correctly formatted for reports
source(file.path(getwd(), "04_utils", "00_verify_data.R"))
dataset$X_E <- dataset$Z9
dataset$X_E[is.na(dataset$X_E)] <- 0
zz_env <- list('x01' = ls())
# Reporting clusters
source(file.path(getwd(), "02_citation_network", "01_execute_and_reports.R"))
table(dataset$X_C)
table(myDataCorrect$X_C)
table(myDataCorrect$level0)
table(myDataCorrect_SAMPLE$X_C)
# Dataset merged RCS
source(file.path(getwd(), "03_reports", "15_rcs_merged.R"))
# Save code snapshot
files_to_save <- list.files(getwd(), full.names = TRUE, recursive = TRUE)
files_to_omit <- list.files(file.path(getwd(),'renv','library'), full.names = TRUE, recursive = TRUE)
files_to_save <- setdiff(files_to_save, files_to_omit)
# Not to zip Rdata environments as they are heavy and saved separately
files_to_save <- files_to_save[!grepl('rdata$', tolower(files_to_save))]
# Zip them. This needs Rtools to work
zip(zipfile = file.path(output_folder_level, 'source_code'),
files = files_to_save)
# Save readable settings
writeLines(RJSONIO::toJSON(settings, pretty=TRUE, auto_unbox=TRUE),
file.path(output_folder_level, "settings.json"))
# Save settings object
save(settings, file = file.path(output_folder_level, "settings.rdata"))
# Save package list
session_info <- sessionInfo()
save(session_info, file = file.path(output_folder_level, "sessionInfo.rdata"))
writeLines(capture.output(sessionInfo()), file.path(output_folder_level, "sessionInfo.txt"))
# Save Global environment
save.image(file.path(output_folder_level, "environ_zz_reports.rdata"))
# Save cluster IDS
if ('fukan_original_cluster_id' %in% colnames(dataset)) {
print('Saving cluster id comparison for subclusters')
cluster_comparison <- dataset[c('X_C', 'fukan_X_C', 'fukan_original_cluster_id', 'fukan_subcluster_label')]
cluster_comparison <- cluster_comparison[!duplicated(cluster_comparison$fukan_subcluster_label),]
cluster_comparison <- cluster_comparison[order(cluster_comparison$fukan_X_C),]
write.csv(cluster_comparison, file = file.path(output_folder_level, "cluster_id_comparison.csv"), row.names = FALSE)
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents != 0) {
article_report_20 <- article_report %>%
group_by(X_C) %>%
top_n(settings$rp$top_documents, settings$rp$column_labels['X_E'])
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(X_C) %>%
top_n(settings$rp$top_documents, settings$rp$column_labels['X_E'])
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(settings$rp$column_labels['X_C']) %>%
top_n(settings$rp$top_documents, settings$rp$column_labels['X_E'])
}
settings$rp$column_labels['X_C']
settings$rp$column_labels['X_E']
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(settings$rp$top_documents, Degree)
}
View(article_report)
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(20, Degree)
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(20, settings$rp$column_labels['X_E'])
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(20, settings$rp$column_labels['X_E'])
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(20, Degree)
}
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(30, Degree)
}
# Write the article report
write.csv(article_report_20,
file = gsub('_report', '_report_20', rn$PROJECTarticlereport),
row.names = FALSE)
