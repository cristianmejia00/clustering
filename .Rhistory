}
# Generate the bulk text
print('get bulk text')
print(glue('Total selected papers for this cluster: {nrow(cluster_data)}'))
my_texts <- list()
for (i in c(1:min(10,nrow(cluster_data)))) {
my_texts[i] <- glue('##### {cluster_data$text[[i]]}')
}
my_texts <- paste(my_texts, collapse = ' ')
my_texts <- substr(my_texts, 1, (3500 * 4))
# Get the topic of the cluster
print('Get cluster topic')
prompt_desc <- prompt_cluster_description(topic = MAIN_TOPIC,
topic_description = MAIN_TOPIC_DESCRIPTION,
cluster_text = my_texts)
cluster_completed <- FALSE
while(!cluster_completed) {
tmp <- tryCatch({
cluster_description <- ask_claude(system_prompt = prompt_desc$system,
user_prompt = prompt_desc$user,
temperature = 0.2)
cluster_completed <- TRUE
print(cluster_description)
},
error = function(err){
message(glue('Error getting topic description of cluster {cluster}. Trying again'))
message(err)
})
}
rcs_merged$description[which(rcs_merged$cluster_code == cluster)] <- cluster_description
# Get the name of the cluster
print('Get cluster name')
cluster_completed <- FALSE
while(!cluster_completed) {
tmp <- tryCatch({
prompt <- prompt_cluster_name(topic = MAIN_TOPIC,
topic_description = MAIN_TOPIC_DESCRIPTION,
cluster_description = cluster_description)
cluster_name <- ask_claude(system_prompt = prompt$system,
user_prompt = prompt$user,
max_tokens = 60,
temperature = 0.3)
cluster_completed <- TRUE
print(cluster_name)
},
error = function(err){
message(glue('Error getting topic name of cluster {cluster}. Trying again'))
message(err)
})
}
rcs_merged$name[which(rcs_merged$cluster_code == cluster)] <- cluster_name
}
# We do this to keep copy of the edits in case we mess it.
rcs_merged$name2 <- gsub('^.*?"','',rcs_merged$name) %>% gsub('".$','', .) %>% gsub('"','', .)
rcs_merged$cluster_name <- rcs_merged$name2
rcs_merged$detailed_description <- rcs_merged$description
for (cluster in list_of_clusters) {
print('=================================================================')
print(glue('cluster: {cluster}'))
# Get the topic of the cluster
print('Get enhanced description')
cluster_completed <- FALSE
while(!cluster_completed) {
tmp <- tryCatch({
prompt_enh <- prompt_cluster_description_enhanced(topic = MAIN_TOPIC,
cluster_description = rcs_merged$detailed_description[rcs_merged$cluster_code == cluster])
print(prompt_enh$user)
cluster_description <- ask_claude(system_prompt = prompt_enh$system,
user_prompt = prompt_enh$user,
#model = 'claude-3-opus-20240229',
temperature = 0.1)
print(cluster_description)
cluster_completed <- TRUE
},
error = function(err){
message(glue('Error getting topic enhanced description of cluster {cluster}. Trying again'))
message(err)
})
}
rcs_merged$description[which(rcs_merged$cluster_code == cluster)] <- cluster_description
}
colnames(rcs_merged)
# Save
write.csv(rcs_merged %>%
mutate(cluster_code = paste('UTokyo', cluster_code, sep = '-')) %>%
rename(ave_PY = cluster_year, ave_Z9 = ave_cites, Count = cluster_size) %>%
select(cluster_code, cluster_name, Count, ave_Z9, ave_PY, description, detailed_description),
file.path("cluster_summary.csv"),
row.names = FALSE)
library(ggplot2)
library(ggrepel)
library(stats)
library(tidyr)
library(reshape2)
save.image("~/Desktop/GitHub/clustering/Q312utokyo_llm.RData")
heatmap_analysis_id = 'H004'
library(ggplot2)
library(ggrepel)
library(stats)
library(tidyr)
library(reshape2)
heatmap_analysis_id = 'H004'
settings_directive = 'heatmap_settings_H004_PIK_RIKEN_UTOKYO.json'
###############################################################################
# Call necessary libraries
source("04_utils/02_libraries.R")
source("04_utils/00_system_paths.R")
###############################################################################
# Load the directive file
settings <- RJSONIO::fromJSON(
file.path(
bibliometrics_folder_path,
heatmap_analysis_id,
settings_directive
),
simplify = FALSE
)
# Save setting inputs as a df.
inputs <- lapply(settings$inputs, function(x) {data.frame(x)}) %>% rbind.fill()
###############################################################################
# Read the files
# The coordinates of all participating clusters across analysis in this heatmap
# Computed in the Heatmap colab
coords <- readr::read_csv(file.path(
bibliometrics_folder_path,
heatmap_analysis_id,
"coordinates.csv"
)) %>%
select(x, y, cluster) %>%
rename(cluster_code = cluster)
# Read the RCS files
# For the heatmap the RCS is expected to have already
# The count, ave_PY, ave_Z9, and the LLM_name (cluster_name)
rcs <- lapply(c(1:nrow(inputs)), \(x) {
readr::read_csv(file.path(
bibliometrics_folder_path,#settings$metadata$input_directory,
settings$inputs[[x]]$project_folder_name,
settings$inputs[[x]]$analysis_folder_name,
settings$inputs[[x]]$level_folder_name,
"cluster_summary.csv"
))
}) %>% rbind.fill() %>%
select(cluster_code, cluster_name, Count, ave_PY, ave_Z9)
###############################################################################
###############################################################################
# Merge the datasets and create needed columns
tmp <- merge(rcs, coords, by = 'cluster_code')
tmp <- tmp %>%
separate(cluster_code,
remove = FALSE,
into = c("dataset", "local_cluster"),
sep = "-")
tmp <- merge(tmp,
inputs %>%
select(display_name, color, heatmap_display_order, sankey_display_order) %>%
rename(dataset = display_name),
by = 'dataset')
# The labels shown in the scatter plots
tmp$scatter_labels <- paste(tmp$local_cluster, tmp$cluster_name, sep = ':')
# Groups of clusters
km1 <- kmeans(tmp[,c("x","y")], centers = 10)
tmp$group <- as.factor(km1$cluster)
###############################################################################
###############################################################################
# Get the scatter plots
# Aux plot function
plot_scatter_group <- function(rcs_data,
point_labels,
x_column,
y_column,
color_hex_column,
color_labels,
size_column,
x_column_label = x_column,
y_column_label = y_column,
show_tags = TRUE) {
# format the df
df <- rcs_data[, c(point_labels, x_column, y_column, color_hex_column, color_labels, size_column)]
colnames(df) <- c("point_labels", "x",    "y",       "color_hex",      "color_label", "size")
# plot
p <- ggplot(df, aes(x = x, y = y)) +
stat_ellipse(geom = "polygon",
aes(linetype = rcs_data$group),
alpha=0.07) + #0.07 OR 0.35 for colors
geom_point(aes(color = color_hex,
size = size)) +
scale_color_identity() +
xlab("") +
ylab("")
if (show_tags) {
p <- p + geom_text_repel(aes(label = gsub("---", "", point_labels)))
}
p <- p + theme_bw() + theme(legend.position = "none")
p
}
#################################################
# Aux plot function
plot_scatter <- function(rcs_data,
point_labels,
x_column,
y_column,
color_hex_column,
color_labels,
size_column,
max_x,
max_y,
x_column_label = x_column,
y_column_label = y_column,
show_tags = TRUE) {
# format the df
df <- rcs_data[, c(point_labels, x_column, y_column, color_hex_column, color_labels, size_column)]
colnames(df) <- c("point_labels", "x",    "y",       "color_hex",      "color_label", "size")
# plot
p <- ggplot(df, aes(x = x, y = y)) +
geom_point(aes(colour = color_hex,
size = size)) +
scale_color_identity() +
scale_x_continuous(limits = c(2005, ceiling(max_x))) + # = seq(2005, 2022, by = 2)) +
#scale_x_continuous(breaks = seq(2005, 2022, by = 2)) +
scale_y_continuous(limits = c(0, (round(max_y, 0) + 10))) +
xlab("") +
ylab("")
if (show_tags) {
p <- p + geom_text_repel(aes(label = gsub("---", "", point_labels)))
}
p <- p + theme_bw() + theme(legend.position = "none")
p
}
# Global scatter by x and y MDS scalling
# i.e. Topic Model plot
tm_plot <- plot_scatter_group(tmp,
point_labels = "cluster_code",
x_column = "x",
y_column = "y",
color_hex_column = "color",
color_labels = "dataset",
size_column = "Count",
show_tags = TRUE)
tm_plot
ggsave(
filename = file.path(
bibliometrics_folder_path,
settings$metadata$heatmap_analysis_id,
"topic_model.png"),
plot = tm_plot,
width = 8,  # Width in inches
height = 6, # Height in inches
dpi = 300   # Resolution (dots per inch)
)
# PY Z9 plots
for (inst in unique(tmp$dataset)) {
p <- plot_scatter(tmp %>% filter(dataset == inst),
point_labels = "scatter_labels",
x_column = "ave_PY",
y_column = "ave_Z9",
color_hex_column = "color",
color_labels = "dataset",
size_column = "Count",
max_x = 2022,
max_y = 350,
show_tags = TRUE)
ggsave(
filename = file.path(
bibliometrics_folder_path,
settings$metadata$heatmap_analysis_id,
paste("scatter_plot_", inst,".png")),
plot = p,
width = 8,  # Width in inches
height = 6, # Height in inches
dpi = 300   # Resolution (dots per inch)
)
}
View(rcs)
View(settings)
View(inputs)
View(rcs)
# PY Z9 plots
for (inst in unique(tmp$dataset)) {
p <- plot_scatter(tmp %>% filter(dataset == inst),
point_labels = "scatter_labels",
x_column = "ave_PY",
y_column = "ave_Z9",
color_hex_column = "color",
color_labels = "dataset",
size_column = "Count",
max_x = 2022,
max_y = 350,
show_tags = TRUE)
p
ggsave(
filename = file.path(
bibliometrics_folder_path,
settings$metadata$heatmap_analysis_id,
paste("scatter_plot_", inst,".png")),
plot = p,
width = 8,  # Width in inches
height = 6, # Height in inches
dpi = 300   # Resolution (dots per inch)
)
}
p
View(tmp)
View(tmp)
View(rcs)
# PY Z9 plots
for (inst in unique(tmp$dataset)) {
p <- plot_scatter(tmp %>% filter(dataset == inst),
point_labels = "scatter_labels",
x_column = "ave_PY",
y_column = "ave_Z9",
color_hex_column = "color",
color_labels = "dataset",
size_column = "Count",
max_x = 2024,
max_y = 350,
show_tags = TRUE)
ggsave(
filename = file.path(
bibliometrics_folder_path,
settings$metadata$heatmap_analysis_id,
paste("scatter_plot_", inst,".png")),
plot = p,
width = 8,  # Width in inches
height = 6, # Height in inches
dpi = 300   # Resolution (dots per inch)
)
}
# Heatmap
hm <- readr::read_csv(file.path(
bibliometrics_folder_path,
settings$metadata$heatmap_analysis_id,
"heatmap_matrix.csv"
)) %>% as.data.frame()
rownames(hm) <- colnames(hm)
# Create a sorting vector
sort_vector <- sort(colnames(hm))
# Sort the heatmap
hm_sorted <- hm[sort_vector, sort_vector]
# Convert matrix to long format for ggplot
df_long <- hm_sorted %>% as.matrix() %>% melt()
# Create heatmap
tm_hm <- ggplot(df_long, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "red") +
theme_minimal() +
coord_fixed() +  # make cells square
labs(x = "", y = "", fill = "Similarity") +  # label axes
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # rotate x labels for better readability
tm_hm
ggsave(
plot = tm_plot,
filename = file.path(
bibliometrics_folder_path,
settings$metadata$heatmap_analysis_id,
"heatmap.png"),
width = 8,  # Width in inches
height = 6, # Height in inches
dpi = 300   # Resolution (dots per inch)
)
# Sankey
melted <- readr::read_csv(file.path(
bibliometrics_folder_path,
settings$metadata$heatmap_analysis_id,
"heatmap_melted.csv"
))
melted <- melted %>%
separate(Source,
remove = FALSE,
into = c("source_dataset", "source_local_cluster"),
sep = "-") %>%
separate(Target,
remove = FALSE,
into = c("target_dataset", "target_local_cluster"),
sep = "-")
melted <- merge(melted,
inputs %>%
select(display_name, color, heatmap_display_order, sankey_display_order) %>%
rename(source_color = color,
source_heatmap_order = heatmap_display_order,
source_sankey_order = sankey_display_order),
by.x = "source_dataset",
by.y = "display_name",
all.x = TRUE,
all.y = FALSE)
melted <- merge(melted,
inputs %>%
select(display_name, color, heatmap_display_order, sankey_display_order) %>%
rename(target_color = color,
target_heatmap_order = heatmap_display_order,
target_sankey_order = sankey_display_order),
by.x = "target_dataset",
by.y = "display_name")
###############################################################################
# Remove pairs in the same sankey level (they belong to same institution)
# Remove pairs in separated for more than one step
melted_filtered <- melted %>%
filter(source_sankey_order != target_sankey_order) %>%
#filter(abs(source_sankey_order - target_sankey_order) == 1) %>%
filter(Similarity >= 0.8)
sankey_steps <- unique(inputs$sankey_display_order) %>% sort()
# Stacking the datasets to reorder them
melted_filtered$pair_index <- c(1:nrow(melted_filtered)) %>% as.character()
sources_df <- lapply(sankey_steps, \(st) {
tmp <- melted_filtered %>%
filter(source_sankey_order == st) %>%
select(Source, source_sankey_order, Similarity, pair_index) %>%
rename(cluster = Source,
step = source_sankey_order,
similarity = Similarity)
}) %>% rbind.fill()
targets_df <- lapply(sankey_steps, \(st) {
tmp <- melted_filtered %>%
filter(target_sankey_order == st) %>%
select(Target, target_sankey_order, Similarity, pair_index) %>%
rename(cluster = Target,
step = target_sankey_order,
similarity = Similarity)
}) %>% rbind.fill()
melted_listed <- rbind(sources_df, targets_df)
###############################################################################
melted_sankey <- lapply(c(0, max(sankey_steps) - 1), function(st) {
left_side <- melted_listed %>%
filter(step == st)
right_side <- melted_listed %>%
filter(step > st) # filter(step == st + 1) when strictly step by step
full_pair <- merge(left_side %>%
select(cluster, step, similarity, pair_index) %>%
rename(Source = cluster, "Step from" = step, source_similarity = similarity),
right_side %>%
select(cluster, step, similarity, pair_index) %>%
rename(Dest = cluster, "Step to" = step, dest_similarity = similarity),
by = "pair_index",
all.x = FALSE,
all.y = FALSE)
}) %>%
rbind.fill() %>%
select(all_of(c("Source", "Dest", "source_similarity", "Step from", "Step to"))) %>%
rename(Similarity = source_similarity) %>%
mutate(Value = 100,
Distance = `Step to` - `Step from`) %>%
arrange(Distance, `Step from`, desc(Similarity))
###############################################################################
melted_sankey_topics <- merge(melted_sankey,
rcs %>%
select(cluster_code, cluster_name) %>%
rename(source_topic = cluster_name),
by.x = 'Source',
by.y = 'cluster_code',
all.x = TRUE,
all.y = FALSE)
melted_sankey_topics <- merge(melted_sankey_topics,
rcs %>%
select(cluster_code, cluster_name) %>%
rename(target_topic = cluster_name),
by.x = 'Dest',
by.y = 'cluster_code',
all.x = TRUE,
all.y = FALSE)
melted_sankey_topics <- melted_sankey_topics %>%
select(all_of(c("Source", "Dest", "Similarity", "Step from", "Step to", "Value", "Distance", "source_topic", "target_topic"))) %>%
arrange(`Step from`, desc(Similarity))
write.csv(melted_sankey_topics,
file=file.path(bibliometrics_folder_path,
settings$metadata$heatmap_analysis_id,
'sankey_df_with_deadends.csv'),
row.names = FALSE)
###############################################################################
# Write color codes for Flourish
write.csv(paste(tmp$cluster_code, tmp$color, sep = ': '),
file=file.path(bibliometrics_folder_path,
settings$metadata$heatmap_analysis_id,
'sankey_cluster_color_for_flourish.csv'),
row.names = FALSE)
###############################################################################
# Hardcoded!
bridge_clusters <-intersect(
melted_sankey$Dest[melted_sankey$`Step to` == 1],
melted_sankey$Source[melted_sankey$`Step from` == 1]
)
if (length(bridge_clusters) > 0) {
melted_bridge <- melted_sankey %>%
filter(`Step to` != 1 | Dest %in% bridge_clusters) %>%
filter(`Step from` != 1 | Source %in% bridge_clusters)
write.csv(melted_bridge,
file=file.path(bibliometrics_folder_path,
settings$metadata$heatmap_analysis_id,
'sankey_df_without_deadends.csv'),
row.names = FALSE)
# Readable
left_side <- melted_bridge %>% filter(`Step to` == 1)
right_side <- melted_bridge %>% filter(`Step from` == 1)
melted_bridge_readable <- merge(left_side %>%
select(Source, Dest) %>%
rename(left = Source, bridge = Dest),
right_side %>%
select(Source, Dest) %>%
rename(right = Dest, bridge = Source),
by = "bridge",
all.x = TRUE,
all.y = TRUE)
# Add topics
melted_bridge_readable$left_topic <- rcs$cluster_name[match(melted_bridge_readable$left, rcs$cluster_code)]
melted_bridge_readable$bridge_topic <- rcs$cluster_name[match(melted_bridge_readable$bridge, rcs$cluster_code)]
melted_bridge_readable$right_topic <- rcs$cluster_name[match(melted_bridge_readable$right, rcs$cluster_code)]
# Arrange columns
melted_bridge_readable <- melted_bridge_readable %>% select(left, bridge, right, left_topic, bridge_topic, right_topic)
write.csv(melted_bridge_readable,
file=file.path(bibliometrics_folder_path,
settings$metadata$heatmap_analysis_id,
'sankey_df_without_deadends_readable.csv'),
row.names = FALSE)
}
