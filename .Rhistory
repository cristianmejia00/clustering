#patents = `weight<Documents>`[1]
)
updated_summary_links <- firms_selected %>%
group_by(fixed_cluster) %>%
#arrange(desc(`weight<Links>`)) %>%
summarize(
#hub = label[1],
firms = dplyr::n(),
#links = `weight<Links>`[1],
#patents = `weight<Documents>`[1]
)
rlang::last_trace()
updated_summary_links <- firms_selected %>%
arrange(desc(`weight<Links>`)) %>%
group_by(fixed_cluster) %>%
summarize(
#hub = label[1],
firms = n(),
#links = `weight<Links>`[1],
#patents = `weight<Documents>`[1]
)
updated_summary_links <- firms_selected %>%
arrange(desc(`weight<Links>`)) %>%
group_by(fixed_cluster) %>%
dplyr::summarize(
#hub = label[1],
firms = n(),
#links = `weight<Links>`[1],
#patents = `weight<Documents>`[1]
)
View(updated_summary_links)
updated_summary_links <- firms_selected %>%
arrange(desc(`weight<Links>`)) %>%
group_by(fixed_cluster) %>%
dplyr::summarize(
hub = label[1],
firms = n(),
links = `weight<Links>`[1],
patents = `weight<Documents>`[1]
)
updated_summary_docs <- firms_selected |>
group_by(fixed_cluster) |>
arrange(desc(`weight<Documents>`)) |>
dplyr::summarize(
hub = label[1],
firms = n_distinct(),
links = `weight<Links>`[1],
patents = `weight<Documents>`[1]
)
updated_summary_docs <- firms_selected |>
group_by(fixed_cluster) |>
arrange(desc(`weight<Documents>`)) |>
dplyr::summarize(
hub = label[1],
firms = n(),
links = `weight<Links>`[1],
patents = `weight<Documents>`[1]
)
View(updated_summary_docs)
View(updated_summary_links)
View(updated_summary_docs)
View(updated_summary_links)
View(updated_summary_docs)
View(updated_summary_docs)
View(updated_summary_links)
View(updated_summary_docs)
View(updated_summary_links)
View(updated_summary_docs)
View(updated_summary_links)
?merge
View(updated_summary_docs)
updated_summary <- merge(updated_summary_links,
updated_summary_docs,
by = 'fixed_cluster',
all.x = TRUE,
all.y = TRUE,
suffixes = c('by_LINKS', 'by_PATENTS'))
View(updated_summary)
# Merge them
updated_summary <- merge(updated_summary_links,
updated_summary_docs,
by = 'fixed_cluster',
all.x = TRUE,
all.y = TRUE,
suffixes = c('_by_LINKS', '_by_PATENTS'))
# Save
write.csv(updated_summary, file='updated_summary.csv')
write.csv(firms_selected, file='firms_selected.csv')
View(updated_summary)
?rename
# Rename
updated_summary <- updated_summary %>% rename(c('cluster' = 'fixed_cluster'))
View(updated_summary)
# Remove cluster 0
updated_summary <- updated_summary[updated_summary$fixed_cluster != 0,]
View(updated_summary)
# Merge them
updated_summary <- merge(updated_summary_links,
updated_summary_docs,
by = 'fixed_cluster',
all.x = TRUE,
all.y = TRUE,
suffixes = c('_by_LINKS', '_by_PATENTS'))
# Remove cluster 0
updated_summary <- updated_summary[updated_summary$fixed_cluster != 0,]
# Rename
updated_summary <- updated_summary %>% rename(c('cluster' = 'fixed_cluster'))
# Save
write.csv(updated_summary, file='updated_summary.csv')
write.csv(firms_selected, file='firms_selected.csv')
network <- read_table("~/Library/CloudStorage/OneDrive-Personal/Documentos/00-Research projects/58 - GMO - Deals and Patents/Patents/02-Results/20240624/net.txt",
col_names = FALSE)
network <- readr::read_table("~/Library/CloudStorage/OneDrive-Personal/Documentos/00-Research projects/58 - GMO - Deals and Patents/Patents/02-Results/20240624/net.txt",
col_names = FALSE)
colnames(network) <- c('a', 'b', 'weight')
network$cluster_a <- firms_selected$fixed_cluster[match(network$a, firms_selected$id)] |> as.character()
network$cluster_b <- firms_selected$fixed_cluster[match(network$b, firms_selected$id)] |> as.character()
network <- network |>
filter(!is.na(cluster_a), !is.na(cluster_b), cluster_a != 0, cluster_b != 0) |>
as.data.frame()
View(network)
edge_matrix_simple <- table(network$cluster_a, network$cluster_b) |> as.matrix.data.frame()
library(tidyr)
edge_matrix_weighted <- network |>
group_by(cluster_a, cluster_b) |>
summarize(
links = sum(weight, na.rm = TRUE)
) |>
ungroup() |>
mutate(
cluster_a = as.numeric(cluster_a),
cluster_b = as.numeric(cluster_b)
) |>
arrange(
cluster_b,
cluster_a
) |>
pivot_wider(
names_from = cluster_b,
values_from = links
) |>
arrange(
cluster_a
) %>%
replace(is.na(.), 0)
View(network)
library(dplyr)
library(tidyr)
edge_matrix_weighted <- network |>
group_by(cluster_a, cluster_b) |>
summarize(
links = sum(weight, na.rm = TRUE)
) |>
ungroup() |>
dplyr::mutate(
cluster_a = as.numeric(cluster_a),
cluster_b = as.numeric(cluster_b)
) |>
arrange(
cluster_b,
cluster_a
) |>
pivot_wider(
names_from = cluster_b,
values_from = links
) |>
arrange(
cluster_a
) %>%
replace(is.na(.), 0)
library(tidyr)
edge_matrix_weighted <- network |>
group_by(cluster_a, cluster_b) |>
summarize(
links = sum(weight, na.rm = TRUE)
) |>
# ungroup() |>
# dplyr::mutate(
#   cluster_a = as.numeric(cluster_a),
#   cluster_b = as.numeric(cluster_b)
# ) |>
# arrange(
#   cluster_b,
#   cluster_a
# ) |>
# pivot_wider(
#   names_from = cluster_b,
#   values_from = links
# ) |>
# arrange(
#   cluster_a
# ) %>%
# replace(is.na(.), 0)
write.csv(edge_matrix_weighted, file = 'edges_weighted.csv', row.names = FALSE)
View(edge_matrix_simple)
View(network)
?summarize
library(tidyr)
edge_matrix_weighted <- network |>
group_by(cluster_a, cluster_b) |>
dplyr::summarize(
links = sum(weight, na.rm = TRUE)
) |>
# ungroup() |>
# dplyr::mutate(
#   cluster_a = as.numeric(cluster_a),
#   cluster_b = as.numeric(cluster_b)
# ) |>
# arrange(
#   cluster_b,
#   cluster_a
# ) |>
# pivot_wider(
#   names_from = cluster_b,
#   values_from = links
# ) |>
# arrange(
#   cluster_a
# ) %>%
# replace(is.na(.), 0)
write.csv(edge_matrix_weighted, file = 'edges_weighted.csv', row.names = FALSE)
library(tidyr)
edge_matrix_weighted <- network |>
group_by(cluster_a, cluster_b) |>
dplyr::summarize(
links = sum(weight, na.rm = TRUE)
) #|>
View(edge_matrix_weighted)
edge_matrix_weighted <- network |>
group_by(cluster_a, cluster_b) |>
dplyr::summarize(
links = sum(weight, na.rm = TRUE)
) |>
ungroup() |>
dplyr::mutate(
cluster_a = as.numeric(cluster_a),
cluster_b = as.numeric(cluster_b)
) |>
arrange(
cluster_b,
cluster_a
) |>
pivot_wider(
names_from = cluster_b,
values_from = links
) |>
arrange(
cluster_a
) %>%
replace(is.na(.), 0)
View(edge_matrix_weighted)
write.csv(edge_matrix_weighted, file = 'edges_weighted.csv', row.names = FALSE)
network_backup <- network
library(dplyr)
##############
network$better_a <- sapply(c(1:nrow(network)), function(x) {
min(as.numeric(network$cluster_a[x]), as.numeric(network$cluster_b[x]))
})
network$better_b <- sapply(c(1:nrow(network)), function(x) {
max(as.numeric(network$cluster_a[x]), as.numeric(network$cluster_b[x]))
})
edge_df_weighted <- network |>
group_by(better_a, better_b) |>
summarize(
weight = sum(weight, na.rm = TRUE)
) |>
ungroup() |>
mutate(
cluster_a = as.numeric(better_a),
cluster_b = as.numeric(better_b)
) |>
arrange(
cluster_b,
cluster_a
)
library(igraph)
edge_df_weighted <- network |>
group_by(better_a, better_b) |>
dplyr::summarize(
weight = sum(weight, na.rm = TRUE)
) |>
ungroup() |>
mutate(
cluster_a = as.numeric(better_a),
cluster_b = as.numeric(better_b)
) |>
arrange(
cluster_b,
cluster_a
)
View(edge_df_weighted)
library(igraph)
new_g <- graph_from_data_frame(edge_df_weighted[,c('cluster_a', 'cluster_b', 'weight')], directed = FALSE)
is_weighted(new_g)
new_adjacency <- as_adjacency_matrix(new_g, type='both', sparse=FALSE, attr = 'weight') %>% as.data.frame()
new_adjacency_lower <- as_adjacency_matrix(new_g, type='lower', sparse=FALSE, attr = 'weight') %>% as.data.frame()
View(new_adjacency_lower)
write.csv(new_adjacency, row.names = TRUE, file='new_adj.csv')
write.csv(new_adjacency_lower, row.names = TRUE, file='new_adj_lower.csv')
getwd()
View(updated_summary)
View(firms_selected)
colnames(updated_summary)
View(firms_selected)
View(new_adjacency)
View(edge_matrix_weighted)
# Firms in the old and in the new
firms_intesect <- gmo_uparents_map_new |> filter(label %in% gmo_uparents_map_old$label) |> select(all_of(colnames(gmo_uparents_map_new)))
firms_old <- gmo_uparents_map_old |> filter(!label %in% gmo_uparents_map_new$label) |> select(all_of(colnames(intersect(gmo_uparents_map_old, gmo_uparents_map_new))))
firms_old <- gmo_uparents_map_old |> filter(!label %in% gmo_uparents_map_new$label) |> select(all_of(intersect(colnames(gmo_uparents_map_old),
colnames(gmo_uparents_map_new))))
firms_new <- gmo_uparents_map_new |> filter(!label %in% gmo_uparents_map_old$label, `weight<Documents>` >= 10) |> select(all_of(colnames(gmo_uparents_map_new)))
firms_selected <- bind_rows(firms_intesect, firms_new, firms_old)
firms_selected$old_cluster <- gmo_uparents_map_old$cluster[match(firms_selected$label, gmo_uparents_map_old$label)]
firms_selected$new_cluster <- gmo_uparents_map_new$cluster[match(firms_selected$label, gmo_uparents_map_new$label)]
firms_selected$fixed_cluster <- sapply(firms_selected$old_cluster, function(x) {x <= 20})
# Add firms to the original 20 clusters.
for (idx in c(1:nrow(firms_selected))) {
this_old_cluster <- firms_selected$old_cluster[idx]
print(this_old_cluster)
if (!is.na(this_old_cluster) & this_old_cluster <= 20) {
print('use old cluster')
fixed_cluster <- this_old_cluster
} else {
this_new_cluster <- firms_selected$new_cluster[idx]
if (!is.na(this_new_cluster)) {
print('inferring cluster')
for (cl in c(1:20)) {
if (this_new_cluster %in% as.numeric(names(table(firms_selected$new_cluster[firms_selected$old_cluster == cl])))) {
fixed_cluster <- cl
}
}
} else {
print('no cluster')
fixed_cluster <- 0
}
}
firms_selected$fixed_cluster[idx] <- fixed_cluster
}
table(firms_selected$fixed_cluster) |> sort(decreasing = TRUE)
updated_summary_links <- firms_selected %>%
arrange(desc(`weight<Links>`)) %>%
group_by(fixed_cluster) %>%
dplyr::summarize(
hub = label[1],
firms = n(),
links = `weight<Links>`[1],
patents = `weight<Documents>`[1]
)
updated_summary_docs <- firms_selected |>
group_by(fixed_cluster) |>
arrange(desc(`weight<Documents>`)) |>
dplyr::summarize(
hub = label[1],
firms = n(),
links = `weight<Links>`[1],
patents = `weight<Documents>`[1]
)
# Merge them
updated_summary <- merge(updated_summary_links,
updated_summary_docs,
by = 'fixed_cluster',
all.x = TRUE,
all.y = TRUE,
suffixes = c('_by_LINKS', '_by_PATENTS'))
# Remove cluster 0
updated_summary <- updated_summary[updated_summary$fixed_cluster != 0,]
# Arrange
updated_summary <- updated_summary[,c('fixed_cluster', 'firms_by_LINKS',
"hub_by_LINKS", "links_by_LINKS", "patents_by_LINKS",
"hub_by_PATENTS", "links_by_PATENTS", "patents_by_PATENTS")]
# Rename
updated_summary <- updated_summary %>% rename(c('cluster' = 'fixed_cluster',
'firms' = 'firms_by_LINKS'))
# Save
write.csv(updated_summary, file='updated_summary.csv')
write.csv(firms_selected[firms_selected$fixed_cluster != 0], file='firms_selected.csv')
write.csv(firms_selected[firms_selected$fixed_cluster != 0,], file='firms_selected.csv')
# ====================================================
# Network to get weights
network <- readr::read_table("~/Library/CloudStorage/OneDrive-Personal/Documentos/00-Research projects/58 - GMO - Deals and Patents/Patents/02-Results/20240624/net.txt",
col_names = FALSE)
colnames(network) <- c('a', 'b', 'weight')
network$cluster_a <- firms_selected$fixed_cluster[match(network$a, firms_selected$id)] |> as.character()
network$cluster_b <- firms_selected$fixed_cluster[match(network$b, firms_selected$id)] |> as.character()
network <- network |>
filter(!is.na(cluster_a), !is.na(cluster_b), cluster_a != 0, cluster_b != 0) |>
as.data.frame()
edge_matrix_simple <- table(network$cluster_a, network$cluster_b) |> as.matrix.data.frame()
network_backup <- network
##############
network$better_a <- sapply(c(1:nrow(network)), function(x) {
min(as.numeric(network$cluster_a[x]), as.numeric(network$cluster_b[x]))
})
network$better_b <- sapply(c(1:nrow(network)), function(x) {
max(as.numeric(network$cluster_a[x]), as.numeric(network$cluster_b[x]))
})
edge_df_weighted <- network |>
group_by(better_a, better_b) |>
dplyr::summarize(
weight = sum(weight, na.rm = TRUE)
) |>
ungroup() |>
mutate(
cluster_a = as.numeric(better_a),
cluster_b = as.numeric(better_b)
) |>
arrange(
cluster_b,
cluster_a
)
library(igraph)
new_g <- graph_from_data_frame(edge_df_weighted[,c('cluster_a', 'cluster_b', 'weight')], directed = FALSE)
is_weighted(new_g)
new_adjacency <- as_adjacency_matrix(new_g, type='both', sparse=FALSE, attr = 'weight') %>% as.data.frame()
new_adjacency_lower <- as_adjacency_matrix(new_g, type='lower', sparse=FALSE, attr = 'weight') %>% as.data.frame()
write.csv(new_adjacency, row.names = TRUE, file='new_adj.csv')
#write.csv(new_adjacency_lower, row.names = TRUE, file='new_adj_lower.csv')
getwd()
nrow(dataset) - nrow(dataset_filtered)
getwd()
write.csv(table(dataset_filtered$PY), file='years_updated.csv')
getwd()
load("~/Library/CloudStorage/OneDrive-Personal/Documentos/03-bibliometrics/Q232/001/level0/environ_zz_reports.rdata")
View(rcs)
colnames(dataset)
colnames(rcs)
tmp <- rcs[,c('cluster', 'cluster_year', 'hub_title', 'Countries', 'ID')]
write.csv(tmp, file = 'palm_oil.csv', row.names = TRUE)
getwd()
View(rcs)
# Call necessary libraries
library(plyr)
library(Opener5)
library(data.table)
library(dplyr)
library(stringr)
library(tm)
choose.files()
file.choose()
###########################################################################################
# OPTIONS
###########################################################################################
## Query_id
## This has de form Qxxx whith the query number from the query control file
dataset_metadata <- list("query_id" = "Qgmo",
"fukan_url" = "Not apply. Directly from WOS")
# Open a window to select the directory with the files to merge
#dir_path = "/Users/cristian/Library/CloudStorage/OneDrive-Personal/Documentos/00-Research projects/58 - GMO - Deals and Patents/Patents/00-Data/Update20240505"
dir_path = "/Users/cristian/Library/CloudStorage/OneDrive-Personal/Documentos/imacros/downloads/Q299 kubota and competitors"
paths_to_files = list.files(path = dir_path, full.names= TRUE, pattern = "*.csv", recursive = TRUE)
paths_to_files = paths_to_files[grepl('.csv$', paths_to_files)]
###########################################################################################
## Path to `/inputs`
# Here 'input' refer to the inputs for clustering.
# From the pov of this very code, this is actually the output folder. Where the files generated by this code will be placed.
bibliometrics_folder <- "/Users/cristian/Library/CloudStorage/OneDrive-Personal/Documentos/03-bibliometrics" # Mac
#bibliometrics_folder <- "C:\\Users\\crist\\OneDrive\\Documentos\\03-bibliometrics" # Windows
dir.create(file.path(bibliometrics_folder, dataset_metadata$query_id), showWarnings = TRUE)
###########################################################################################
# OPTIONS
###########################################################################################
## Query_id
## This has de form Qxxx whith the query number from the query control file
dataset_metadata <- list("query_id" = "Q299 2nd",
"fukan_url" = "Not apply. Directly from WOS")
###########################################################################################
## Path to `/inputs`
# Here 'input' refer to the inputs for clustering.
# From the pov of this very code, this is actually the output folder. Where the files generated by this code will be placed.
bibliometrics_folder <- "/Users/cristian/Library/CloudStorage/OneDrive-Personal/Documentos/03-bibliometrics" # Mac
#bibliometrics_folder <- "C:\\Users\\crist\\OneDrive\\Documentos\\03-bibliometrics" # Windows
dir.create(file.path(bibliometrics_folder, dataset_metadata$query_id), showWarnings = TRUE)
# Read each file and store them in a vector
# fread sometimes fails when reading the header, what to do?
list_of_all_files <- lapply(paths_to_files, function(a_path){
data1 <- readr::read_csv(a_path, skip = 1)
return(data1)})
# Verify than the files have the expected number of rows: 500. Except for a few that were the tails.
plot(unlist(sapply(list_of_all_files, nrow))) #The number of rows in each file, mostly 500.
# Create the merged dataset
dataset <- rbind.fill(list_of_all_files)
dataset <- as.data.frame(dataset)
dataset$X_N <- c(1:nrow(dataset))
load("~/Library/CloudStorage/OneDrive-Personal/Documentos/00-Research projects/58 - GMO - Deals and Patents/Patents/02-Results/20240624/computed with R/dataset_filtered_20240624.rdata")
View(dataset_filtered)
load("~/Library/CloudStorage/OneDrive-Personal/Documentos/03-bibliometrics/Qgmo/001/level0/environ_zz_reports.rdata")
min(dataset$PY)
dataset$TI[dataset$PY < 1980,]
dataset$TI[dataset$PY < 1980]
dataset$TI[dataset$PY < 1990]
dataset$TI[dataset$PY < 1980]
dataset$TI[dataset$PY < 1985]
dataset$TI[dataset$PY < 1976]
ttt <- dataset[dataset$PY < 1976,]
View(ttt)
ttt$AB
dataset$AB[100]
sum(grepl('; ' dataset_filtered$AU))
sum(grepl('; ', dataset_filtered$AU))
ttt <- dataset_filtered %>% filter(grepl('; ', AU))
library(dplyr)
ttt <- dataset_filtered %>% filter(grepl('; ', AU))
# Total entities
dataset_filtered$AU %>% strsplit(., '; ') %>% unlist() %>% table() %>% sort(decreasing = TRUE)
# Total entities
dataset_filtered$AU %>% strsplit(., '; ') %>% unlist() %>% table() %>% sort(decreasing = TRUE) %>% length()
ttt$AU %>% strsplit(., '; ') %>% unlist() %>% table() %>% sort(decreasing = TRUE)
# Total entities
dataset_filtered$AU %>% strsplit(., '; ') %>% unlist() %>% table() %>% sort(decreasing = TRUE) %>% length()
ttt$AU %>% strsplit(., '; ') %>% unlist() %>% table() %>% sort(decreasing = TRUE) %>% length()
2642/6020
