source("04_utils/zz_createJSON_cnet.R")
source("03_reports/06_citation_to_topic_model_converter.R")
source("03_reports/07_prob_exclu_keywords.R")
}
# Create the Keywords report
if (level_report <= 4) {
print("Keywords report")
source("03_reports/08_all_keywords_report.R")
# Optional views
# source("03_reports/09_keywords_per_clusters.R")
source("03_reports/10_rcs_keywords.R")
}
zz_env$x05 <- c(zz_env$x04, "papersText", "myDataCorrect_SAMPLE", "unified_keywords", "PHI", "from_stem_to_raw")
# Overlays (Only for WOS data)
if (settings$params$dataset_source == "wos") {
source(file.path(getwd(), "03_reports", "13_WC_overlays.R"))
}
############################################################################
# Dataset merged RCS
source(file.path(getwd(), "03_reports", "15_rcs_merged.R"))
# figures
# Save PNG figures. Normal raster figures for easy navigation in PC.
print("###################### PNG CHARTS")
extension <- 'png'
subfolder_dataset <- "charts_dataset"
subfolder_clusters <- "charts_clusters"
source(file.path(getwd(), "zz-charts_dataset.R"))
source(file.path(getwd(), "zz-charts_clusters_scatterplots.R"))
source(file.path(getwd(), "zz-charts_clusters_stats1_bp.R"))
source(file.path(getwd(), "zz-charts_clusters_stats2_bars.R"))
source(file.path(getwd(), "zz-charts_clusters_stats3_lda.R"))
source(file.path(getwd(), "zz-charts_clusters_stats4_heatmap.R"))
source(file.path(getwd(), "zz-charts_trends_and_clustered_bars.R"))
# Save PNG figures. Needed for notebook.
print("###################### SVG CHARTS")
extension <- 'svg'
subfolder_dataset <- "index_files/charts"
subfolder_clusters <- "index_files/charts"
source(file.path(getwd(), "zz-charts_dataset.R"))
source(file.path(getwd(), "zz-charts_clusters_scatterplots.R"))
source(file.path(getwd(), "zz-charts_clusters_stats1_bp.R"))
source(file.path(getwd(), "zz-charts_clusters_stats2_bars.R"))
source(file.path(getwd(), "zz-charts_clusters_stats3_lda.R"))
source(file.path(getwd(), "zz-charts_clusters_stats4_heatmap.R"))
source(file.path(getwd(), "zz-charts_trends_and_clustered_bars.R"))
############################################################################
# Save complete environment by level. First remove unnecessary variables
print("Saving image")
#rm(list = setdiff(ls(), zz_env$x05))
save.image(rn$PROJECTenviron)
# Time per level
time_02_finished <- Sys.time()
time_03_taken <- time_02_finished - time_01_started
print(time_03_taken)
}
print("###################### reports/01_document_report_with_abstract.R")
# Helper function to get urls from DOI
convert_doi_to_url <- function(a_list_of_DOI) {
a_list_of_DOI[is.na(a_list_of_DOI)] <- ""
sapply(a_list_of_DOI, function(x) {
if (nchar(x) > 0) {
paste("https://doi.org/", x, sep = "")
} else {
x
}
})
}
settings$rp$article_report_columns %>% unlist()
# Find which colnames exist.
# This define which columns and in which order they will appear in the article report
columns_in_myDataCorrect <- intersect(
c(
"X_C", "cluster_code",
"topic", "related_topics", "TD",
"AU", "PY", "DI", "TI", "AB", "Z9", "X_E", "DE", "SO", "WC", "Countries", "sentiment", "sentiment_factor", "Page_Rank", "Eigen", "Closeness", "Betweenness", "UT"
),
colnames(myDataCorrect)
)
# Create the file
article_report <- myDataCorrect %>% select(all_of(columns_in_myDataCorrect))
## Format columns
# Format DOI
if ("DI" %in% colnames(article_report)) {
article_report$DI <- convert_doi_to_url(article_report$DI)
}
# Replace NA by empty character
article_report[is.na(article_report)] <- ""
# Filter to the top_documents of each cluster
if (settings$rp$top_documents != 0) {
article_report <- article_report %>%
group_by(X_C) %>%
top_n(settings$rp$top_documents, X_E)
}
# Clean the columns
article_report$Z9 <- as.integer(article_report$Z9)
article_report$Z9[is.na(article_report$Z9)] <- 0
article_report$PY <- as.integer(article_report$PY)
article_report$PY[is.na(article_report$PY)] <- median(article_report$PY, na.rm = TRUE)
# Order the report
article_report <- article_report[order(article_report$X_C,
-article_report$X_E,
-article_report$Z9,
-article_report$PY),]
# Change colnames to natural names
setnames(article_report,
names(settings$rp$column_labels),
unname(settings$rp$column_labels),
skip_absent = TRUE)
settings$rp$column_labels
names(settings$rp$column_labels)
unname(settings$rp$column_labels)
unname(settings$rp$column_labels) %>% unlist()
# Change colnames to natural names
setnames(article_report,
names(settings$rp$column_labels),
unname(settings$rp$column_labels) %>% unlist(),
skip_absent = TRUE)
# Write the article report
write.csv(article_report,
file = rn$PROJECTarticlereport,
row.names = FALSE)
# Cleaning up
rm('columns_in_myDataCorrect')
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(20, Degree)
}
# Write the article report
write.csv(article_report_20,
file = gsub('_report', '_report_20', rn$PROJECTarticlereport),
row.names = FALSE)
dataset_minimal %>% columns()
dataset_minimal %>% colnames()
# Find which colnames exist.
# This define which columns and in which order they will appear in the article report
potential_columns <- c(
"X_C", "cluster_code",
"topic", "related_topics", "TD",
"AU", "PY", "DI", "TI", "AB", "Z9", "X_E", "DE", "SO", "WC", "Countries", "sentiment", "sentiment_factor", "UT",
"global_degree", "global_in_degree", "global_page_rank"
)
if (as.numeric(settings$cno$thresholding$recursive_level) == 0) {
potential_columns <- c(potential_columns, "level0_page_rank",  "level0_degree", "level0_in_degree" )
}
potential_columns
if (level_report == 0) {
potential_columns <- c(potential_columns, "level0_page_rank",  "level0_degree", "level0_in_degree" )
}
potential_columns
if (level_report == 1) {
potential_columns <- c(potential_columns, "level1_page_rank",  "level1_degree", "level1_in_degree" )
}
potential_columns
# Retain what's available
columns_in_myDataCorrect <- intersect(
potential_columns,
colnames(myDataCorrect)
)
# Create the file
article_report <- myDataCorrect %>% select(all_of(columns_in_myDataCorrect))
## Format columns
# Format DOI
if ("DI" %in% colnames(article_report)) {
article_report$DI <- convert_doi_to_url(article_report$DI)
}
# Replace NA by empty character
article_report[is.na(article_report)] <- ""
# Filter to the top_documents of each cluster
if (settings$rp$top_documents != 0) {
article_report <- article_report %>%
group_by(X_C) %>%
top_n(settings$rp$top_documents, X_E)
}
# Clean the columns
article_report$Z9 <- as.integer(article_report$Z9)
article_report$Z9[is.na(article_report$Z9)] <- 0
article_report$PY <- as.integer(article_report$PY)
article_report$PY[is.na(article_report$PY)] <- median(article_report$PY, na.rm = TRUE)
# Order the report
article_report <- article_report[order(article_report$X_C,
-article_report$X_E,
-article_report$Z9,
-article_report$PY),]
# Change colnames to natural names
setnames(article_report,
names(settings$rp$column_labels),
unname(settings$rp$column_labels) %>% unlist(),
skip_absent = TRUE)
# Write the article report
write.csv(article_report,
file = rn$PROJECTarticlereport,
row.names = FALSE)
# Cleaning up
rm('columns_in_myDataCorrect')
# Filter to the top_documents of each cluster
if (settings$rp$top_documents == 0) {
article_report_20 <- article_report %>%
group_by(Cluster) %>%
top_n(20, Degree)
}
# Write the article report
write.csv(article_report_20,
file = gsub('_report', '_report_20', rn$PROJECTarticlereport),
row.names = FALSE)
###############################################################################
###############################################################################
###############################################################################
# Reporting clusters
source(file.path(getwd(),
"02_citation_network",
"01_execute_and_reports.R"))
# 20181206 Cluster summaries
print("###################### reports/04_cluster_reports.R")
# Load utils
source("04_utils/zz_auxiliary_functions.R")
# INPUT
list_of_clusters <- myDataCorrect$X_C %>%
unique() %>%
sort()
available_columns <- colnames(myDataCorrect)
## Check the columns that are actually available
categorical_long_reports <- settings$rp$categorical_long_reports %>% unlist() %>% .[. %in% available_columns]
categorical_simple_wide_reports <- settings$rp$categorical_simple_wide_reports %>% unlist() %>% .[. %in% available_columns]
categorical_multi_wide_reports <- settings$rp$categorical_multi_wide_reports %>% unlist() %>% .[. %in% available_columns]
numerical_reports <- settings$rp$numerical_reports %>% unlist() %>% .[. %in% available_columns]
##################################################################
## Utils:
#' @description
#' Creates summary df properly formatted by removing NAs and adjusting for the items found
#' @param a_table TABLE. Usually the output of `TopSomething()`
#' @param a_cluster INTEGER. The cluster being formatted.
#' @param top INTEGER. the number of results to include in the report
#' @returns DATAFRAME. A long shaped data frame
format_long_table <- function(a_table, a_cluster, top) {
## Update the table to remove possible NAs
a_table <- a_table[!is.na(a_table)]
if (length(a_table) >= 1) {
## Update "top" in case the table contains fewer values.
top1 <- min(top, length(a_table))
data.frame(toupper(names(a_table)), unname(a_table), rep(a_cluster, top1))
}
}
#' @description
#' Creates a long report based on selected column.
#' @param df DATAFRAME. Usually `myDataCorrect`.
#' @param a_column STRING. the name of the column to summarize
#' @param clusters LIST[INTEGERS]. a list of clusters to include in the summary
#' @param top INTEGER. the number of results to include in the report
#' @param with_all BOOL. if the summary including all data should be include as `Cluster 0`
#' @returns Nothing. --> It writes a .csv with the report.
generate_long_report <- function(df, a_column, clusters, top, with_all = TRUE) {
## Get clusters' results
result_list <- lapply(clusters, function(c) {
cluster_data <- subset(df, df$"X_C" == c)
cluster_tops <- TopSomething(cluster_data, coll = a_column, top = top)
return(format_long_table(cluster_tops, a_cluster = c, top = top))
}) %>% rbind.fill()
if (ncol(result_list) > 4) {
result_list <- result_list[, c(1:4)]
}
## Insert `cluster 0` summary
if (with_all & a_column != 'AU') {
cluster_zero <- TopSomething(df, coll = a_column, top = top) %>%
format_long_table(a_cluster = 0, top = top)
result_list <- rbind(cluster_zero, result_list)
}
## Romat and write
if (ncol(result_list) ==3) {
colnames(result_list) <- c(a_column, "Freq", "Cluster")
}
if (ncol(result_list) == 4) {
colnames(result_list) <- c(a_column, "X", "Freq", "Cluster")
}
result_list$X <- NULL
result_list <- result_list[!is.na(result_list[, c(a_column)]), ]
write.csv(result_list, file = file.path(output_folder_level, paste("report_", a_column, ".csv", sep = "")), row.names = FALSE)
}
## Write reports
for (cc in categorical_long_reports) {
generate_long_report(df = myDataCorrect, a_column = cc, clusters = list_of_clusters, top = settings$rp$top_items)
}
generate_categorical_simple_wide_reports <- function(df, a_column) {
# Creates a `clusters x a_column` reports for frequencies and proportions based on selected column.
# This column has a single value per record e.g. PY
# df = a data frame. Usually `myDataCorrect` or any other with X_C column
# a_column = the column to summarize
# clusters = a list of clusters to include in the summary
cluster_frequencies <- table(df$X_C, df[, a_column]) %>% as.matrix()
cluster_proportions <- prop.table(cluster_frequencies, 2)
cluster_frequencies <- cbind("cluster" = row.names(cluster_frequencies), cluster_frequencies)
cluster_proportions <- cbind("cluster" = row.names(cluster_proportions), cluster_proportions)
write.csv(cluster_frequencies,
file = file.path(output_folder_level, paste("report_", a_column, "_frequencies.csv", sep = "")),
row.names = FALSE
)
write.csv(cluster_proportions,
file = file.path(output_folder_level, paste("report_", a_column, "_proportions.csv", sep = "")),
row.names = FALSE
)
}
generate_categorical_multi_wide_reports <- function(df, a_column, clusters) {
# Creates a `clusters x a_column` reports for frequencies and proportions based on selected column.
# This column has a multiple values per record e.g. WC because a paper can be "Engineering; Finances"
# df = a data frame. Usually `myDataCorrect` or any other with X_C column
# a_column = the column to summarize
# clusters = a list of clusters to include in the summary
column_summary <- df[, a_column] %>%
strsplit(., split = "; ") %>%
unlist() %>%
table() %>%
sort(., decreasing = TRUE)
# Define the max number of categories to analyze
max_cols <- if (length(names(column_summary)) > 100) {
100
} else {
length(names(column_summary))
}
column_summary <- column_summary[1:max_cols]
# WC frequencies by cluster
cluster_frequencies <- lapply(clusters, function(x) {
temp <- df[, a_column][which(df$X_C == x)]
column_summary <- temp %>%
strsplit(., split = "; ") %>%
unlist() %>%
table() %>%
as.matrix() %>%
t() %>%
data.frame(., stringsAsFactors = FALSE, check.names = FALSE)
if (ncol(column_summary) == 0) {
column_summary <- data.frame("no_data" = 1)
}
return(column_summary)
}) %>%
rbindlist(., fill = TRUE) %>%
as.data.frame() %>%
.[, names(column_summary)[1:max_cols]]
cluster_frequencies[is.na(cluster_frequencies)] <- 0
cluster_proportions <- t(t(as.matrix(cluster_frequencies)) / as.integer(column_summary))
cluster_frequencies <- cbind("cluster" = clusters, cluster_frequencies)
cluster_proportions <- cbind("cluster" = clusters, cluster_proportions)
write.csv(cluster_frequencies,
file = file.path(output_folder_level, paste("report_", a_column, "_frequencies.csv", sep = "")),
row.names = FALSE
)
write.csv(cluster_proportions,
file = file.path(output_folder_level, paste("report_", a_column, "_proportions.csv", sep = "")),
row.names = FALSE
)
}
generate_numerical_report <- function(df, a_column, clusters, with_all = TRUE) {
# Creates a  numeric summary (min, mean, meadian, max, sd) report based on selected column.
# df = a data frame. Usually `myDataCorrect` or any other with X_C column
# a_column = the column to summarize
# clusters = a list of clusters to include in the summary
# with_all = if the summary including all data should be include as `Cluster 0`
## Get clusters' results
result_list <- lapply(clusters, function(c) {
cluster_data <- subset(df, df$"X_C" == c)
tmp <- summary(cluster_data[, a_column]) %>%
as.matrix() %>%
t() %>%
data.frame()
tmp$sd <- sd(cluster_data[, a_column], na.rm = TRUE) %>% round(3)
tmp$cluster <- c
return(tmp)
}) %>% rbind.fill()
## Insert `cluster 0` summary
if (with_all) {
cluster_zero <- summary(df[, a_column]) %>%
as.matrix() %>%
t() %>%
data.frame()
cluster_zero$sd <- sd(df[, a_column]) %>% round(3)
cluster_zero$cluster <- 0
result_list <- rbind.fill(cluster_zero, result_list)
}
## Format and write
write.csv(result_list,
file = file.path(output_folder_level, paste("report_", a_column, ".csv", sep = "")),
row.names = FALSE
)
}
## Write reports
for (cc in categorical_long_reports) {
generate_long_report(df = myDataCorrect, a_column = cc, clusters = list_of_clusters, top = settings$rp$top_items)
}
for (cc in categorical_simple_wide_reports) {
generate_categorical_simple_wide_reports(df = myDataCorrect, a_column = cc)
}
for (cc in categorical_multi_wide_reports) {
generate_categorical_multi_wide_reports(df = myDataCorrect, a_column = cc, clusters = list_of_clusters)
}
for (cc in numerical_reports) {
generate_numerical_report(df = myDataCorrect, a_column = cc, clusters = list_of_clusters)
}
# Cleaning up
rm('cc','list_of_clusters', 'available_columns',
'categorical_long_reports', 'categorical_simple_wide_reports',
'categorical_multi_wide_reports', 'numerical_reports')
#####################################################
#####################################################
print("###################### reports/02_rcs.R")
# Computed
myDataCorrect$PY <- as.character(myDataCorrect$PY) %>% as.integer()
id_com <- sort(unique(myDataCorrect$"X_C"))
network_year <- round(mean(myDataCorrect$PY, na.rm = TRUE), digits = 1)
# Create a summary with information of each cluster
# per each cluster a list of data frames is created (one data frame per core patent)
values <- lapply(id_com, function(cluster) {
cluster_data <- myDataCorrect[myDataCorrect$"X_C" == cluster,]
cluster_size <- length(cluster_data$"X_C")
cluster_year <- round(mean(cluster_data$PY, na.rm = TRUE), digits = 1)
cluster_code <- names(table(cluster_data$cluster_code))
sum_cites <- sum(cluster_data$"Z9", na.rm = TRUE)
ave_cites <- sum_cites / cluster_size
degrees <- cluster_data$X_E
dmax <- max(degrees, na.rm = TRUE)
max_degrees <- cluster_data$"X_N"[which(degrees == dmax)][1] # get the id of the documents with highest degree #Remove "[1]" at the end to obtain multiple core papers per cluster
rows <- lapply(max_degrees, function(y) {
hub_year_temp <- cluster_data$"PY"[which(cluster_data$"X_N" == y)]
hub_year <- if (is.na(hub_year_temp)) {
cluster_year
} else {
hub_year_temp
}
hub_title <- cluster_data$"TI"[which(cluster_data$"X_N" == y)]
hub_type1 <- if (settings$params$dataset_source != "wos") {
"ARTICLE"
} else {
toupper(cluster_data$"DT"[which(cluster_data$"X_N" == y)])
} # Whether a paper was classified as Review by WOS
hub_type2 <- if (grepl("overview|review|survey", tolower(hub_title))) {
"REVIEW"
} else {
"ARTICLE"
} # Whether it is a review by the title
hub_ID <- y
row <- data.frame(
cluster, cluster_code,
network_year, cluster_year,
hub_year, hub_title, hub_ID, hub_type1, hub_type2,
dmax, sum_cites, ave_cites, cluster_size
)
return(row)
})
valid_fields <- settings$rp$categorical_long_reports %>% unlist()
valid_fields <- valid_fields[valid_fields %in% colnames(cluster_data)]
tt <- c()
for (i in c(1:length(valid_fields))) {
tt[i] <- paste(names(TopSomething(cluster_data, coll = valid_fields[i])), collapse = "; ") %>% tolower()
}
names(tt) <- valid_fields
tops <- data.frame(as.list(tt))
return(cbind(rows, tops))
})
# convert lists of data frames into single data frame
rcs <- rbindlist(values) %>% as.data.frame()
# Calculate participation
# Participation is the proportion of papers within the cluster connected to the hub
rcs$participation <- round(rcs$dmax / rcs$cluster_size, 3)
# Calculate RCS Labels
rcs$X <- rcs$cluster_year - rcs$network_year
rcs$Y <- rcs$hub_year - rcs$cluster_year
rcs$X[is.na(rcs$X)] <- 0
rcs$Y[is.na(rcs$Y)] <- 0
# Add labels
labels <- sapply(1:nrow(rcs), function(z) {
x <- rcs$X[z]
y <- rcs$Y[z]
name <- if (x > 0 & y > 0) {
"Change Maker"
} else if (x > 0 & y < 0) {
"Incremental"
} else if (x < 0 & y > 0) {
"Breaktrough"
} else if (x < 0 & y < 0) {
"Matured"
}
# else {"OTHER"}})
# The appearance of the following may imply error in calculations
else if (x == 0 & y > 0) {
"B & CM"
} else if (x == 0 & y < 0) {
"M & I"
} else if (x > 0 & y == 0) {
"CM & I"
} else if (x < 0 & y == 0) {
"B & M"
} else {
"CENTERED"
}
})
rcs$label <- labels
## Needs the PY prop table computed in cluster reports
# Find growing clusters
growth_finder <- function(a_prop_matrix, a_range) {
a_mat <- a_prop_matrix[, c((ncol(a_prop_matrix) - a_range + 1):ncol(a_prop_matrix))]
b_mat <- a_prop_matrix[, c((ncol(a_prop_matrix) - a_range):(ncol(a_prop_matrix) - 1))]
c_mat <- a_mat - b_mat
scores <- rowSums(c_mat) / (a_range - 1)
return(scores)
}
# By best speed use proportions, by best amount of publication use frequencies
# By comparing the growing rate of the last 4 years "growth_rate" = growth_rate
cluster_year_proportions <- read.csv(file.path(output_folder_level, "report_PY_proportions.csv"))
rcs$growth_rate <- growth_finder(cluster_year_proportions, 4)
# Write RCS
write.csv(rcs, file = rn$PROJECTrcs, row.names = FALSE)
# cleaning up
rm('id_com', 'network_year', 'values', 'labels', 'cluster_year_proportions')
