"topic_model.png"),
plot = tm_plot,
width = 8,  # Width in inches
height = 6, # Height in inches
dpi = 300   # Resolution (dots per inch)
)
# Same as above without labels (Good for subcluster)
tm_plot <- plot_scatter_group(tmp,
point_labels = "cluster_code",
x_column = "x",
y_column = "y",
color_hex_column = "color",
color_labels = "dataset",
size_column = "documents",
show_tags = FALSE)
tm_plot
ggsave(
filename = file.path(
output_folder_path,
settings$metadata$heatmap_analysis_id,
"topic_model_no_tags.png"),
plot = tm_plot,
width = 8,  # Width in inches
height = 6, # Height in inches
dpi = 300   # Resolution (dots per inch)
)
# PY Z9 plots
for (inst in unique(tmp$dataset)) {
print(inst)
p <- plot_scatter(tmp %>% filter(dataset == inst),
point_labels = "scatter_labels", # "scatter_labels" for the full cluster name. # "local_cluster" for the cluster code only
x_column = "PY_Mean",
y_column = "Z9_Mean",
color_hex_column = "color",
color_labels = "dataset",
size_column = "documents",
min_x = min(tmp$PY_Mean, na.rm = TRUE) %>% floor(),
max_x = max(tmp$PY_Mean, na.rm = TRUE) %>% ceiling(),
max_y = max(tmp$Z9_Mean, na.rm = TRUE) %>% ceiling(),
show_tags = TRUE)
ggsave(
filename = file.path(
output_folder_path,
settings$metadata$heatmap_analysis_id,
paste("scatter_plot_", inst, ".png", sep = "")),
plot = p,
width = 8,  # Width in inches
height = 6, # Height in inches
dpi = 300   # Resolution (dots per inch)
)
}
###############################################################################
###############################################################################
# Heatmap
hm <- readr::read_csv(file.path(
output_folder_path,
settings$metadata$heatmap_analysis_id,
"heatmap_matrix.csv"
)) %>% as.data.frame()
rownames(hm) <- colnames(hm)
# Create a sorting vector
sort_vector <- sort(colnames(hm))
# Sort the heatmap
hm_sorted <- hm[sort_vector, sort_vector]
# Convert matrix to long format for ggplot
df_long <- hm_sorted %>% as.matrix() %>% melt()
# Create heatmap
tm_hm <- ggplot(df_long, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "red") +
theme_minimal() +
coord_fixed() +  # make cells square
labs(x = "", y = "", fill = "Similarity") +  # label axes
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # rotate x labels for better readability
tm_hm
ggsave(
plot = tm_hm,
filename = file.path(
output_folder_path,
settings$metadata$heatmap_analysis_id,
"heatmap.png"),
width = 8,  # Width in inches
height = 6, # Height in inches
dpi = 300   # Resolution (dots per inch)
)
# # Using base R heatmap
# heatmap(as.matrix(hm_sorted),
#         Rowv = NA,  # prevent row clustering
#         Colv = NA,  # prevent column clustering
#         col = colorRampPalette(c("white", "red"))(100),
#         scale = "none")
###############################################################################
###############################################################################
# melted: The heatmap matrix melted.
# melted_filtered: Only those beyond threshold and that connect the next step in the path in the sankey
# melted_listed: Same data as `melted_filtered` but stacked. Used as intermediary processing table.
# melted_sankey: The data formatted as needed for Flourish
# melted_sankey_topics: Same as `melted_sankey` but with topic names
# Sankey
melted <- readr::read_csv(file.path(
output_folder_path,
settings$metadata$heatmap_analysis_id,
"heatmap_melted.csv"
))
melted <- melted %>%
separate(Source,
remove = FALSE,
into = c("source_dataset", "source_local_cluster"),
sep = "-") %>%
separate(Target,
remove = FALSE,
into = c("target_dataset", "target_local_cluster"),
sep = "-")
melted <- merge(melted,
inputs %>%
select(display_name, color, heatmap_display_order, sankey_display_order) %>%
rename(source_color = color,
source_heatmap_order = heatmap_display_order,
source_sankey_order = sankey_display_order),
by.x = "source_dataset",
by.y = "display_name",
all.x = TRUE,
all.y = FALSE)
melted <- merge(melted,
inputs %>%
select(display_name, color, heatmap_display_order, sankey_display_order) %>%
rename(target_color = color,
target_heatmap_order = heatmap_display_order,
target_sankey_order = sankey_display_order),
by.x = "target_dataset",
by.y = "display_name")
###############################################################################
png(filename = file.path(
output_folder_path,
settings$metadata$heatmap_analysis_id,
"similarity_boxplot.png"))
dev.off()
###############################################################################
# Thresholding
# Statistic threshold
bp <- boxplot(melted %>%
filter(source_sankey_order != target_sankey_order) %>%
pull(Similarity),
ylab = "Similarity")
bp$stats[3,1] #mean
bp$stats[4,1] #3rd quartile
settings$global$sankey_threshold #selected
sankey_threshold <- bp$stats[4,1]#settings$global$sankey_threshold
# Remove pairs in the same sankey level (they belong to same institution)
# Remove pairs in separated for more than one step
melted_filtered <- melted %>%
filter(source_sankey_order != target_sankey_order) %>%
#filter(abs(source_sankey_order - target_sankey_order) == 1) %>%
filter(Similarity >= sankey_threshold)
sankey_steps <- unique(inputs$sankey_display_order) %>% sort()
# Stacking the datasets to reorder them
melted_filtered$pair_index <- c(1:nrow(melted_filtered)) %>% as.character()
sources_df <- lapply(sankey_steps, \(st) {
tmp <- melted_filtered %>%
filter(source_sankey_order == st) %>%
select(Source, source_sankey_order, Similarity, pair_index) %>%
rename(cluster = Source,
step = source_sankey_order,
similarity = Similarity)
}) %>% rbind.fill()
targets_df <- lapply(sankey_steps, \(st) {
tmp <- melted_filtered %>%
filter(target_sankey_order == st) %>%
select(Target, target_sankey_order, Similarity, pair_index) %>%
rename(cluster = Target,
step = target_sankey_order,
similarity = Similarity)
}) %>% rbind.fill()
melted_listed <- rbind(sources_df, targets_df)
###############################################################################
melted_sankey <- lapply(c(0, max(sankey_steps) - 1), function(st) {
left_side <- melted_listed %>%
filter(step == st)
right_side <- melted_listed %>%
filter(step > st) # filter(step == st + 1) when strictly step by step
full_pair <- merge(left_side %>%
select(cluster, step, similarity, pair_index) %>%
rename(Source = cluster, "Step from" = step, source_similarity = similarity),
right_side %>%
select(cluster, step, similarity, pair_index) %>%
rename(Dest = cluster, "Step to" = step, dest_similarity = similarity),
by = "pair_index",
all.x = FALSE,
all.y = FALSE)
}) %>%
rbind.fill() %>%
select(all_of(c("Source", "Dest", "source_similarity", "Step from", "Step to"))) %>%
rename(Similarity = source_similarity) %>%
mutate(Value = 100,
Distance = `Step to` - `Step from`) %>%
arrange(Distance, `Step from`, desc(Similarity))
###############################################################################
melted_sankey_topics <- merge(melted_sankey,
rcs %>%
select(cluster_code, cluster_name) %>%
rename(source_topic = cluster_name),
by.x = 'Source',
by.y = 'cluster_code',
all.x = TRUE,
all.y = FALSE)
melted_sankey_topics <- merge(melted_sankey_topics,
rcs %>%
select(cluster_code, cluster_name) %>%
rename(target_topic = cluster_name),
by.x = 'Dest',
by.y = 'cluster_code',
all.x = TRUE,
all.y = FALSE)
melted_sankey_topics <- melted_sankey_topics %>%
select(all_of(c("Source", "Dest", "Value", "Step from", "Step to", "Similarity", "Distance", "source_topic", "target_topic"))) %>%
arrange(`Step from`, Source, desc(Similarity)) %>%
distinct(Source, Dest, .keep_all = TRUE) %>%
mutate(
'Value' = map_to_range(Value, 100, 10)
)
# Special filtering
# Save files
write.csv(melted_sankey_topics,
file=file.path(output_folder_path,
settings$metadata$heatmap_analysis_id,
glue('sankey_df_with_deadends_{round(sankey_threshold, 2)}_selected.csv')),
row.names = FALSE)
###############################################################################
# Write color codes for Flourish
write.csv(paste(tmp$cluster_code, tmp$color, sep = ': '),
file=file.path(output_folder_path,
settings$metadata$heatmap_analysis_id,
'sankey_cluster_color_for_flourish.csv'),
row.names = FALSE)
###############################################################################
# Hardcoded!
bridge_clusters <-intersect(
melted_sankey$Dest[melted_sankey$`Step to` == 1],
melted_sankey$Source[melted_sankey$`Step from` == 1]
)
if (length(bridge_clusters) > 0) {
melted_bridge <- melted_sankey %>%
filter(`Step to` != 1 | Dest %in% bridge_clusters) %>%
filter(`Step from` != 1 | Source %in% bridge_clusters)
write.csv(melted_bridge,
file=file.path(output_folder_path,
settings$metadata$heatmap_analysis_id,
'sankey_df_without_deadends.csv'),
row.names = FALSE)
# Readable
left_side <- melted_bridge %>% filter(`Step to` == 1)
right_side <- melted_bridge %>% filter(`Step from` == 1)
melted_bridge_readable <- merge(left_side %>%
select(Source, Dest) %>%
rename(left = Source, bridge = Dest),
right_side %>%
select(Source, Dest) %>%
rename(right = Dest, bridge = Source),
by = "bridge",
all.x = TRUE,
all.y = TRUE)
# Add topics
melted_bridge_readable$left_topic <- rcs$cluster_name[match(melted_bridge_readable$left, rcs$cluster_code)]
melted_bridge_readable$bridge_topic <- rcs$cluster_name[match(melted_bridge_readable$bridge, rcs$cluster_code)]
melted_bridge_readable$right_topic <- rcs$cluster_name[match(melted_bridge_readable$right, rcs$cluster_code)]
# Arrange columns
melted_bridge_readable <- melted_bridge_readable %>% select(left, bridge, right, left_topic, bridge_topic, right_topic)
write.csv(melted_bridge_readable,
file=file.path(output_folder_path,
settings$metadata$heatmap_analysis_id,
'sankey_df_without_deadends_readable.csv'),
row.names = FALSE)
}
# 2024-11-18
# Code to plot a Sankey directly in Rstudo.
# This codes depends on `04_Analyze_after_colab_TM_v3.R`...
# Meaning that we must run it after it.
# This code:
# Plots the Sanky in RStudio
# Saves the plot as an HTML widget
# Colors the edges by the target cluster color (Gradients are not possible yet)
# Displays a max of 50 paths.
# We need two inputs from that environment:
# - `melted_sankey_topics`: the final data frame with the paths
# - `inputs`: the dataframe with the display names and colors as assigned in settings
# Load required libraries
library(dplyr)
library(networkD3)
library(htmlwidgets)
library(RColorBrewer)
library(readr)
library(scales)
# Read the data
data <- melted_sankey_topics #
# Retain upto 50
data <- data %>% top_n(100, wt=Similarity)
# Remove 'others'
data<- data %>%
filter(!grepl("99---|99$", Source)) %>%
filter(!grepl("99---|99$", Dest))
# Remove dashes
data$Source <- gsub("---", ": ", data$Source)
data$Dest <- gsub("---", ": ", data$Dest)
# Prepare names
data$Source <- paste(data$Source, data$source_topic)
data$Dest <- paste(data$Dest, data$target_topic)
# Create nodes dataframe
# Get unique nodes from both source and destination
nodes <- unique(c(data$Source, data$Dest))
nodes_group <- sapply(nodes, \(x) {unlist(strsplit(x, "-"))[[1]]})
nodes_dn <- paste0("'", inputs$display_name, "'", collapse = ", ")
nodes_cl <- paste0("'", inputs$color, "'", collapse = ", ")
nodes_df <- data.frame(
name = nodes,
node_group = factor(nodes_group)
)
# Create links dataframe
links_df <- data.frame(
source = match(data$Source, nodes_df$name) - 1,  # 0-based indexing
target = match(data$Dest, nodes_df$name) - 1,
value = rescale(data$Similarity, to = c(10, 100)) #data$Value
)
links_df$link_group <- nodes_df[links_df$target + 1, 'node_group']
# Create custom color scale
my_color_scale <- JS(sprintf(
glue("d3.scaleOrdinal()
.domain([{nodes_dn}])
.range([{nodes_cl}])")
))
# Create Sankey diagram
sankey <- sankeyNetwork(
Links = links_df,
Nodes = nodes_df,
Source = "source",
Target = "target",
Value = "value",
NodeID = "name",
NodeGroup = "node_group",
LinkGroup = "link_group",
colourScale = my_color_scale,
fontSize = 11,
nodeWidth = 25,
nodePadding = 10,
margin = c('right'=420, 'left'=300),
height = 600,
width = 1600,
sinksRight = FALSE
)
# Display the Sankey in R
sankey
# Add JavaScript to modify label positions
sankey <- htmlwidgets::onRender(
sankey,
'
function(el,x) {
// Get all the node labels
var labels = d3.select(el)
.selectAll(".node text");
// For each label
labels.each(function(d) {
// If node is on the left side (x position is small)
if (d.x < 300) {  // You might need to adjust this threshold
// Position text to the left of the node
d3.select(this)
.attr("x", -10)  // Adjust this value to control label distance
.style("text-anchor", "end");
}
});
}
'
)
sankey
# Save the widget
saveWidget(sankey,
file=file.path(output_folder_path,
settings$metadata$heatmap_analysis_id,
"sankey_diagram.html"),
selfcontained = TRUE)
sankey
tm_plot
# Global scatter by x and y MDS scalling
# i.e. Topic Model plot
tm_plot <- plot_scatter_group(tmp,
point_labels = "cluster_code",
x_column = "x",
y_column = "y",
color_hex_column = "color",
color_labels = "dataset",
size_column = "documents",
show_tags = TRUE)
tm_plot
p <- plot_scatter(tmp %>% filter(dataset == "EUact"),
point_labels = "scatter_labels", # "scatter_labels" for the full cluster name. # "local_cluster" for the cluster code only
x_column = "PY_Mean",
y_column = "Z9_Mean",
color_hex_column = "color",
color_labels = "dataset",
size_column = "documents",
min_x = min(tmp$PY_Mean, na.rm = TRUE) %>% floor(),
max_x = max(tmp$PY_Mean, na.rm = TRUE) %>% ceiling(),
max_y = max(tmp$Z9_Mean, na.rm = TRUE) %>% ceiling(),
show_tags = TRUE)
p
View(tmp)
p <- plot_scatter(tmp %>% filter(dataset == "AI"),
point_labels = "scatter_labels", # "scatter_labels" for the full cluster name. # "local_cluster" for the cluster code only
x_column = "PY_Mean",
y_column = "Z9_Mean",
color_hex_column = "color",
color_labels = "dataset",
size_column = "documents",
min_x = min(tmp$PY_Mean, na.rm = TRUE) %>% floor(),
max_x = max(tmp$PY_Mean, na.rm = TRUE) %>% ceiling(),
max_y = max(tmp$Z9_Mean, na.rm = TRUE) %>% ceiling(),
show_tags = TRUE)
p
p <- plot_scatter(tmp %>% filter(dataset == "AI"),
point_labels = "local_cluster", # "scatter_labels" for the full cluster name. # "local_cluster" for the cluster code only
x_column = "PY_Mean",
y_column = "Z9_Mean",
color_hex_column = "color",
color_labels = "dataset",
size_column = "documents",
min_x = min(tmp$PY_Mean, na.rm = TRUE) %>% floor(),
max_x = max(tmp$PY_Mean, na.rm = TRUE) %>% ceiling(),
max_y = max(tmp$Z9_Mean, na.rm = TRUE) %>% ceiling(),
show_tags = TRUE)
p
convert_to_text(rcs_merged %>%
select(
cluster_code, cluster_name,
documents, PY_Mean, Z9_Mean, description
))
# Assuming your data frame is called 'df'
convert_to_text <- function(df) {
# Open a connection to write to a file
fileConn <- file("EU_act_clusters.txt", "w")
# Loop through each row of the data frame
for(i in 1:nrow(df)) {
# Write each column name and its value
writeLines(paste0("cluster_code: ", df$cluster_code[i]), fileConn)
writeLines(paste0("cluster_name: ", df$cluster_name[i]), fileConn)
writeLines(paste0("PY_Mean: ", df$PY_Mean[i]), fileConn)
writeLines(paste0("Z9_Mean: ", df$Z9_Mean[i]), fileConn)
writeLines(paste0("description: ", df$description[i]), fileConn)
# Add separator between records (except for the last record)
if(i < nrow(df)) {
writeLines("---", fileConn)
}
}
# Close the connection
close(fileConn)
}
convert_to_text(rcs_merged %>%
select(
cluster_code, cluster_name,
documents, PY_Mean, Z9_Mean, description
))
# Assuming your data frame is called 'df'
convert_to_text <- function(df) {
# Open a connection to write to a file
fileConn <- file("EU_act_clusters.md", "w")
# Loop through each row of the data frame
for(i in 1:nrow(df)) {
# Write each column name and its value
writeLines(paste0("cluster_code: ", df$cluster_code[i]), fileConn)
writeLines(paste0("cluster_name: ", df$cluster_name[i]), fileConn)
writeLines(paste0("PY_Mean: ", df$PY_Mean[i]), fileConn)
writeLines(paste0("Z9_Mean: ", df$Z9_Mean[i]), fileConn)
writeLines(paste0("description: ", df$description[i]), fileConn)
# Add separator between records (except for the last record)
if(i < nrow(df)) {
writeLines("\n---\n", fileConn)
}
}
# Close the connection
close(fileConn)
}
# Assuming your data frame is called 'df'
convert_to_text <- function(df) {
# Open a connection to write to a file
fileConn <- file("EU_act_clusters.md", "w")
# Loop through each row of the data frame
for(i in 1:nrow(df)) {
# Write each column name and its value
writeLines(paste0("cluster_code: ", df$cluster_code[i]), fileConn)
writeLines(paste0("cluster_name: ", df$cluster_name[i]), fileConn)
writeLines(paste0("PY_Mean: ", df$PY_Mean[i]), fileConn)
writeLines(paste0("Z9_Mean: ", df$Z9_Mean[i]), fileConn)
writeLines(paste0("description: ", df$description[i]), fileConn)
# Add separator between records (except for the last record)
if(i < nrow(df)) {
writeLines("\n\n---\n\n", fileConn)
}
}
# Close the connection
close(fileConn)
}
convert_to_text(rcs_merged %>%
select(
cluster_code, cluster_name,
documents, PY_Mean, Z9_Mean, description
))
library(readr)
rcs_merged_EUact <- read_csv("~/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive/Q324_EU_Act/a01_tm__f01_e01__km01/level0/cluster_summary.csv")
View(rcs_merged_EUact)
View(rcs_merged)
convert_to_text(rcs_merged_EUact %>%
select(
cluster_code, cluster_name,
documents, PY_Mean, Z9_Mean, description
))
