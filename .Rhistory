###############################################################################
###############################################################################
# Merge the datasets and create needed columns
tmp <- merge(rcs, coords, by = 'cluster_code')
tmp <- tmp %>%
separate(cluster_code,
remove = FALSE,
into = c("dataset", "local_cluster"),
sep = "-",
extra = "merge")
# When using subclusters, lets remove the trailing "---"
tmp$local_cluster <- gsub("---", "", tmp$local_cluster)
tmp <- merge(tmp,
inputs %>%
select(display_name, color, heatmap_display_order, sankey_display_order) %>%
rename(dataset = display_name),
by = 'dataset')
# The labels shown in the scatter plots
tmp$scatter_labels <- paste(tmp$local_cluster, tmp$cluster_name, sep = ':')
# Groups of clusters
km1 <- kmeans(tmp[,c("x","y")], centers = floor(sqrt(nrow(rcs))))
tmp$group <- as.factor(km1$cluster)
unique(tmp$dataset)
# PY Z9 plots
inst <- unique(tmp$dataset)[[3]]
tmp_dataset <- tmp %>% filter(dataset == inst)
tmp_dataset$valid_labels <- tmp_dataset$scatter_labels
tmp_dataset$valid_labels <- paste(substr(tmp_dataset$valid_labels, 1, 30), "...", sep = "")
tmp_dataset$valid_labels[grepl("99|Error", tmp_dataset$valid_labels)] <- ""
p <- plot_scatter(tmp_dataset,
point_labels = "valid_labels",
x_column = "PY_Mean",
y_column = "Z9_Mean",
color_hex_column = "color",
color_labels = "dataset",
size_column = "documents",
min_x = min(tmp$PY_Mean, na.rm = TRUE) %>% floor(),
max_x = max(tmp$PY_Mean, na.rm = TRUE) %>% ceiling(),
max_y = max(tmp$Z9_Mean, na.rm = TRUE) %>% ceiling(),
show_tags = TRUE)
p
p <- plot_scatter(tmp_dataset,
point_labels = "valid_labels",
x_column = "PY_Mean",
y_column = "Z9_Mean",
color_hex_column = "color",
color_labels = "dataset",
size_column = "documents",
min_x = 2017,
max_x = 2023,
max_y = 50,
show_tags = TRUE)
p
# PY Z9 plots
inst <- unique(tmp$dataset)[[4]]
tmp_dataset <- tmp %>% filter(dataset == inst)
tmp_dataset$valid_labels <- tmp_dataset$scatter_labels
tmp_dataset$valid_labels <- paste(substr(tmp_dataset$valid_labels, 1, 30), "...", sep = "")
tmp_dataset$valid_labels[grepl("99|Error", tmp_dataset$valid_labels)] <- ""
p <- plot_scatter(tmp_dataset,
point_labels = "valid_labels",
x_column = "PY_Mean",
y_column = "Z9_Mean",
color_hex_column = "color",
color_labels = "dataset",
size_column = "documents",
min_x = 2017,
max_x = 2023,
max_y = 50,
show_tags = TRUE)
p
# PY Z9 plots
inst <- unique(tmp$dataset)[[2]]
tmp_dataset <- tmp %>% filter(dataset == inst)
tmp_dataset$valid_labels <- tmp_dataset$scatter_labels
tmp_dataset$valid_labels <- paste(substr(tmp_dataset$valid_labels, 1, 30), "...", sep = "")
tmp_dataset$valid_labels[grepl("99|Error", tmp_dataset$valid_labels)] <- ""
p <- plot_scatter(tmp_dataset,
point_labels = "valid_labels",
x_column = "PY_Mean",
y_column = "Z9_Mean",
color_hex_column = "color",
color_labels = "dataset",
size_column = "documents",
min_x = 2017,
max_x = 2023,
max_y = 50,
show_tags = TRUE)
p
load("~/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive/Q318_human_augmentation/a01_cn__f01_dc__c01_lv/level1/environ.rdata")
library(readr)
cluster_summary_assessment <- read_csv("~/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive/Q318_human_augmentation/a01_cn__f01_dc__c01_lv/level1/cluster_summary_assessment.csv")
View(cluster_summary_assessment)
library(readr)
sankey <- read_csv("~/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive/H006_Human-Aug_Sust_Wellbeing_QoL/sankey_df_with_deadends_0.33_selected.csv")
View(sankey)
View(sankey)
View(rcs)
View(rcs_merged)
View(cluster_summary_assessment)
rcs_llm <- cluster_summary_assessment
valid_topic_names <- unique(sankey$source_topic)
valid_clusters <- rcs_llm$cluster_code[rcs_llm$cluster_name %in% valid_topic_names]
valid_clusters
dataset_filteres <- dataset %>% filter(cluster_code %in% valid_clusters)
dataset_filtered <- dataset %>% filter(cluster_code %in% valid_clusters)
View(dataset_filtered)
dataset_filtered <- dataset_filtered[,-c(1:21)]
View(dataset_filtered)
dataset_filtered$X_E <- NULL
# Save dataset for vosviewer
write.csv(dataset_filtered, file = "dataset_filtered_HA_VOSVIEWER.csv", row.names = FALSE)
load("~/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive/Q315_TI_sustainability_10years/a01_cn__f01_dc__c01_lv/level1/environ.rdata")
load("~/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive/Q315_TI_sustainability_10years/a01_cn__f01_dc__c01_lv/level1/environ.rdata")
# ------------------------------------------
# Selected clusters from the other datasets
# We load 1 by one and rename the objects
dataset_sust <- dataset
rcs_merged_sust <- rcs_merged
load("~/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive/Q316_TI_quality_of_life_10years/a01_cn__f01_dc__c01_lv/level1/environ.rdata")
load("~/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive/Q316_TI_quality_of_life_10years/a01_cn__f01_dc__c01_lv/level1/environ.rdata")
dataset_qol <- dataset
rcs_merged_qol <- rcs_merged
load("~/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive/Q317_TI_wellbeing_10years/a01_cn__f01_dc__c01_lv/level1/environ.rdata")
dataset_wb <- dataset
rcs_merged_wb <- rcs_merged
sankey <- read_csv("~/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive/H006_Human-Aug_Sust_Wellbeing_QoL/sankey_df_with_deadends_0.33_selected.csv")
View(sankey)
View(sankey)
valid_topic_names <- unique(sankey$Dest)
valid_clusters <- sapply(valid_topic_names, function(x) {
tt <- strsplit(x, ": ") %>% unlist()
return[[1]]
})
valid_clusters <- sapply(valid_topic_names, function(x) {
tt <- strsplit(x, ": ") %>% unlist()
return(tt[[1]])
})
valid_clusters <- valid_cluster[!grepl("99$", valid_clusters)]
valid_clusters
View(sankey)
# Get the valid clusters
valid_topic_names <- unique(sankey$Dest[sankey$Value >= 0.4])
valid_clusters <- sapply(valid_topic_names, function(x) {
tt <- strsplit(x, ": ") %>% unlist()
return(tt[[1]])
})
valid_clusters <- valid_cluster[!grepl("99$", valid_clusters)]
valid_clusters
# Get the valid clusters
valid_topic_names <- unique(sankey$Dest[sankey$Value >= 0.4])
valid_clusters <- sapply(valid_topic_names, function(x) {
tt <- strsplit(x, ": ") %>% unlist()
return(tt[[1]])
})
# Get the valid clusters
valid_topic_names <- unique(sankey$Dest[sankey$Value >= 0.45])
valid_clusters <- sapply(valid_topic_names, function(x) {
tt <- strsplit(x, ": ") %>% unlist()
return(tt[[1]])
})
valid_clusters <- valid_cluster[!grepl("99$", valid_clusters)]
valid_clusters
View(sankey)
# Get the valid clusters
valid_topic_names <- unique(sankey$Dest[sankey$Similarity >= 0.40])
valid_clusters <- sapply(valid_topic_names, function(x) {
tt <- strsplit(x, ": ") %>% unlist()
return(tt[[1]])
})
valid_clusters <- valid_cluster[!grepl("99$", valid_clusters)]
valid_clusters
# Get the dataset to be used in vos viewer having only selected clusters
dataset_filtered <- dataset %>% filter(cluster_code %in% valid_clusters)
dataset_filtered <- dataset_filtered[,-c(1:21)]
dataset_filtered$X_E <- NULL
View(dataset_qol)
dataset_sust$label <- gsub("---$", "", dataset_sust$subcluster_label1)
dataset_sust$label <- paste("HA", dataset_sust$label, sep = "")
dataset_sust$label <- gsub("---$", "", dataset_sust$subcluster_label1)
dataset_sust$label <- paste("Sust-", dataset_sust$label, sep = "")
dataset_sust$label[1:10]
dataset_qol$label[1:10]
dataset_qol$label <- gsub("---$", "", dataset_qol$subcluster_label1)
dataset_qol$label <- paste("QoL-", dataset_qol$label, sep = "")
dataset_qol$label[1:10]
dataset_wb$label <- gsub("---$", "", dataset_wb$subcluster_label1)
dataset_wb$label <- paste("WB-", dataset_wb$label, sep = "")
dataset_wb$label[1:10]
dt_qol <- dataset_qol %>% filter(label %in% valid_clusters)
dt_wb <- dataset_wb %>% filter(label %in% valid_clusters)
# Get the dataset to be used in vos viewer having only selected clusters
dt_sust <- dataset_sust %>% filter(label %in% valid_clusters)
dt_qol <- dataset_qol %>% filter(label %in% valid_clusters) %>% sample_n(2500)
# Get the dataset to be used in vos viewer having only selected clusters
dt_sust <- dataset_sust %>% filter(label %in% valid_clusters) %>% sample_n(2500)
dataset_filtered <- rbind(dt_sust, dt_qol, dt_wb)
dataset_filtered <- dataset_filtered[,-c(1:21)]
dataset_filtered <- rbind(dt_sust, dt_qol, dt_wb)
unique(colnames(dt_sust), colnames(dt_qol), colnames(dt_wb))
unique(c(colnames(dt_sust), colnames(dt_qol), colnames(dt_wb)))
dataset_filtered <- rbind(dt_sust, dt_qol, dt_wb)
union(c(colnames(dt_sust), colnames(dt_qol), colnames(dt_wb)))
union(colnames(dt_sust), colnames(dt_qol))
valid_header <- union(colnames(dt_sust), colnames(dt_qol))
valid_header <- union(valid_header, colnames(dt_wb))
dataset_filtered <- rbind(dt_sust[,valid_header], dt_qol[,valid_header], dt_wb[,valid_header])
colnames(dt_sust)
colnames(dt_qol)
colnames(dt_wb)
dataset_filtered <- rbind.fill(dt_sust[,valid_header], dt_qol[,valid_header], dt_wb[,valid_header])
dataset_filtered <- rbind.fill(dt_sust, dt_qol, dt_wb)
View(dataset_filtered)
dataset_filtered <- dataset_filtered[,-c(1:21)]
dataset_filtered$X_E <- NULL
# Save dataset for vosviewer
write.csv(dataset_filtered, file = "dataset_filtered_Sust_QuL_WB_VOSVIEWER.csv", row.names = FALSE)
load("~/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive/Q318_human_augmentation/a01_cn__f01_dc__c01_lv/level1/environ.rdata")
rcs_merged_ha <- rcs_merged
dataset_ha$label <- gsub("---$", "", dataset_ha$subcluster_label1)
dataset_ha$label <- paste("HA-", dataset_ha$label, sep = "")
# Selected HA clusters for keyword analysis
# - Those in the sankey
# - Those that are relevant
dataset_ha <- dataset
rcs_merged_ha <- rcs_merged
dataset_ha$label <- gsub("---$", "", dataset_ha$subcluster_label1)
dataset_ha$label <- paste("HA-", dataset_ha$label, sep = "")
dataset_ha$label[1:10]
library(readr)
cluster_summary_assessment <- read_csv("~/Library/CloudStorage/GoogleDrive-cristianmejia00@gmail.com/My Drive/Bibliometrics_Drive/Q318_human_augmentation/a01_cn__f01_dc__c01_lv/level1/cluster_summary_assessment.csv")
View(cluster_summary_assessment)
rcs_llm <- cluster_summary_assessment
load("~/Desktop/GitHub/clustering/VOS_Viewer/vos_assessment.csv")
library(readr)
vos_assessment <- read_csv("VOS_Viewer/vos_assessment.csv")
View(vos_assessment)
#####################
my_regex <- sapply(c(1:9), function(x) {
paste(vos_assessment$label[vos_assessment$cluster2 == x], collapse = "|")
})
#####################
my_regex <- lapply(c(1:9), function(x) {
paste(vos_assessment$label[vos_assessment$cluster2 == x], collapse = "|")
})
#####################
my_regex <- lapply(c(1:9), function(x) {
paste(vos_assessment$label[vos_assessment$cluster2 == x], sep = "|")
})
vos_assessment$label[vos_assessment$cluster2 == 1]
#####################
vos_assessment <- as.data.frame(vos_assessment)
my_regex <- lapply(c(1:9), function(x) {
paste(vos_assessment$label[vos_assessment$cluster2 == x], sep = "|")
})
vos_assessment$label[vos_assessment$cluster2 == 1]
vos_assessment$label[vos_assessment$cluster2 == 2]
ttt <- ttt[is.na(ttt)]
ttt <- vos_assessment$label[vos_assessment$cluster2 == 2]
ttt <- ttt[is.na(ttt)]
ttt
ttt <- vos_assessment$label[vos_assessment$cluster2 == 2]
ttt <- ttt[!is.na(ttt)]
ttt
ttt <- paste(ttt, sep = "|")
ttt
ttt <- paste(ttt, collapse = "|")
ttt
my_regex <- lapply(c(1:9), function(x) {
ttt <- vos_assessment$label[vos_assessment$cluster2 == 2]
ttt <- ttt[!is.na(ttt)]
ttt <- paste(ttt, collapse = "|")
ttt
})
#####################
vos_assessment <- as.data.frame(vos_assessment)
my_regex <- lapply(c(1:9), function(x) {
ttt <- vos_assessment$label[vos_assessment$cluster2 == x]
ttt <- ttt[!is.na(ttt)]
ttt <- paste(ttt, collapse = "|")
ttt
})
ha_text <- paste(dataset$AB, dataset$TI, dataset$ID, dataset$ED, sep = ". ")
ha_text <- paste(dataset$AB, dataset$TI, dataset$ID, dataset$ED, collapse = ". ")
ha_text <- paste(dataset$AB, dataset$TI, dataset$ID, dataset$ED, text = ". ")
ha_text <- paste(dataset$AB, dataset$TI, dataset$ID, dataset$ED, text = ". ")
ha_text[1]
ha_text[100]
ha_text <- tolower(paste(dataset$AB, dataset$TI, dataset$ID, dataset$ED, text = ". "))
dataset_ha$cluster2 <- ""
dataset_ha$cluster[grepl(ttt[[1]], ]
dataset_ha$cluster2 <- ""
for (i in c(1:9)) {
}
dataset_ha$cluster2 <- ""
for (i in c(1:9)) {
dataset_ha$cluster2[grepl(ttt[[x]], ha_text)] <- x
}
dataset_ha$cluster2 <- ""
for (i in c(1:9)) {
dataset_ha$cluster2[grepl(ttt[[i]], ha_text)] <- i
}
ttt
dataset_ha$cluster2 <- ""
for (i in c(1:9)) {
dataset_ha$cluster2[grepl(my_regex[[i]], ha_text)] <- i
}
table(dataset_ha$subcluster_label1, dataset_ha$cluster2)
table(dataset_ha$subcluster_label1, dataset_ha$cluster2) %>% data.frame()
table(dataset_ha$subcluster_label1, dataset_ha$cluster2) %>% as.data.frame()
table(dataset_ha$subcluster_label1, dataset_ha$cluster2) %>% data.frame.as.is()
table(dataset_ha$subcluster_label1, dataset_ha$cluster2) %>% as.data.frame.table()
table(dataset_ha$subcluster_label1, dataset_ha$cluster2) %>% as.data.frame.list()
table(dataset_ha$subcluster_label1, dataset_ha$cluster2) %>% as.data.frame.array()
presence <- table(dataset_ha$subcluster_label1, dataset_ha$cluster2) %>% as.data.frame.array()
write.csv(precense, file="presence.csv", row.names = FALSE)
write.csv(presence, file="presence.csv", row.names = FALSE)
write.csv(presence, file="presence.csv")
dataset_ha %>%
filter(
label == clt,
cluster2 == pp
)
#######################
# selection datasets
clt <- "HA-25-0---"
pp <- 6
dataset_ha %>%
filter(
label == clt,
cluster2 == pp
)
View(dataset_ha)
#######################
# selection datasets
clt <- "25-0---"
pp <- 6
dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
)
pp <- 6
yyy <- dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
) %>%
select(subcluster_label1, AU, PY, Z9, DO, TI, AB, SO)
write.csv(yyy, file = paste("HA-", clt, pp, ".csv"), row.names = FALSE)
#######################
# selection datasets
clt <- "25-0---"
pp <- 6
yyy <- dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
) %>%
select(subcluster_label1, AU, PY, Z9, DI, TI, AB, SO)
View(yyy)
#######################
# selection datasets
clt <- "3-0---"
pp <- 5
yyy <- dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
) %>%
select(subcluster_label1, AU, PY, Z9, DI, TI, AB, SO)
write.csv(yyy, file = paste("HA-", clt, pp, ".csv"), row.names = FALSE)
View(yyy)
#######################
# selection datasets
clt <- "2-1---"
pp <- 3
yyy <- dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
) %>%
select(subcluster_label1, AU, PY, Z9, DI, TI, AB, SO)
for (i in c(1:9)) {
dataset_ha[paste("tt", i, sep="")] <- grepl(my_regex[[i]], ha_text)
}
View(dataset_ha)
presence_correct <- dataset_ha %>% summarise(across(tt1, tt2, tt3), test = sum())
presence_correct <- dataset_ha %>%
group_by(subcluster_label1) %>%
summarise(
tt1_count = sum(tt1, na.rm = TRUE),
tt2_count = sum(tt2, na.rm = TRUE),
tt3_count = sum(tt3, na.rm = TRUE),
tt4_count = sum(tt4, na.rm = TRUE),
tt5_count = sum(tt5, na.rm = TRUE),
tt6_count = sum(tt6, na.rm = TRUE),
tt7_count = sum(tt7, na.rm = TRUE),
tt8_count = sum(tt8, na.rm = TRUE)
)
View(presence_correct)
presence_correct <- dataset_ha %>%
group_by(subcluster_label1) %>%
summarise(
tt1_count = sum(tt1, na.rm = TRUE),
tt2_count = sum(tt2, na.rm = TRUE),
tt3_count = sum(tt3, na.rm = TRUE),
tt4_count = sum(tt4, na.rm = TRUE),
tt5_count = sum(tt5, na.rm = TRUE),
tt6_count = sum(tt6, na.rm = TRUE),
tt7_count = sum(tt7, na.rm = TRUE),
tt8_count = sum(tt8, na.rm = TRUE),
tt9_count = sum(tt9, na.rm = TRUE)
)
View(presence_correct)
write.csv(presence_correct, file="presence_correct.csv")
#######################
# selection datasets
clt <- "99-2---"
pp <- 7
yyy <- dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
) %>%
select(subcluster_label1, AU, PY, Z9, DI, TI, AB, SO)
write.csv(yyy[c(1:5  )], file = paste("HA-", clt, pp, ".csv"), row.names = FALSE)
write.csv(yyy, file = paste("HA-", clt, pp, ".csv"), row.names = FALSE)
#######################
# selection datasets
clt <- "3-0---"
pp <- 5
yyy <- dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
) %>%
select(subcluster_label1, AU, PY, Z9, DI, TI, AB, SO)
write.csv(yyy, file = paste("HA-", clt, pp, ".csv"), row.names = FALSE)
xxx <- dataset_ha[dataset_ha$DI == "https://doi.org/10.1007/s11948-009-9142-5"]
xxx <- dataset_ha[dataset_ha$DI == "https://doi.org/10.1007/s11948-009-9142-5", ]
View(xxx)
xxx <- dataset_ha %>% filter(dataset_ha$DI == "https://doi.org/10.1007/s11948-009-9142-5")
#######################
# selection datasets
clt <- "25-2---"
pp <- 6
yyy <- dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
) %>%
select(subcluster_label1, AU, PY, Z9, DI, TI, AB, SO)
#######################
# selection datasets
clt <- "25-0---"
pp <- 6
yyy <- dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
) %>%
select(subcluster_label1, AU, PY, Z9, DI, TI, AB, SO)
write.csv(yyy, file = paste("HA-", clt, pp, ".csv"), row.names = FALSE)
#######################
# selection datasets
clt <- "18-0---"
pp <- 3
yyy <- dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
) %>%
select(subcluster_label1, AU, PY, Z9, DI, TI, AB, SO)
write.csv(yyy, file = paste("HA-", clt, pp, ".csv"), row.names = FALSE)
#######################
# selection datasets
clt <- "22-0---"
pp <- 2
#######################
# selection datasets
clt <- "26-0---"
pp <- 4
yyy <- dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
) %>%
select(subcluster_label1, AU, PY, Z9, DI, TI, AB, SO)
write.csv(yyy, file = paste("HA-", clt, pp, ".csv"), row.names = FALSE)
#######################
# selection datasets
clt <- "2-2---"
pp <- 2
yyy <- dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
) %>%
select(subcluster_label1, AU, PY, Z9, DI, TI, AB, SO)
write.csv(yyy, file = paste("HA-", clt, pp, ".csv"), row.names = FALSE)
#######################
# selection datasets
clt <- "22-0---"
pp <- 2
yyy <- dataset_ha %>%
filter(
subcluster_label1 == clt,
cluster2 == pp
) %>%
select(subcluster_label1, AU, PY, Z9, DI, TI, AB, SO)
write.csv(yyy, file = paste("HA-", clt, pp, ".csv"), row.names = FALSE)
